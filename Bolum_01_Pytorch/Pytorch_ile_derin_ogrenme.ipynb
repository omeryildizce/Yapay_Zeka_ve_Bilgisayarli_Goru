{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Veri Hazırlama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kütüphaneler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import (Dataset, DataLoader)\n",
    "from skimage import io\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class veri(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n",
    "        image = io.imread(img_path)\n",
    "        y_label = torch.tensor(int(self.annotations.iloc[index, 1]))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return(image, y_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veri Hazırlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = veri(csv_file=r\"../../veriler/f1_classification/f111.csv\", root_dir=r\"../../veriler/f1_classification\", transform=transforms.Compose([\n",
    "\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(size=(28, 28)),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.veri at 0x242acd41d90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veri Ön İşleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = torch.utils.data.random_split(dataset, [200, 79])\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=1, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x242acd41970>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x242acd41be0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veri Görselleştirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redbull\n",
      "torch.Size([1, 3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "batch_size = 1\n",
    "\n",
    "classes = [\"Ferrari\", \"Mclaren\", \"Mercedes\", \"Redbull\"]\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(batch_size)))\n",
    "print(images.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Mimarisini Oluşturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3,  out_channels=4,  kernel_size=(5, 5))\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=4,  out_channels=8,  kernel_size=(3, 3))\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=8,  out_channels=16, kernel_size=(2, 2))\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=16, out_channels=32, kernel_size=(2, 2))\n",
    "\n",
    "        self.max = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.func = nn.ELU()\n",
    "        self.func1 = nn.ReLU()\n",
    "\n",
    "        self.fullyconnect1 = nn.Linear(in_features=32, out_features=50)\n",
    "        self.fullyconnect2 = nn.Linear(in_features=50, out_features=50)\n",
    "        self.fullyconnect3 = nn.Linear(in_features=50, out_features=100)\n",
    "        self.fullyconnect4 = nn.Linear(in_features=100, out_features=4)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.func(x)\n",
    "        x = self.max(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.func(x)\n",
    "        x = self.max(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.func(x)\n",
    "        x = self.max(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.func(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # flaten\n",
    "        \n",
    "        x = self.fullyconnect1(x)\n",
    "        x = self.func(x)\n",
    "        x = self.fullyconnect2(x)\n",
    "        x = self.func(x)\n",
    "        x = self.fullyconnect3(x)\n",
    "        x = self.func(x)\n",
    "        \n",
    "        x = self.fullyconnect4(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelin Eğitimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1, loss:1.5265]\n",
      "Epoch [1/2, loss:1.4699]\n",
      "Epoch [1/3, loss:1.4191]\n",
      "Epoch [1/4, loss:1.3566]\n",
      "Epoch [1/5, loss:1.3355]\n",
      "Epoch [1/6, loss:1.2994]\n",
      "Epoch [1/7, loss:1.4783]\n",
      "Epoch [1/8, loss:1.3582]\n",
      "Epoch [1/9, loss:1.3561]\n",
      "Epoch [1/10, loss:1.2142]\n",
      "Epoch [1/11, loss:1.1995]\n",
      "Epoch [1/12, loss:1.1928]\n",
      "Epoch [1/13, loss:1.3423]\n",
      "Epoch [1/14, loss:1.3381]\n",
      "Epoch [1/15, loss:1.3204]\n",
      "Epoch [1/16, loss:1.5631]\n",
      "Epoch [1/17, loss:1.6724]\n",
      "Epoch [1/18, loss:1.2934]\n",
      "Epoch [1/19, loss:1.2787]\n",
      "Epoch [1/20, loss:1.5869]\n",
      "Epoch [1/21, loss:1.2475]\n",
      "Epoch [1/22, loss:1.1313]\n",
      "Epoch [1/23, loss:1.5663]\n",
      "Epoch [1/24, loss:1.5710]\n",
      "Epoch [1/25, loss:1.7390]\n",
      "Epoch [1/26, loss:1.1788]\n",
      "Epoch [1/27, loss:1.1693]\n",
      "Epoch [1/28, loss:1.7331]\n",
      "Epoch [1/29, loss:1.1799]\n",
      "Epoch [1/30, loss:1.1733]\n",
      "Epoch [1/31, loss:1.7219]\n",
      "Epoch [1/32, loss:1.7242]\n",
      "Epoch [1/33, loss:1.7099]\n",
      "Epoch [1/34, loss:1.5337]\n",
      "Epoch [1/35, loss:1.2549]\n",
      "Epoch [1/36, loss:1.6709]\n",
      "Epoch [1/37, loss:1.5202]\n",
      "Epoch [1/38, loss:1.5190]\n",
      "Epoch [1/39, loss:1.5077]\n",
      "Epoch [1/40, loss:1.4945]\n",
      "Epoch [1/41, loss:1.2054]\n",
      "Epoch [1/42, loss:1.2940]\n",
      "Epoch [1/43, loss:1.4612]\n",
      "Epoch [1/44, loss:1.6110]\n",
      "Epoch [1/45, loss:1.5985]\n",
      "Epoch [1/46, loss:1.5907]\n",
      "Epoch [1/47, loss:1.2515]\n",
      "Epoch [1/48, loss:1.5711]\n",
      "Epoch [1/49, loss:1.5654]\n",
      "Epoch [1/50, loss:1.5471]\n",
      "Epoch [1/51, loss:1.2689]\n",
      "Epoch [1/52, loss:1.4132]\n",
      "Epoch [1/53, loss:1.4123]\n",
      "Epoch [1/54, loss:1.5138]\n",
      "Epoch [1/55, loss:1.5075]\n",
      "Epoch [1/56, loss:1.4029]\n",
      "Epoch [1/57, loss:1.3724]\n",
      "Epoch [1/58, loss:1.3940]\n",
      "Epoch [1/59, loss:1.3857]\n",
      "Epoch [1/60, loss:1.4723]\n",
      "Epoch [1/61, loss:1.3661]\n",
      "Epoch [1/62, loss:1.3313]\n",
      "Epoch [1/63, loss:1.3440]\n",
      "Epoch [1/64, loss:1.3422]\n",
      "Epoch [1/65, loss:1.3416]\n",
      "Epoch [1/66, loss:1.4240]\n",
      "Epoch [1/67, loss:1.4216]\n",
      "Epoch [1/68, loss:1.4209]\n",
      "Epoch [1/69, loss:1.3561]\n",
      "Epoch [1/70, loss:1.3485]\n",
      "Epoch [1/71, loss:1.4151]\n",
      "Epoch [1/72, loss:1.4641]\n",
      "Epoch [1/73, loss:1.4676]\n",
      "Epoch [1/74, loss:1.3225]\n",
      "Epoch [1/75, loss:1.4667]\n",
      "Epoch [1/76, loss:1.4086]\n",
      "Epoch [1/77, loss:1.3169]\n",
      "Epoch [1/78, loss:1.4090]\n",
      "Epoch [1/79, loss:1.4045]\n",
      "Epoch [1/80, loss:1.4026]\n",
      "Epoch [1/81, loss:1.3767]\n",
      "Epoch [1/82, loss:1.4595]\n",
      "Epoch [1/83, loss:1.3793]\n",
      "Epoch [1/84, loss:1.3819]\n",
      "Epoch [1/85, loss:1.3750]\n",
      "Epoch [1/86, loss:1.3818]\n",
      "Epoch [1/87, loss:1.3640]\n",
      "Epoch [1/88, loss:1.3312]\n",
      "Epoch [1/89, loss:1.3447]\n",
      "Epoch [1/90, loss:1.3426]\n",
      "Epoch [1/91, loss:1.4712]\n",
      "Epoch [1/92, loss:1.3308]\n",
      "Epoch [1/93, loss:1.3977]\n",
      "Epoch [1/94, loss:1.4725]\n",
      "Epoch [1/95, loss:1.3260]\n",
      "Epoch [1/96, loss:1.3895]\n",
      "Epoch [1/97, loss:1.3514]\n",
      "Epoch [1/98, loss:1.4728]\n",
      "Epoch [1/99, loss:1.3058]\n",
      "Epoch [1/100, loss:1.3505]\n",
      "Epoch [1/101, loss:1.3085]\n",
      "Epoch [1/102, loss:1.4789]\n",
      "Epoch [1/103, loss:1.3473]\n",
      "Epoch [1/104, loss:1.2995]\n",
      "Epoch [1/105, loss:1.3519]\n",
      "Epoch [1/106, loss:1.2895]\n",
      "Epoch [1/107, loss:1.2804]\n",
      "Epoch [1/108, loss:1.2764]\n",
      "Epoch [1/109, loss:1.2798]\n",
      "Epoch [1/110, loss:1.4802]\n",
      "Epoch [1/111, loss:1.3402]\n",
      "Epoch [1/112, loss:1.4655]\n",
      "Epoch [1/113, loss:1.2175]\n",
      "Epoch [1/114, loss:1.5037]\n",
      "Epoch [1/115, loss:1.3474]\n",
      "Epoch [1/116, loss:1.3437]\n",
      "Epoch [1/117, loss:1.3343]\n",
      "Epoch [1/118, loss:1.5162]\n",
      "Epoch [1/119, loss:1.5196]\n",
      "Epoch [1/120, loss:1.5231]\n",
      "Epoch [1/121, loss:1.3233]\n",
      "Epoch [1/122, loss:1.2134]\n",
      "Epoch [1/123, loss:1.3179]\n",
      "Epoch [1/124, loss:1.3039]\n",
      "Epoch [1/125, loss:1.3021]\n",
      "Epoch [1/126, loss:1.2945]\n",
      "Epoch [1/127, loss:1.2369]\n",
      "Epoch [1/128, loss:1.2039]\n",
      "Epoch [1/129, loss:1.5274]\n",
      "Epoch [1/130, loss:1.5475]\n",
      "Epoch [1/131, loss:1.2117]\n",
      "Epoch [1/132, loss:1.5781]\n",
      "Epoch [1/133, loss:1.5513]\n",
      "Epoch [1/134, loss:1.2053]\n",
      "Epoch [1/135, loss:1.5178]\n",
      "Epoch [1/136, loss:1.2243]\n",
      "Epoch [1/137, loss:1.5420]\n",
      "Epoch [1/138, loss:1.5626]\n",
      "Epoch [1/139, loss:1.5402]\n",
      "Epoch [1/140, loss:1.5469]\n",
      "Epoch [1/141, loss:1.5208]\n",
      "Epoch [1/142, loss:1.5515]\n",
      "Epoch [1/143, loss:1.5237]\n",
      "Epoch [1/144, loss:1.5197]\n",
      "Epoch [1/145, loss:1.2206]\n",
      "Epoch [1/146, loss:1.5119]\n",
      "Epoch [1/147, loss:1.4808]\n",
      "Epoch [1/148, loss:1.4764]\n",
      "Epoch [1/149, loss:1.4805]\n",
      "Epoch [1/150, loss:1.3214]\n",
      "Epoch [1/151, loss:1.3485]\n",
      "Epoch [1/152, loss:1.4488]\n",
      "Epoch [1/153, loss:1.4631]\n",
      "Epoch [1/154, loss:1.2863]\n",
      "Epoch [1/155, loss:1.2808]\n",
      "Epoch [1/156, loss:1.3406]\n",
      "Epoch [1/157, loss:1.2634]\n",
      "Epoch [1/158, loss:1.4262]\n",
      "Epoch [1/159, loss:1.4503]\n",
      "Epoch [1/160, loss:1.3576]\n",
      "Epoch [1/161, loss:1.4235]\n",
      "Epoch [1/162, loss:1.2910]\n",
      "Epoch [1/163, loss:1.4548]\n",
      "Epoch [1/164, loss:1.3716]\n",
      "Epoch [1/165, loss:1.3677]\n",
      "Epoch [1/166, loss:1.3552]\n",
      "Epoch [1/167, loss:1.3681]\n",
      "Epoch [1/168, loss:1.3442]\n",
      "Epoch [1/169, loss:1.3909]\n",
      "Epoch [1/170, loss:1.4510]\n",
      "Epoch [1/171, loss:1.4322]\n",
      "Epoch [1/172, loss:1.3451]\n",
      "Epoch [1/173, loss:1.3126]\n",
      "Epoch [1/174, loss:1.4385]\n",
      "Epoch [1/175, loss:1.3192]\n",
      "Epoch [1/176, loss:1.4829]\n",
      "Epoch [1/177, loss:1.4090]\n",
      "Epoch [1/178, loss:1.2920]\n",
      "Epoch [1/179, loss:1.4404]\n",
      "Epoch [1/180, loss:1.4467]\n",
      "Epoch [1/181, loss:1.3159]\n",
      "Epoch [1/182, loss:1.3181]\n",
      "Epoch [1/183, loss:1.4197]\n",
      "Epoch [1/184, loss:1.3522]\n",
      "Epoch [1/185, loss:1.4069]\n",
      "Epoch [1/186, loss:1.3063]\n",
      "Epoch [1/187, loss:1.3087]\n",
      "Epoch [1/188, loss:1.3095]\n",
      "Epoch [1/189, loss:1.4034]\n",
      "Epoch [1/190, loss:1.3975]\n",
      "Epoch [1/191, loss:1.3651]\n",
      "Epoch [1/192, loss:1.4276]\n",
      "Epoch [1/193, loss:1.2666]\n",
      "Epoch [1/194, loss:1.4054]\n",
      "Epoch [1/195, loss:1.3586]\n",
      "Epoch [1/196, loss:1.3525]\n",
      "Epoch [1/197, loss:1.4436]\n",
      "Epoch [1/198, loss:1.3609]\n",
      "Epoch [1/199, loss:1.3514]\n",
      "Epoch [1/200, loss:1.2796]\n",
      "Epoch [2/1, loss:1.3592]\n",
      "Epoch [2/2, loss:1.2850]\n",
      "Epoch [2/3, loss:1.2809]\n",
      "Epoch [2/4, loss:1.3136]\n",
      "Epoch [2/5, loss:1.2895]\n",
      "Epoch [2/6, loss:1.2476]\n",
      "Epoch [2/7, loss:1.3920]\n",
      "Epoch [2/8, loss:1.2941]\n",
      "Epoch [2/9, loss:1.2859]\n",
      "Epoch [2/10, loss:1.2576]\n",
      "Epoch [2/11, loss:1.2521]\n",
      "Epoch [2/12, loss:1.1938]\n",
      "Epoch [2/13, loss:1.3263]\n",
      "Epoch [2/14, loss:1.3179]\n",
      "Epoch [2/15, loss:1.3497]\n",
      "Epoch [2/16, loss:1.4674]\n",
      "Epoch [2/17, loss:1.5434]\n",
      "Epoch [2/18, loss:1.3351]\n",
      "Epoch [2/19, loss:1.2665]\n",
      "Epoch [2/20, loss:1.4475]\n",
      "Epoch [2/21, loss:1.1966]\n",
      "Epoch [2/22, loss:1.1180]\n",
      "Epoch [2/23, loss:1.5882]\n",
      "Epoch [2/24, loss:1.4414]\n",
      "Epoch [2/25, loss:1.5283]\n",
      "Epoch [2/26, loss:1.2701]\n",
      "Epoch [2/27, loss:1.2855]\n",
      "Epoch [2/28, loss:1.5230]\n",
      "Epoch [2/29, loss:1.2842]\n",
      "Epoch [2/30, loss:1.1530]\n",
      "Epoch [2/31, loss:1.5021]\n",
      "Epoch [2/32, loss:1.5204]\n",
      "Epoch [2/33, loss:1.6123]\n",
      "Epoch [2/34, loss:1.6012]\n",
      "Epoch [2/35, loss:1.2176]\n",
      "Epoch [2/36, loss:1.4896]\n",
      "Epoch [2/37, loss:1.6505]\n",
      "Epoch [2/38, loss:1.4698]\n",
      "Epoch [2/39, loss:1.4010]\n",
      "Epoch [2/40, loss:1.5691]\n",
      "Epoch [2/41, loss:1.2647]\n",
      "Epoch [2/42, loss:1.2462]\n",
      "Epoch [2/43, loss:1.5669]\n",
      "Epoch [2/44, loss:1.5169]\n",
      "Epoch [2/45, loss:1.4812]\n",
      "Epoch [2/46, loss:1.4060]\n",
      "Epoch [2/47, loss:1.2644]\n",
      "Epoch [2/48, loss:1.4012]\n",
      "Epoch [2/49, loss:1.5808]\n",
      "Epoch [2/50, loss:1.3908]\n",
      "Epoch [2/51, loss:1.1917]\n",
      "Epoch [2/52, loss:1.5018]\n",
      "Epoch [2/53, loss:1.3153]\n",
      "Epoch [2/54, loss:1.3974]\n",
      "Epoch [2/55, loss:1.5498]\n",
      "Epoch [2/56, loss:1.4936]\n",
      "Epoch [2/57, loss:1.3441]\n",
      "Epoch [2/58, loss:1.5178]\n",
      "Epoch [2/59, loss:1.4423]\n",
      "Epoch [2/60, loss:1.3538]\n",
      "Epoch [2/61, loss:1.2877]\n",
      "Epoch [2/62, loss:1.2852]\n",
      "Epoch [2/63, loss:1.2661]\n",
      "Epoch [2/64, loss:1.3006]\n",
      "Epoch [2/65, loss:1.3223]\n",
      "Epoch [2/66, loss:1.2575]\n",
      "Epoch [2/67, loss:1.3770]\n",
      "Epoch [2/68, loss:1.3246]\n",
      "Epoch [2/69, loss:1.3133]\n",
      "Epoch [2/70, loss:1.2308]\n",
      "Epoch [2/71, loss:1.2582]\n",
      "Epoch [2/72, loss:1.2913]\n",
      "Epoch [2/73, loss:1.5014]\n",
      "Epoch [2/74, loss:1.4129]\n",
      "Epoch [2/75, loss:1.4778]\n",
      "Epoch [2/76, loss:1.2786]\n",
      "Epoch [2/77, loss:1.2784]\n",
      "Epoch [2/78, loss:1.1838]\n",
      "Epoch [2/79, loss:1.1299]\n",
      "Epoch [2/80, loss:1.2394]\n",
      "Epoch [2/81, loss:1.3147]\n",
      "Epoch [2/82, loss:1.1148]\n",
      "Epoch [2/83, loss:1.3308]\n",
      "Epoch [2/84, loss:1.3082]\n",
      "Epoch [2/85, loss:1.2735]\n",
      "Epoch [2/86, loss:1.3135]\n",
      "Epoch [2/87, loss:1.0945]\n",
      "Epoch [2/88, loss:1.0900]\n",
      "Epoch [2/89, loss:1.1537]\n",
      "Epoch [2/90, loss:1.3168]\n",
      "Epoch [2/91, loss:1.4959]\n",
      "Epoch [2/92, loss:1.2193]\n",
      "Epoch [2/93, loss:1.6432]\n",
      "Epoch [2/94, loss:1.2679]\n",
      "Epoch [2/95, loss:0.9806]\n",
      "Epoch [2/96, loss:1.1182]\n",
      "Epoch [2/97, loss:1.0941]\n",
      "Epoch [2/98, loss:1.1259]\n",
      "Epoch [2/99, loss:1.0359]\n",
      "Epoch [2/100, loss:1.0037]\n",
      "Epoch [2/101, loss:1.0261]\n",
      "Epoch [2/102, loss:1.0640]\n",
      "Epoch [2/103, loss:0.9910]\n",
      "Epoch [2/104, loss:1.1295]\n",
      "Epoch [2/105, loss:1.3757]\n",
      "Epoch [2/106, loss:1.0683]\n",
      "Epoch [2/107, loss:0.9937]\n",
      "Epoch [2/108, loss:0.9912]\n",
      "Epoch [2/109, loss:0.8999]\n",
      "Epoch [2/110, loss:0.8775]\n",
      "Epoch [2/111, loss:0.9631]\n",
      "Epoch [2/112, loss:1.1600]\n",
      "Epoch [2/113, loss:0.7700]\n",
      "Epoch [2/114, loss:2.2456]\n",
      "Epoch [2/115, loss:1.2723]\n",
      "Epoch [2/116, loss:0.9900]\n",
      "Epoch [2/117, loss:0.9628]\n",
      "Epoch [2/118, loss:1.0349]\n",
      "Epoch [2/119, loss:0.9203]\n",
      "Epoch [2/120, loss:1.5751]\n",
      "Epoch [2/121, loss:1.0056]\n",
      "Epoch [2/122, loss:0.8966]\n",
      "Epoch [2/123, loss:0.9887]\n",
      "Epoch [2/124, loss:0.8932]\n",
      "Epoch [2/125, loss:0.8780]\n",
      "Epoch [2/126, loss:0.8686]\n",
      "Epoch [2/127, loss:1.0516]\n",
      "Epoch [2/128, loss:0.7912]\n",
      "Epoch [2/129, loss:1.3054]\n",
      "Epoch [2/130, loss:1.9486]\n",
      "Epoch [2/131, loss:0.9274]\n",
      "Epoch [2/132, loss:1.5441]\n",
      "Epoch [2/133, loss:1.6881]\n",
      "Epoch [2/134, loss:0.8022]\n",
      "Epoch [2/135, loss:1.1376]\n",
      "Epoch [2/136, loss:1.0235]\n",
      "Epoch [2/137, loss:0.6358]\n",
      "Epoch [2/138, loss:1.6906]\n",
      "Epoch [2/139, loss:0.6633]\n",
      "Epoch [2/140, loss:0.5909]\n",
      "Epoch [2/141, loss:1.5986]\n",
      "Epoch [2/142, loss:1.3486]\n",
      "Epoch [2/143, loss:0.5471]\n",
      "Epoch [2/144, loss:0.5467]\n",
      "Epoch [2/145, loss:0.8387]\n",
      "Epoch [2/146, loss:1.9003]\n",
      "Epoch [2/147, loss:1.2308]\n",
      "Epoch [2/148, loss:0.3780]\n",
      "Epoch [2/149, loss:1.2825]\n",
      "Epoch [2/150, loss:0.8184]\n",
      "Epoch [2/151, loss:1.1509]\n",
      "Epoch [2/152, loss:0.3727]\n",
      "Epoch [2/153, loss:1.9297]\n",
      "Epoch [2/154, loss:1.0411]\n",
      "Epoch [2/155, loss:0.9157]\n",
      "Epoch [2/156, loss:0.8208]\n",
      "Epoch [2/157, loss:0.8167]\n",
      "Epoch [2/158, loss:1.2597]\n",
      "Epoch [2/159, loss:1.6706]\n",
      "Epoch [2/160, loss:0.9247]\n",
      "Epoch [2/161, loss:0.2627]\n",
      "Epoch [2/162, loss:0.8900]\n",
      "Epoch [2/163, loss:2.1293]\n",
      "Epoch [2/164, loss:2.4918]\n",
      "Epoch [2/165, loss:1.2086]\n",
      "Epoch [2/166, loss:1.0140]\n",
      "Epoch [2/167, loss:2.2246]\n",
      "Epoch [2/168, loss:0.8023]\n",
      "Epoch [2/169, loss:1.4705]\n",
      "Epoch [2/170, loss:0.6081]\n",
      "Epoch [2/171, loss:1.4957]\n",
      "Epoch [2/172, loss:2.5602]\n",
      "Epoch [2/173, loss:0.8440]\n",
      "Epoch [2/174, loss:0.3098]\n",
      "Epoch [2/175, loss:0.8390]\n",
      "Epoch [2/176, loss:2.7392]\n",
      "Epoch [2/177, loss:1.2176]\n",
      "Epoch [2/178, loss:0.7442]\n",
      "Epoch [2/179, loss:0.5129]\n",
      "Epoch [2/180, loss:0.8433]\n",
      "Epoch [2/181, loss:0.9057]\n",
      "Epoch [2/182, loss:0.9332]\n",
      "Epoch [2/183, loss:1.4168]\n",
      "Epoch [2/184, loss:0.8555]\n",
      "Epoch [2/185, loss:1.2211]\n",
      "Epoch [2/186, loss:0.8820]\n",
      "Epoch [2/187, loss:0.9635]\n",
      "Epoch [2/188, loss:0.9264]\n",
      "Epoch [2/189, loss:1.2158]\n",
      "Epoch [2/190, loss:1.3345]\n",
      "Epoch [2/191, loss:1.1860]\n",
      "Epoch [2/192, loss:1.5374]\n",
      "Epoch [2/193, loss:0.7498]\n",
      "Epoch [2/194, loss:1.1657]\n",
      "Epoch [2/195, loss:0.8369]\n",
      "Epoch [2/196, loss:1.2771]\n",
      "Epoch [2/197, loss:0.6096]\n",
      "Epoch [2/198, loss:1.3780]\n",
      "Epoch [2/199, loss:1.1638]\n",
      "Epoch [2/200, loss:0.7347]\n",
      "Epoch [3/1, loss:1.3793]\n",
      "Epoch [3/2, loss:1.3480]\n",
      "Epoch [3/3, loss:1.1969]\n",
      "Epoch [3/4, loss:1.0396]\n",
      "Epoch [3/5, loss:1.1122]\n",
      "Epoch [3/6, loss:1.1513]\n",
      "Epoch [3/7, loss:0.9351]\n",
      "Epoch [3/8, loss:0.7499]\n",
      "Epoch [3/9, loss:0.7698]\n",
      "Epoch [3/10, loss:1.0525]\n",
      "Epoch [3/11, loss:1.2532]\n",
      "Epoch [3/12, loss:1.0604]\n",
      "Epoch [3/13, loss:1.3856]\n",
      "Epoch [3/14, loss:0.9227]\n",
      "Epoch [3/15, loss:1.5029]\n",
      "Epoch [3/16, loss:0.9862]\n",
      "Epoch [3/17, loss:1.0683]\n",
      "Epoch [3/18, loss:1.1427]\n",
      "Epoch [3/19, loss:0.6969]\n",
      "Epoch [3/20, loss:0.9372]\n",
      "Epoch [3/21, loss:0.5962]\n",
      "Epoch [3/22, loss:0.9419]\n",
      "Epoch [3/23, loss:1.1346]\n",
      "Epoch [3/24, loss:0.9327]\n",
      "Epoch [3/25, loss:0.8400]\n",
      "Epoch [3/26, loss:1.5227]\n",
      "Epoch [3/27, loss:1.8478]\n",
      "Epoch [3/28, loss:0.7901]\n",
      "Epoch [3/29, loss:1.7354]\n",
      "Epoch [3/30, loss:1.1207]\n",
      "Epoch [3/31, loss:0.4938]\n",
      "Epoch [3/32, loss:0.6674]\n",
      "Epoch [3/33, loss:2.7182]\n",
      "Epoch [3/34, loss:0.9996]\n",
      "Epoch [3/35, loss:0.7263]\n",
      "Epoch [3/36, loss:0.6831]\n",
      "Epoch [3/37, loss:1.6960]\n",
      "Epoch [3/38, loss:0.9329]\n",
      "Epoch [3/39, loss:0.8639]\n",
      "Epoch [3/40, loss:1.0321]\n",
      "Epoch [3/41, loss:1.7897]\n",
      "Epoch [3/42, loss:0.8937]\n",
      "Epoch [3/43, loss:1.2020]\n",
      "Epoch [3/44, loss:0.6298]\n",
      "Epoch [3/45, loss:0.7642]\n",
      "Epoch [3/46, loss:0.4074]\n",
      "Epoch [3/47, loss:1.0930]\n",
      "Epoch [3/48, loss:0.4280]\n",
      "Epoch [3/49, loss:1.9424]\n",
      "Epoch [3/50, loss:0.4885]\n",
      "Epoch [3/51, loss:1.0206]\n",
      "Epoch [3/52, loss:0.9622]\n",
      "Epoch [3/53, loss:0.7592]\n",
      "Epoch [3/54, loss:0.5510]\n",
      "Epoch [3/55, loss:2.5793]\n",
      "Epoch [3/56, loss:0.8790]\n",
      "Epoch [3/57, loss:1.0171]\n",
      "Epoch [3/58, loss:0.9984]\n",
      "Epoch [3/59, loss:0.8779]\n",
      "Epoch [3/60, loss:0.5402]\n",
      "Epoch [3/61, loss:0.5965]\n",
      "Epoch [3/62, loss:1.0689]\n",
      "Epoch [3/63, loss:0.7285]\n",
      "Epoch [3/64, loss:1.1012]\n",
      "Epoch [3/65, loss:0.6744]\n",
      "Epoch [3/66, loss:1.0324]\n",
      "Epoch [3/67, loss:1.3447]\n",
      "Epoch [3/68, loss:1.0232]\n",
      "Epoch [3/69, loss:1.0667]\n",
      "Epoch [3/70, loss:1.3200]\n",
      "Epoch [3/71, loss:1.0517]\n",
      "Epoch [3/72, loss:0.6342]\n",
      "Epoch [3/73, loss:0.9733]\n",
      "Epoch [3/74, loss:1.3904]\n",
      "Epoch [3/75, loss:0.5492]\n",
      "Epoch [3/76, loss:1.0616]\n",
      "Epoch [3/77, loss:0.6961]\n",
      "Epoch [3/78, loss:1.0974]\n",
      "Epoch [3/79, loss:1.0937]\n",
      "Epoch [3/80, loss:1.0674]\n",
      "Epoch [3/81, loss:1.0943]\n",
      "Epoch [3/82, loss:0.1437]\n",
      "Epoch [3/83, loss:1.1590]\n",
      "Epoch [3/84, loss:1.1742]\n",
      "Epoch [3/85, loss:0.9735]\n",
      "Epoch [3/86, loss:1.0535]\n",
      "Epoch [3/87, loss:0.9033]\n",
      "Epoch [3/88, loss:0.6242]\n",
      "Epoch [3/89, loss:0.7340]\n",
      "Epoch [3/90, loss:0.6914]\n",
      "Epoch [3/91, loss:0.5942]\n",
      "Epoch [3/92, loss:0.9721]\n",
      "Epoch [3/93, loss:1.0633]\n",
      "Epoch [3/94, loss:0.6355]\n",
      "Epoch [3/95, loss:0.5365]\n",
      "Epoch [3/96, loss:1.3913]\n",
      "Epoch [3/97, loss:0.9304]\n",
      "Epoch [3/98, loss:0.3935]\n",
      "Epoch [3/99, loss:0.6361]\n",
      "Epoch [3/100, loss:0.9411]\n",
      "Epoch [3/101, loss:0.5170]\n",
      "Epoch [3/102, loss:0.1797]\n",
      "Epoch [3/103, loss:0.9391]\n",
      "Epoch [3/104, loss:0.7042]\n",
      "Epoch [3/105, loss:0.9557]\n",
      "Epoch [3/106, loss:0.5783]\n",
      "Epoch [3/107, loss:0.4955]\n",
      "Epoch [3/108, loss:0.5796]\n",
      "Epoch [3/109, loss:0.5543]\n",
      "Epoch [3/110, loss:0.3220]\n",
      "Epoch [3/111, loss:1.2764]\n",
      "Epoch [3/112, loss:1.2734]\n",
      "Epoch [3/113, loss:0.5307]\n",
      "Epoch [3/114, loss:1.0296]\n",
      "Epoch [3/115, loss:1.1749]\n",
      "Epoch [3/116, loss:1.0450]\n",
      "Epoch [3/117, loss:1.1696]\n",
      "Epoch [3/118, loss:0.3787]\n",
      "Epoch [3/119, loss:0.3200]\n",
      "Epoch [3/120, loss:1.0056]\n",
      "Epoch [3/121, loss:0.9439]\n",
      "Epoch [3/122, loss:0.4777]\n",
      "Epoch [3/123, loss:0.9000]\n",
      "Epoch [3/124, loss:1.1056]\n",
      "Epoch [3/125, loss:0.9807]\n",
      "Epoch [3/126, loss:0.9125]\n",
      "Epoch [3/127, loss:0.6076]\n",
      "Epoch [3/128, loss:0.5068]\n",
      "Epoch [3/129, loss:1.9845]\n",
      "Epoch [3/130, loss:1.0231]\n",
      "Epoch [3/131, loss:0.6898]\n",
      "Epoch [3/132, loss:1.1043]\n",
      "Epoch [3/133, loss:1.0037]\n",
      "Epoch [3/134, loss:0.6089]\n",
      "Epoch [3/135, loss:1.4622]\n",
      "Epoch [3/136, loss:0.6573]\n",
      "Epoch [3/137, loss:0.3735]\n",
      "Epoch [3/138, loss:0.7646]\n",
      "Epoch [3/139, loss:0.4039]\n",
      "Epoch [3/140, loss:0.2495]\n",
      "Epoch [3/141, loss:0.9488]\n",
      "Epoch [3/142, loss:0.6983]\n",
      "Epoch [3/143, loss:0.2709]\n",
      "Epoch [3/144, loss:0.2349]\n",
      "Epoch [3/145, loss:0.5955]\n",
      "Epoch [3/146, loss:1.7002]\n",
      "Epoch [3/147, loss:0.9232]\n",
      "Epoch [3/148, loss:0.1913]\n",
      "Epoch [3/149, loss:0.9213]\n",
      "Epoch [3/150, loss:0.9932]\n",
      "Epoch [3/151, loss:0.8657]\n",
      "Epoch [3/152, loss:0.2662]\n",
      "Epoch [3/153, loss:1.9587]\n",
      "Epoch [3/154, loss:0.8601]\n",
      "Epoch [3/155, loss:0.6859]\n",
      "Epoch [3/156, loss:0.8921]\n",
      "Epoch [3/157, loss:0.5902]\n",
      "Epoch [3/158, loss:1.1542]\n",
      "Epoch [3/159, loss:1.0983]\n",
      "Epoch [3/160, loss:0.8084]\n",
      "Epoch [3/161, loss:0.2038]\n",
      "Epoch [3/162, loss:0.6885]\n",
      "Epoch [3/163, loss:1.2003]\n",
      "Epoch [3/164, loss:3.8277]\n",
      "Epoch [3/165, loss:0.8952]\n",
      "Epoch [3/166, loss:0.7874]\n",
      "Epoch [3/167, loss:3.0585]\n",
      "Epoch [3/168, loss:0.7878]\n",
      "Epoch [3/169, loss:1.3345]\n",
      "Epoch [3/170, loss:0.5057]\n",
      "Epoch [3/171, loss:0.9093]\n",
      "Epoch [3/172, loss:3.9840]\n",
      "Epoch [3/173, loss:0.6606]\n",
      "Epoch [3/174, loss:0.2669]\n",
      "Epoch [3/175, loss:0.7912]\n",
      "Epoch [3/176, loss:2.7302]\n",
      "Epoch [3/177, loss:1.0690]\n",
      "Epoch [3/178, loss:0.5740]\n",
      "Epoch [3/179, loss:0.5453]\n",
      "Epoch [3/180, loss:0.8633]\n",
      "Epoch [3/181, loss:0.7565]\n",
      "Epoch [3/182, loss:0.7299]\n",
      "Epoch [3/183, loss:0.8972]\n",
      "Epoch [3/184, loss:0.7155]\n",
      "Epoch [3/185, loss:0.8924]\n",
      "Epoch [3/186, loss:0.7767]\n",
      "Epoch [3/187, loss:0.7871]\n",
      "Epoch [3/188, loss:0.7727]\n",
      "Epoch [3/189, loss:0.8757]\n",
      "Epoch [3/190, loss:1.4022]\n",
      "Epoch [3/191, loss:0.8174]\n",
      "Epoch [3/192, loss:0.9993]\n",
      "Epoch [3/193, loss:0.7045]\n",
      "Epoch [3/194, loss:1.0415]\n",
      "Epoch [3/195, loss:0.6878]\n",
      "Epoch [3/196, loss:1.0223]\n",
      "Epoch [3/197, loss:0.5737]\n",
      "Epoch [3/198, loss:1.2129]\n",
      "Epoch [3/199, loss:0.8437]\n",
      "Epoch [3/200, loss:0.6395]\n",
      "Epoch [4/1, loss:0.8513]\n",
      "Epoch [4/2, loss:1.0365]\n",
      "Epoch [4/3, loss:1.0820]\n",
      "Epoch [4/4, loss:0.9600]\n",
      "Epoch [4/5, loss:0.7398]\n",
      "Epoch [4/6, loss:0.8101]\n",
      "Epoch [4/7, loss:0.8801]\n",
      "Epoch [4/8, loss:0.5940]\n",
      "Epoch [4/9, loss:0.6810]\n",
      "Epoch [4/10, loss:0.6945]\n",
      "Epoch [4/11, loss:0.7266]\n",
      "Epoch [4/12, loss:0.7215]\n",
      "Epoch [4/13, loss:2.4994]\n",
      "Epoch [4/14, loss:0.8988]\n",
      "Epoch [4/15, loss:2.0000]\n",
      "Epoch [4/16, loss:0.9132]\n",
      "Epoch [4/17, loss:0.9260]\n",
      "Epoch [4/18, loss:1.2178]\n",
      "Epoch [4/19, loss:0.6332]\n",
      "Epoch [4/20, loss:0.8250]\n",
      "Epoch [4/21, loss:0.5915]\n",
      "Epoch [4/22, loss:0.5623]\n",
      "Epoch [4/23, loss:1.0135]\n",
      "Epoch [4/24, loss:0.8013]\n",
      "Epoch [4/25, loss:0.9862]\n",
      "Epoch [4/26, loss:0.8568]\n",
      "Epoch [4/27, loss:1.4049]\n",
      "Epoch [4/28, loss:0.9921]\n",
      "Epoch [4/29, loss:1.1843]\n",
      "Epoch [4/30, loss:0.7693]\n",
      "Epoch [4/31, loss:0.7483]\n",
      "Epoch [4/32, loss:0.8669]\n",
      "Epoch [4/33, loss:2.8044]\n",
      "Epoch [4/34, loss:0.8281]\n",
      "Epoch [4/35, loss:0.6499]\n",
      "Epoch [4/36, loss:0.8537]\n",
      "Epoch [4/37, loss:1.6557]\n",
      "Epoch [4/38, loss:0.8333]\n",
      "Epoch [4/39, loss:0.7239]\n",
      "Epoch [4/40, loss:0.8554]\n",
      "Epoch [4/41, loss:2.0248]\n",
      "Epoch [4/42, loss:0.8165]\n",
      "Epoch [4/43, loss:0.9892]\n",
      "Epoch [4/44, loss:0.6750]\n",
      "Epoch [4/45, loss:0.8061]\n",
      "Epoch [4/46, loss:0.5267]\n",
      "Epoch [4/47, loss:0.7077]\n",
      "Epoch [4/48, loss:0.5150]\n",
      "Epoch [4/49, loss:1.5203]\n",
      "Epoch [4/50, loss:0.5689]\n",
      "Epoch [4/51, loss:0.7358]\n",
      "Epoch [4/52, loss:0.7629]\n",
      "Epoch [4/53, loss:0.7130]\n",
      "Epoch [4/54, loss:0.5497]\n",
      "Epoch [4/55, loss:2.7023]\n",
      "Epoch [4/56, loss:0.7066]\n",
      "Epoch [4/57, loss:0.8918]\n",
      "Epoch [4/58, loss:0.7794]\n",
      "Epoch [4/59, loss:0.7110]\n",
      "Epoch [4/60, loss:0.5205]\n",
      "Epoch [4/61, loss:0.4819]\n",
      "Epoch [4/62, loss:0.8129]\n",
      "Epoch [4/63, loss:0.7234]\n",
      "Epoch [4/64, loss:0.8386]\n",
      "Epoch [4/65, loss:0.5933]\n",
      "Epoch [4/66, loss:0.9437]\n",
      "Epoch [4/67, loss:1.4577]\n",
      "Epoch [4/68, loss:0.9057]\n",
      "Epoch [4/69, loss:0.8293]\n",
      "Epoch [4/70, loss:1.5027]\n",
      "Epoch [4/71, loss:0.9611]\n",
      "Epoch [4/72, loss:0.7384]\n",
      "Epoch [4/73, loss:0.7932]\n",
      "Epoch [4/74, loss:1.5449]\n",
      "Epoch [4/75, loss:0.4589]\n",
      "Epoch [4/76, loss:0.9614]\n",
      "Epoch [4/77, loss:0.5708]\n",
      "Epoch [4/78, loss:1.1108]\n",
      "Epoch [4/79, loss:1.0934]\n",
      "Epoch [4/80, loss:0.9953]\n",
      "Epoch [4/81, loss:0.8992]\n",
      "Epoch [4/82, loss:0.1477]\n",
      "Epoch [4/83, loss:1.0676]\n",
      "Epoch [4/84, loss:1.1229]\n",
      "Epoch [4/85, loss:0.8177]\n",
      "Epoch [4/86, loss:0.8369]\n",
      "Epoch [4/87, loss:0.8200]\n",
      "Epoch [4/88, loss:0.5907]\n",
      "Epoch [4/89, loss:0.8085]\n",
      "Epoch [4/90, loss:0.5487]\n",
      "Epoch [4/91, loss:0.5558]\n",
      "Epoch [4/92, loss:1.0164]\n",
      "Epoch [4/93, loss:0.8579]\n",
      "Epoch [4/94, loss:0.7535]\n",
      "Epoch [4/95, loss:0.5104]\n",
      "Epoch [4/96, loss:1.1702]\n",
      "Epoch [4/97, loss:0.9143]\n",
      "Epoch [4/98, loss:0.5037]\n",
      "Epoch [4/99, loss:0.6104]\n",
      "Epoch [4/100, loss:0.9334]\n",
      "Epoch [4/101, loss:0.4228]\n",
      "Epoch [4/102, loss:0.1914]\n",
      "Epoch [4/103, loss:0.9232]\n",
      "Epoch [4/104, loss:0.6625]\n",
      "Epoch [4/105, loss:0.8510]\n",
      "Epoch [4/106, loss:0.4867]\n",
      "Epoch [4/107, loss:0.3953]\n",
      "Epoch [4/108, loss:0.5143]\n",
      "Epoch [4/109, loss:0.5541]\n",
      "Epoch [4/110, loss:0.4204]\n",
      "Epoch [4/111, loss:1.3684]\n",
      "Epoch [4/112, loss:1.1144]\n",
      "Epoch [4/113, loss:0.5389]\n",
      "Epoch [4/114, loss:0.8398]\n",
      "Epoch [4/115, loss:1.1307]\n",
      "Epoch [4/116, loss:0.9766]\n",
      "Epoch [4/117, loss:1.2196]\n",
      "Epoch [4/118, loss:0.4506]\n",
      "Epoch [4/119, loss:0.3814]\n",
      "Epoch [4/120, loss:0.8473]\n",
      "Epoch [4/121, loss:0.9243]\n",
      "Epoch [4/122, loss:0.4211]\n",
      "Epoch [4/123, loss:0.8245]\n",
      "Epoch [4/124, loss:1.1478]\n",
      "Epoch [4/125, loss:0.9964]\n",
      "Epoch [4/126, loss:0.8838]\n",
      "Epoch [4/127, loss:0.5583]\n",
      "Epoch [4/128, loss:0.4397]\n",
      "Epoch [4/129, loss:2.0587]\n",
      "Epoch [4/130, loss:0.7580]\n",
      "Epoch [4/131, loss:0.6794]\n",
      "Epoch [4/132, loss:0.7898]\n",
      "Epoch [4/133, loss:0.9059]\n",
      "Epoch [4/134, loss:0.5743]\n",
      "Epoch [4/135, loss:1.2413]\n",
      "Epoch [4/136, loss:0.5853]\n",
      "Epoch [4/137, loss:0.4851]\n",
      "Epoch [4/138, loss:0.7858]\n",
      "Epoch [4/139, loss:0.5265]\n",
      "Epoch [4/140, loss:0.3162]\n",
      "Epoch [4/141, loss:0.7210]\n",
      "Epoch [4/142, loss:0.7510]\n",
      "Epoch [4/143, loss:0.3497]\n",
      "Epoch [4/144, loss:0.2881]\n",
      "Epoch [4/145, loss:0.5398]\n",
      "Epoch [4/146, loss:1.2936]\n",
      "Epoch [4/147, loss:0.7450]\n",
      "Epoch [4/148, loss:0.2384]\n",
      "Epoch [4/149, loss:0.7457]\n",
      "Epoch [4/150, loss:1.0556]\n",
      "Epoch [4/151, loss:0.7917]\n",
      "Epoch [4/152, loss:0.3466]\n",
      "Epoch [4/153, loss:1.5055]\n",
      "Epoch [4/154, loss:0.8772]\n",
      "Epoch [4/155, loss:0.6639]\n",
      "Epoch [4/156, loss:0.9428]\n",
      "Epoch [4/157, loss:0.5353]\n",
      "Epoch [4/158, loss:0.9975]\n",
      "Epoch [4/159, loss:0.8073]\n",
      "Epoch [4/160, loss:0.7853]\n",
      "Epoch [4/161, loss:0.2478]\n",
      "Epoch [4/162, loss:0.6591]\n",
      "Epoch [4/163, loss:0.7262]\n",
      "Epoch [4/164, loss:3.6545]\n",
      "Epoch [4/165, loss:0.7926]\n",
      "Epoch [4/166, loss:0.6748]\n",
      "Epoch [4/167, loss:2.9813]\n",
      "Epoch [4/168, loss:0.7567]\n",
      "Epoch [4/169, loss:1.1119]\n",
      "Epoch [4/170, loss:0.6218]\n",
      "Epoch [4/171, loss:0.7199]\n",
      "Epoch [4/172, loss:3.9657]\n",
      "Epoch [4/173, loss:0.6310]\n",
      "Epoch [4/174, loss:0.3186]\n",
      "Epoch [4/175, loss:0.7795]\n",
      "Epoch [4/176, loss:2.6641]\n",
      "Epoch [4/177, loss:0.9455]\n",
      "Epoch [4/178, loss:0.5295]\n",
      "Epoch [4/179, loss:0.7032]\n",
      "Epoch [4/180, loss:1.0271]\n",
      "Epoch [4/181, loss:0.6931]\n",
      "Epoch [4/182, loss:0.6488]\n",
      "Epoch [4/183, loss:0.7860]\n",
      "Epoch [4/184, loss:0.7220]\n",
      "Epoch [4/185, loss:0.7725]\n",
      "Epoch [4/186, loss:0.7414]\n",
      "Epoch [4/187, loss:0.6955]\n",
      "Epoch [4/188, loss:0.7028]\n",
      "Epoch [4/189, loss:0.7141]\n",
      "Epoch [4/190, loss:1.4097]\n",
      "Epoch [4/191, loss:0.6617]\n",
      "Epoch [4/192, loss:0.7647]\n",
      "Epoch [4/193, loss:0.6631]\n",
      "Epoch [4/194, loss:1.0826]\n",
      "Epoch [4/195, loss:0.6332]\n",
      "Epoch [4/196, loss:0.9154]\n",
      "Epoch [4/197, loss:0.6433]\n",
      "Epoch [4/198, loss:1.0686]\n",
      "Epoch [4/199, loss:0.7261]\n",
      "Epoch [4/200, loss:0.5742]\n",
      "Epoch [5/1, loss:0.6610]\n",
      "Epoch [5/2, loss:0.9157]\n",
      "Epoch [5/3, loss:1.0453]\n",
      "Epoch [5/4, loss:0.8984]\n",
      "Epoch [5/5, loss:0.5979]\n",
      "Epoch [5/6, loss:0.6895]\n",
      "Epoch [5/7, loss:0.9233]\n",
      "Epoch [5/8, loss:0.4724]\n",
      "Epoch [5/9, loss:0.6185]\n",
      "Epoch [5/10, loss:0.5740]\n",
      "Epoch [5/11, loss:0.5485]\n",
      "Epoch [5/12, loss:0.6124]\n",
      "Epoch [5/13, loss:2.7419]\n",
      "Epoch [5/14, loss:0.8116]\n",
      "Epoch [5/15, loss:2.0688]\n",
      "Epoch [5/16, loss:0.9449]\n",
      "Epoch [5/17, loss:1.0641]\n",
      "Epoch [5/18, loss:1.1991]\n",
      "Epoch [5/19, loss:0.5758]\n",
      "Epoch [5/20, loss:0.8112]\n",
      "Epoch [5/21, loss:0.5548]\n",
      "Epoch [5/22, loss:0.4413]\n",
      "Epoch [5/23, loss:1.0436]\n",
      "Epoch [5/24, loss:0.7679]\n",
      "Epoch [5/25, loss:1.1391]\n",
      "Epoch [5/26, loss:0.6081]\n",
      "Epoch [5/27, loss:1.0977]\n",
      "Epoch [5/28, loss:1.1538]\n",
      "Epoch [5/29, loss:0.8978]\n",
      "Epoch [5/30, loss:0.6403]\n",
      "Epoch [5/31, loss:0.7970]\n",
      "Epoch [5/32, loss:0.9836]\n",
      "Epoch [5/33, loss:2.9155]\n",
      "Epoch [5/34, loss:0.7929]\n",
      "Epoch [5/35, loss:0.5642]\n",
      "Epoch [5/36, loss:0.9600]\n",
      "Epoch [5/37, loss:1.7262]\n",
      "Epoch [5/38, loss:0.8314]\n",
      "Epoch [5/39, loss:0.6625]\n",
      "Epoch [5/40, loss:0.8279]\n",
      "Epoch [5/41, loss:2.0262]\n",
      "Epoch [5/42, loss:0.7225]\n",
      "Epoch [5/43, loss:1.0054]\n",
      "Epoch [5/44, loss:0.7140]\n",
      "Epoch [5/45, loss:0.8648]\n",
      "Epoch [5/46, loss:0.5286]\n",
      "Epoch [5/47, loss:0.5926]\n",
      "Epoch [5/48, loss:0.5142]\n",
      "Epoch [5/49, loss:1.4464]\n",
      "Epoch [5/50, loss:0.5740]\n",
      "Epoch [5/51, loss:0.6470]\n",
      "Epoch [5/52, loss:0.7177]\n",
      "Epoch [5/53, loss:0.7154]\n",
      "Epoch [5/54, loss:0.5436]\n",
      "Epoch [5/55, loss:2.8517]\n",
      "Epoch [5/56, loss:0.6440]\n",
      "Epoch [5/57, loss:0.7851]\n",
      "Epoch [5/58, loss:0.7141]\n",
      "Epoch [5/59, loss:0.6535]\n",
      "Epoch [5/60, loss:0.4931]\n",
      "Epoch [5/61, loss:0.4132]\n",
      "Epoch [5/62, loss:0.7317]\n",
      "Epoch [5/63, loss:0.7188]\n",
      "Epoch [5/64, loss:0.7406]\n",
      "Epoch [5/65, loss:0.5473]\n",
      "Epoch [5/66, loss:0.8986]\n",
      "Epoch [5/67, loss:1.3427]\n",
      "Epoch [5/68, loss:0.8453]\n",
      "Epoch [5/69, loss:0.7654]\n",
      "Epoch [5/70, loss:1.6326]\n",
      "Epoch [5/71, loss:0.9172]\n",
      "Epoch [5/72, loss:0.7952]\n",
      "Epoch [5/73, loss:0.8145]\n",
      "Epoch [5/74, loss:1.6628]\n",
      "Epoch [5/75, loss:0.4223]\n",
      "Epoch [5/76, loss:0.8922]\n",
      "Epoch [5/77, loss:0.4938]\n",
      "Epoch [5/78, loss:1.1950]\n",
      "Epoch [5/79, loss:1.1247]\n",
      "Epoch [5/80, loss:0.8716]\n",
      "Epoch [5/81, loss:0.8537]\n",
      "Epoch [5/82, loss:0.1063]\n",
      "Epoch [5/83, loss:1.0900]\n",
      "Epoch [5/84, loss:0.9980]\n",
      "Epoch [5/85, loss:0.6845]\n",
      "Epoch [5/86, loss:0.7646]\n",
      "Epoch [5/87, loss:0.7185]\n",
      "Epoch [5/88, loss:0.5686]\n",
      "Epoch [5/89, loss:0.9077]\n",
      "Epoch [5/90, loss:0.4876]\n",
      "Epoch [5/91, loss:0.5383]\n",
      "Epoch [5/92, loss:1.0602]\n",
      "Epoch [5/93, loss:0.8424]\n",
      "Epoch [5/94, loss:0.7660]\n",
      "Epoch [5/95, loss:0.5021]\n",
      "Epoch [5/96, loss:1.1941]\n",
      "Epoch [5/97, loss:0.9015]\n",
      "Epoch [5/98, loss:0.5197]\n",
      "Epoch [5/99, loss:0.6014]\n",
      "Epoch [5/100, loss:0.9333]\n",
      "Epoch [5/101, loss:0.3563]\n",
      "Epoch [5/102, loss:0.1472]\n",
      "Epoch [5/103, loss:0.9084]\n",
      "Epoch [5/104, loss:0.6499]\n",
      "Epoch [5/105, loss:0.7697]\n",
      "Epoch [5/106, loss:0.4352]\n",
      "Epoch [5/107, loss:0.3216]\n",
      "Epoch [5/108, loss:0.4700]\n",
      "Epoch [5/109, loss:0.5884]\n",
      "Epoch [5/110, loss:0.4206]\n",
      "Epoch [5/111, loss:1.5173]\n",
      "Epoch [5/112, loss:1.1352]\n",
      "Epoch [5/113, loss:0.5290]\n",
      "Epoch [5/114, loss:0.8386]\n",
      "Epoch [5/115, loss:1.0574]\n",
      "Epoch [5/116, loss:0.9326]\n",
      "Epoch [5/117, loss:1.2851]\n",
      "Epoch [5/118, loss:0.4630]\n",
      "Epoch [5/119, loss:0.3731]\n",
      "Epoch [5/120, loss:0.7811]\n",
      "Epoch [5/121, loss:0.8996]\n",
      "Epoch [5/122, loss:0.3756]\n",
      "Epoch [5/123, loss:0.7342]\n",
      "Epoch [5/124, loss:1.1588]\n",
      "Epoch [5/125, loss:0.9946]\n",
      "Epoch [5/126, loss:0.8378]\n",
      "Epoch [5/127, loss:0.5305]\n",
      "Epoch [5/128, loss:0.3847]\n",
      "Epoch [5/129, loss:2.2299]\n",
      "Epoch [5/130, loss:0.6825]\n",
      "Epoch [5/131, loss:0.6765]\n",
      "Epoch [5/132, loss:0.6767]\n",
      "Epoch [5/133, loss:0.9050]\n",
      "Epoch [5/134, loss:0.5713]\n",
      "Epoch [5/135, loss:1.2786]\n",
      "Epoch [5/136, loss:0.5383]\n",
      "Epoch [5/137, loss:0.4990]\n",
      "Epoch [5/138, loss:0.8348]\n",
      "Epoch [5/139, loss:0.5496]\n",
      "Epoch [5/140, loss:0.2861]\n",
      "Epoch [5/141, loss:0.6415]\n",
      "Epoch [5/142, loss:0.7849]\n",
      "Epoch [5/143, loss:0.3354]\n",
      "Epoch [5/144, loss:0.2560]\n",
      "Epoch [5/145, loss:0.5053]\n",
      "Epoch [5/146, loss:1.0629]\n",
      "Epoch [5/147, loss:0.6691]\n",
      "Epoch [5/148, loss:0.2198]\n",
      "Epoch [5/149, loss:0.6697]\n",
      "Epoch [5/150, loss:1.0473]\n",
      "Epoch [5/151, loss:0.7314]\n",
      "Epoch [5/152, loss:0.3571]\n",
      "Epoch [5/153, loss:1.1784]\n",
      "Epoch [5/154, loss:0.9075]\n",
      "Epoch [5/155, loss:0.6668]\n",
      "Epoch [5/156, loss:0.9887]\n",
      "Epoch [5/157, loss:0.4904]\n",
      "Epoch [5/158, loss:0.9516]\n",
      "Epoch [5/159, loss:0.7073]\n",
      "Epoch [5/160, loss:0.7434]\n",
      "Epoch [5/161, loss:0.2404]\n",
      "Epoch [5/162, loss:0.6446]\n",
      "Epoch [5/163, loss:0.6043]\n",
      "Epoch [5/164, loss:3.2702]\n",
      "Epoch [5/165, loss:0.7151]\n",
      "Epoch [5/166, loss:0.5613]\n",
      "Epoch [5/167, loss:2.8675]\n",
      "Epoch [5/168, loss:0.6754]\n",
      "Epoch [5/169, loss:1.0218]\n",
      "Epoch [5/170, loss:0.6811]\n",
      "Epoch [5/171, loss:0.6293]\n",
      "Epoch [5/172, loss:3.8014]\n",
      "Epoch [5/173, loss:0.6201]\n",
      "Epoch [5/174, loss:0.3178]\n",
      "Epoch [5/175, loss:0.7653]\n",
      "Epoch [5/176, loss:2.6121]\n",
      "Epoch [5/177, loss:0.9128]\n",
      "Epoch [5/178, loss:0.4932]\n",
      "Epoch [5/179, loss:0.7901]\n",
      "Epoch [5/180, loss:1.1045]\n",
      "Epoch [5/181, loss:0.6189]\n",
      "Epoch [5/182, loss:0.5583]\n",
      "Epoch [5/183, loss:0.7461]\n",
      "Epoch [5/184, loss:0.7642]\n",
      "Epoch [5/185, loss:0.6993]\n",
      "Epoch [5/186, loss:0.7155]\n",
      "Epoch [5/187, loss:0.6143]\n",
      "Epoch [5/188, loss:0.6466]\n",
      "Epoch [5/189, loss:0.6406]\n",
      "Epoch [5/190, loss:1.3829]\n",
      "Epoch [5/191, loss:0.5749]\n",
      "Epoch [5/192, loss:0.6452]\n",
      "Epoch [5/193, loss:0.5989]\n",
      "Epoch [5/194, loss:1.1310]\n",
      "Epoch [5/195, loss:0.5343]\n",
      "Epoch [5/196, loss:0.9078]\n",
      "Epoch [5/197, loss:0.6638]\n",
      "Epoch [5/198, loss:0.9967]\n",
      "Epoch [5/199, loss:0.6931]\n",
      "Epoch [5/200, loss:0.4947]\n",
      "Epoch [6/1, loss:0.5752]\n",
      "Epoch [6/2, loss:0.8958]\n",
      "Epoch [6/3, loss:1.0590]\n",
      "Epoch [6/4, loss:0.8187]\n",
      "Epoch [6/5, loss:0.5347]\n",
      "Epoch [6/6, loss:0.6539]\n",
      "Epoch [6/7, loss:0.9568]\n",
      "Epoch [6/8, loss:0.3535]\n",
      "Epoch [6/9, loss:0.5715]\n",
      "Epoch [6/10, loss:0.5336]\n",
      "Epoch [6/11, loss:0.4728]\n",
      "Epoch [6/12, loss:0.5970]\n",
      "Epoch [6/13, loss:2.7272]\n",
      "Epoch [6/14, loss:0.6967]\n",
      "Epoch [6/15, loss:1.9349]\n",
      "Epoch [6/16, loss:0.9538]\n",
      "Epoch [6/17, loss:1.1235]\n",
      "Epoch [6/18, loss:1.1061]\n",
      "Epoch [6/19, loss:0.5278]\n",
      "Epoch [6/20, loss:0.7634]\n",
      "Epoch [6/21, loss:0.5034]\n",
      "Epoch [6/22, loss:0.3953]\n",
      "Epoch [6/23, loss:1.0492]\n",
      "Epoch [6/24, loss:0.7031]\n",
      "Epoch [6/25, loss:1.2045]\n",
      "Epoch [6/26, loss:0.4922]\n",
      "Epoch [6/27, loss:0.9093]\n",
      "Epoch [6/28, loss:1.2264]\n",
      "Epoch [6/29, loss:0.7395]\n",
      "Epoch [6/30, loss:0.5962]\n",
      "Epoch [6/31, loss:0.7295]\n",
      "Epoch [6/32, loss:1.0019]\n",
      "Epoch [6/33, loss:2.9930]\n",
      "Epoch [6/34, loss:0.7288]\n",
      "Epoch [6/35, loss:0.4813]\n",
      "Epoch [6/36, loss:0.9986]\n",
      "Epoch [6/37, loss:1.8499]\n",
      "Epoch [6/38, loss:0.8325]\n",
      "Epoch [6/39, loss:0.5646]\n",
      "Epoch [6/40, loss:0.7770]\n",
      "Epoch [6/41, loss:1.9960]\n",
      "Epoch [6/42, loss:0.6615]\n",
      "Epoch [6/43, loss:1.0613]\n",
      "Epoch [6/44, loss:0.7061]\n",
      "Epoch [6/45, loss:0.8777]\n",
      "Epoch [6/46, loss:0.4863]\n",
      "Epoch [6/47, loss:0.5429]\n",
      "Epoch [6/48, loss:0.4767]\n",
      "Epoch [6/49, loss:1.4094]\n",
      "Epoch [6/50, loss:0.5471]\n",
      "Epoch [6/51, loss:0.6033]\n",
      "Epoch [6/52, loss:0.6590]\n",
      "Epoch [6/53, loss:0.7302]\n",
      "Epoch [6/54, loss:0.5229]\n",
      "Epoch [6/55, loss:2.9451]\n",
      "Epoch [6/56, loss:0.5623]\n",
      "Epoch [6/57, loss:0.6856]\n",
      "Epoch [6/58, loss:0.6310]\n",
      "Epoch [6/59, loss:0.5765]\n",
      "Epoch [6/60, loss:0.4600]\n",
      "Epoch [6/61, loss:0.3467]\n",
      "Epoch [6/62, loss:0.6907]\n",
      "Epoch [6/63, loss:0.6935]\n",
      "Epoch [6/64, loss:0.6974]\n",
      "Epoch [6/65, loss:0.5142]\n",
      "Epoch [6/66, loss:0.8577]\n",
      "Epoch [6/67, loss:1.2070]\n",
      "Epoch [6/68, loss:0.7921]\n",
      "Epoch [6/69, loss:0.7391]\n",
      "Epoch [6/70, loss:1.7031]\n",
      "Epoch [6/71, loss:0.8763]\n",
      "Epoch [6/72, loss:0.8467]\n",
      "Epoch [6/73, loss:0.8534]\n",
      "Epoch [6/74, loss:1.7310]\n",
      "Epoch [6/75, loss:0.3927]\n",
      "Epoch [6/76, loss:0.8421]\n",
      "Epoch [6/77, loss:0.3981]\n",
      "Epoch [6/78, loss:1.3390]\n",
      "Epoch [6/79, loss:1.1221]\n",
      "Epoch [6/80, loss:0.7385]\n",
      "Epoch [6/81, loss:0.8275]\n",
      "Epoch [6/82, loss:0.0791]\n",
      "Epoch [6/83, loss:1.1071]\n",
      "Epoch [6/84, loss:0.8627]\n",
      "Epoch [6/85, loss:0.5419]\n",
      "Epoch [6/86, loss:0.7210]\n",
      "Epoch [6/87, loss:0.5984]\n",
      "Epoch [6/88, loss:0.5244]\n",
      "Epoch [6/89, loss:1.0414]\n",
      "Epoch [6/90, loss:0.4129]\n",
      "Epoch [6/91, loss:0.5254]\n",
      "Epoch [6/92, loss:1.0546]\n",
      "Epoch [6/93, loss:0.8374]\n",
      "Epoch [6/94, loss:0.7681]\n",
      "Epoch [6/95, loss:0.4955]\n",
      "Epoch [6/96, loss:1.2297]\n",
      "Epoch [6/97, loss:0.9111]\n",
      "Epoch [6/98, loss:0.5286]\n",
      "Epoch [6/99, loss:0.5672]\n",
      "Epoch [6/100, loss:0.9701]\n",
      "Epoch [6/101, loss:0.2740]\n",
      "Epoch [6/102, loss:0.1137]\n",
      "Epoch [6/103, loss:0.9145]\n",
      "Epoch [6/104, loss:0.6267]\n",
      "Epoch [6/105, loss:0.6765]\n",
      "Epoch [6/106, loss:0.3680]\n",
      "Epoch [6/107, loss:0.2332]\n",
      "Epoch [6/108, loss:0.4051]\n",
      "Epoch [6/109, loss:0.6753]\n",
      "Epoch [6/110, loss:0.4101]\n",
      "Epoch [6/111, loss:1.7485]\n",
      "Epoch [6/112, loss:1.1792]\n",
      "Epoch [6/113, loss:0.4975]\n",
      "Epoch [6/114, loss:0.8502]\n",
      "Epoch [6/115, loss:0.9814]\n",
      "Epoch [6/116, loss:0.8988]\n",
      "Epoch [6/117, loss:1.3576]\n",
      "Epoch [6/118, loss:0.4723]\n",
      "Epoch [6/119, loss:0.3599]\n",
      "Epoch [6/120, loss:0.7280]\n",
      "Epoch [6/121, loss:0.8410]\n",
      "Epoch [6/122, loss:0.3231]\n",
      "Epoch [6/123, loss:0.6269]\n",
      "Epoch [6/124, loss:1.1157]\n",
      "Epoch [6/125, loss:0.9721]\n",
      "Epoch [6/126, loss:0.7736]\n",
      "Epoch [6/127, loss:0.4984]\n",
      "Epoch [6/128, loss:0.3187]\n",
      "Epoch [6/129, loss:2.3811]\n",
      "Epoch [6/130, loss:0.6411]\n",
      "Epoch [6/131, loss:0.6584]\n",
      "Epoch [6/132, loss:0.6110]\n",
      "Epoch [6/133, loss:0.9183]\n",
      "Epoch [6/134, loss:0.5817]\n",
      "Epoch [6/135, loss:1.3367]\n",
      "Epoch [6/136, loss:0.4755]\n",
      "Epoch [6/137, loss:0.5006]\n",
      "Epoch [6/138, loss:0.8870]\n",
      "Epoch [6/139, loss:0.5591]\n",
      "Epoch [6/140, loss:0.2522]\n",
      "Epoch [6/141, loss:0.6007]\n",
      "Epoch [6/142, loss:0.8055]\n",
      "Epoch [6/143, loss:0.3147]\n",
      "Epoch [6/144, loss:0.2212]\n",
      "Epoch [6/145, loss:0.4613]\n",
      "Epoch [6/146, loss:0.9238]\n",
      "Epoch [6/147, loss:0.6240]\n",
      "Epoch [6/148, loss:0.2009]\n",
      "Epoch [6/149, loss:0.6233]\n",
      "Epoch [6/150, loss:0.9551]\n",
      "Epoch [6/151, loss:0.6754]\n",
      "Epoch [6/152, loss:0.3612]\n",
      "Epoch [6/153, loss:0.9291]\n",
      "Epoch [6/154, loss:0.9052]\n",
      "Epoch [6/155, loss:0.6615]\n",
      "Epoch [6/156, loss:1.0616]\n",
      "Epoch [6/157, loss:0.4226]\n",
      "Epoch [6/158, loss:0.9261]\n",
      "Epoch [6/159, loss:0.6629]\n",
      "Epoch [6/160, loss:0.6829]\n",
      "Epoch [6/161, loss:0.2284]\n",
      "Epoch [6/162, loss:0.6175]\n",
      "Epoch [6/163, loss:0.5350]\n",
      "Epoch [6/164, loss:2.8094]\n",
      "Epoch [6/165, loss:0.6390]\n",
      "Epoch [6/166, loss:0.4355]\n",
      "Epoch [6/167, loss:2.7163]\n",
      "Epoch [6/168, loss:0.5375]\n",
      "Epoch [6/169, loss:0.9497]\n",
      "Epoch [6/170, loss:0.7234]\n",
      "Epoch [6/171, loss:0.5737]\n",
      "Epoch [6/172, loss:3.5526]\n",
      "Epoch [6/173, loss:0.6027]\n",
      "Epoch [6/174, loss:0.3097]\n",
      "Epoch [6/175, loss:0.7579]\n",
      "Epoch [6/176, loss:2.5490]\n",
      "Epoch [6/177, loss:0.9010]\n",
      "Epoch [6/178, loss:0.4496]\n",
      "Epoch [6/179, loss:0.8470]\n",
      "Epoch [6/180, loss:1.1333]\n",
      "Epoch [6/181, loss:0.5237]\n",
      "Epoch [6/182, loss:0.4481]\n",
      "Epoch [6/183, loss:0.7297]\n",
      "Epoch [6/184, loss:0.8349]\n",
      "Epoch [6/185, loss:0.6474]\n",
      "Epoch [6/186, loss:0.7026]\n",
      "Epoch [6/187, loss:0.5319]\n",
      "Epoch [6/188, loss:0.6014]\n",
      "Epoch [6/189, loss:0.5984]\n",
      "Epoch [6/190, loss:1.3614]\n",
      "Epoch [6/191, loss:0.5309]\n",
      "Epoch [6/192, loss:0.5787]\n",
      "Epoch [6/193, loss:0.4980]\n",
      "Epoch [6/194, loss:1.1566]\n",
      "Epoch [6/195, loss:0.3749]\n",
      "Epoch [6/196, loss:0.9201]\n",
      "Epoch [6/197, loss:0.6656]\n",
      "Epoch [6/198, loss:0.9650]\n",
      "Epoch [6/199, loss:0.6926]\n",
      "Epoch [6/200, loss:0.3900]\n",
      "Epoch [7/1, loss:0.5302]\n",
      "Epoch [7/2, loss:0.8855]\n",
      "Epoch [7/3, loss:1.1123]\n",
      "Epoch [7/4, loss:0.7408]\n",
      "Epoch [7/5, loss:0.4989]\n",
      "Epoch [7/6, loss:0.6400]\n",
      "Epoch [7/7, loss:0.9534]\n",
      "Epoch [7/8, loss:0.2362]\n",
      "Epoch [7/9, loss:0.5417]\n",
      "Epoch [7/10, loss:0.5067]\n",
      "Epoch [7/11, loss:0.4311]\n",
      "Epoch [7/12, loss:0.5964]\n",
      "Epoch [7/13, loss:2.6334]\n",
      "Epoch [7/14, loss:0.5860]\n",
      "Epoch [7/15, loss:1.7722]\n",
      "Epoch [7/16, loss:0.9080]\n",
      "Epoch [7/17, loss:1.1672]\n",
      "Epoch [7/18, loss:1.0046]\n",
      "Epoch [7/19, loss:0.4816]\n",
      "Epoch [7/20, loss:0.6560]\n",
      "Epoch [7/21, loss:0.4287]\n",
      "Epoch [7/22, loss:0.3694]\n",
      "Epoch [7/23, loss:1.0050]\n",
      "Epoch [7/24, loss:0.5876]\n",
      "Epoch [7/25, loss:1.2451]\n",
      "Epoch [7/26, loss:0.4274]\n",
      "Epoch [7/27, loss:0.7757]\n",
      "Epoch [7/28, loss:1.2718]\n",
      "Epoch [7/29, loss:0.6446]\n",
      "Epoch [7/30, loss:0.5764]\n",
      "Epoch [7/31, loss:0.6620]\n",
      "Epoch [7/32, loss:1.0046]\n",
      "Epoch [7/33, loss:3.0113]\n",
      "Epoch [7/34, loss:0.6152]\n",
      "Epoch [7/35, loss:0.3926]\n",
      "Epoch [7/36, loss:1.0298]\n",
      "Epoch [7/37, loss:2.0220]\n",
      "Epoch [7/38, loss:0.8444]\n",
      "Epoch [7/39, loss:0.4261]\n",
      "Epoch [7/40, loss:0.6755]\n",
      "Epoch [7/41, loss:1.9743]\n",
      "Epoch [7/42, loss:0.6337]\n",
      "Epoch [7/43, loss:1.1472]\n",
      "Epoch [7/44, loss:0.6993]\n",
      "Epoch [7/45, loss:0.8785]\n",
      "Epoch [7/46, loss:0.4502]\n",
      "Epoch [7/47, loss:0.5184]\n",
      "Epoch [7/48, loss:0.4448]\n",
      "Epoch [7/49, loss:1.3666]\n",
      "Epoch [7/50, loss:0.5232]\n",
      "Epoch [7/51, loss:0.5714]\n",
      "Epoch [7/52, loss:0.5646]\n",
      "Epoch [7/53, loss:0.7825]\n",
      "Epoch [7/54, loss:0.5073]\n",
      "Epoch [7/55, loss:2.9761]\n",
      "Epoch [7/56, loss:0.4501]\n",
      "Epoch [7/57, loss:0.5756]\n",
      "Epoch [7/58, loss:0.5093]\n",
      "Epoch [7/59, loss:0.4654]\n",
      "Epoch [7/60, loss:0.4340]\n",
      "Epoch [7/61, loss:0.2915]\n",
      "Epoch [7/62, loss:0.6633]\n",
      "Epoch [7/63, loss:0.6386]\n",
      "Epoch [7/64, loss:0.6834]\n",
      "Epoch [7/65, loss:0.5025]\n",
      "Epoch [7/66, loss:0.8071]\n",
      "Epoch [7/67, loss:1.0631]\n",
      "Epoch [7/68, loss:0.7156]\n",
      "Epoch [7/69, loss:0.7289]\n",
      "Epoch [7/70, loss:1.7770]\n",
      "Epoch [7/71, loss:0.8184]\n",
      "Epoch [7/72, loss:0.8998]\n",
      "Epoch [7/73, loss:0.8980]\n",
      "Epoch [7/74, loss:1.7505]\n",
      "Epoch [7/75, loss:0.3708]\n",
      "Epoch [7/76, loss:0.7903]\n",
      "Epoch [7/77, loss:0.2854]\n",
      "Epoch [7/78, loss:1.5486]\n",
      "Epoch [7/79, loss:1.0286]\n",
      "Epoch [7/80, loss:0.5909]\n",
      "Epoch [7/81, loss:0.8055]\n",
      "Epoch [7/82, loss:0.0633]\n",
      "Epoch [7/83, loss:1.1070]\n",
      "Epoch [7/84, loss:0.7150]\n",
      "Epoch [7/85, loss:0.3842]\n",
      "Epoch [7/86, loss:0.6900]\n",
      "Epoch [7/87, loss:0.4552]\n",
      "Epoch [7/88, loss:0.4549]\n",
      "Epoch [7/89, loss:1.2366]\n",
      "Epoch [7/90, loss:0.3221]\n",
      "Epoch [7/91, loss:0.5157]\n",
      "Epoch [7/92, loss:0.9808]\n",
      "Epoch [7/93, loss:0.8322]\n",
      "Epoch [7/94, loss:0.7653]\n",
      "Epoch [7/95, loss:0.5057]\n",
      "Epoch [7/96, loss:1.2586]\n",
      "Epoch [7/97, loss:0.9417]\n",
      "Epoch [7/98, loss:0.5382]\n",
      "Epoch [7/99, loss:0.5014]\n",
      "Epoch [7/100, loss:1.0494]\n",
      "Epoch [7/101, loss:0.1869]\n",
      "Epoch [7/102, loss:0.0910]\n",
      "Epoch [7/103, loss:0.9372]\n",
      "Epoch [7/104, loss:0.5848]\n",
      "Epoch [7/105, loss:0.5625]\n",
      "Epoch [7/106, loss:0.2861]\n",
      "Epoch [7/107, loss:0.1455]\n",
      "Epoch [7/108, loss:0.3205]\n",
      "Epoch [7/109, loss:0.8559]\n",
      "Epoch [7/110, loss:0.3970]\n",
      "Epoch [7/111, loss:2.0583]\n",
      "Epoch [7/112, loss:1.2370]\n",
      "Epoch [7/113, loss:0.4485]\n",
      "Epoch [7/114, loss:0.8704]\n",
      "Epoch [7/115, loss:0.9033]\n",
      "Epoch [7/116, loss:0.8709]\n",
      "Epoch [7/117, loss:1.4045]\n",
      "Epoch [7/118, loss:0.4810]\n",
      "Epoch [7/119, loss:0.3457]\n",
      "Epoch [7/120, loss:0.6834]\n",
      "Epoch [7/121, loss:0.7168]\n",
      "Epoch [7/122, loss:0.2665]\n",
      "Epoch [7/123, loss:0.5018]\n",
      "Epoch [7/124, loss:0.9737]\n",
      "Epoch [7/125, loss:0.9060]\n",
      "Epoch [7/126, loss:0.6785]\n",
      "Epoch [7/127, loss:0.4597]\n",
      "Epoch [7/128, loss:0.2456]\n",
      "Epoch [7/129, loss:2.5579]\n",
      "Epoch [7/130, loss:0.6155]\n",
      "Epoch [7/131, loss:0.6162]\n",
      "Epoch [7/132, loss:0.5699]\n",
      "Epoch [7/133, loss:0.9373]\n",
      "Epoch [7/134, loss:0.6127]\n",
      "Epoch [7/135, loss:1.3930]\n",
      "Epoch [7/136, loss:0.3926]\n",
      "Epoch [7/137, loss:0.4987]\n",
      "Epoch [7/138, loss:0.9383]\n",
      "Epoch [7/139, loss:0.5639]\n",
      "Epoch [7/140, loss:0.2245]\n",
      "Epoch [7/141, loss:0.5786]\n",
      "Epoch [7/142, loss:0.8071]\n",
      "Epoch [7/143, loss:0.2970]\n",
      "Epoch [7/144, loss:0.1926]\n",
      "Epoch [7/145, loss:0.4045]\n",
      "Epoch [7/146, loss:0.8269]\n",
      "Epoch [7/147, loss:0.5971]\n",
      "Epoch [7/148, loss:0.1874]\n",
      "Epoch [7/149, loss:0.5953]\n",
      "Epoch [7/150, loss:0.7576]\n",
      "Epoch [7/151, loss:0.6168]\n",
      "Epoch [7/152, loss:0.3643]\n",
      "Epoch [7/153, loss:0.7623]\n",
      "Epoch [7/154, loss:0.8539]\n",
      "Epoch [7/155, loss:0.6414]\n",
      "Epoch [7/156, loss:1.1764]\n",
      "Epoch [7/157, loss:0.3300]\n",
      "Epoch [7/158, loss:0.9129]\n",
      "Epoch [7/159, loss:0.6439]\n",
      "Epoch [7/160, loss:0.5994]\n",
      "Epoch [7/161, loss:0.2173]\n",
      "Epoch [7/162, loss:0.5747]\n",
      "Epoch [7/163, loss:0.4907]\n",
      "Epoch [7/164, loss:2.3259]\n",
      "Epoch [7/165, loss:0.5570]\n",
      "Epoch [7/166, loss:0.3072]\n",
      "Epoch [7/167, loss:2.5535]\n",
      "Epoch [7/168, loss:0.3632]\n",
      "Epoch [7/169, loss:0.8840]\n",
      "Epoch [7/170, loss:0.7462]\n",
      "Epoch [7/171, loss:0.5387]\n",
      "Epoch [7/172, loss:3.2560]\n",
      "Epoch [7/173, loss:0.5701]\n",
      "Epoch [7/174, loss:0.2997]\n",
      "Epoch [7/175, loss:0.7624]\n",
      "Epoch [7/176, loss:2.4455]\n",
      "Epoch [7/177, loss:0.8975]\n",
      "Epoch [7/178, loss:0.3982]\n",
      "Epoch [7/179, loss:0.8685]\n",
      "Epoch [7/180, loss:1.1131]\n",
      "Epoch [7/181, loss:0.4111]\n",
      "Epoch [7/182, loss:0.3300]\n",
      "Epoch [7/183, loss:0.7247]\n",
      "Epoch [7/184, loss:0.9289]\n",
      "Epoch [7/185, loss:0.6118]\n",
      "Epoch [7/186, loss:0.7065]\n",
      "Epoch [7/187, loss:0.4470]\n",
      "Epoch [7/188, loss:0.5735]\n",
      "Epoch [7/189, loss:0.5667]\n",
      "Epoch [7/190, loss:1.3621]\n",
      "Epoch [7/191, loss:0.5444]\n",
      "Epoch [7/192, loss:0.5472]\n",
      "Epoch [7/193, loss:0.3671]\n",
      "Epoch [7/194, loss:1.1249]\n",
      "Epoch [7/195, loss:0.2046]\n",
      "Epoch [7/196, loss:0.9332]\n",
      "Epoch [7/197, loss:0.6650]\n",
      "Epoch [7/198, loss:0.9791]\n",
      "Epoch [7/199, loss:0.7066]\n",
      "Epoch [7/200, loss:0.2759]\n",
      "Epoch [8/1, loss:0.5058]\n",
      "Epoch [8/2, loss:0.8718]\n",
      "Epoch [8/3, loss:1.2705]\n",
      "Epoch [8/4, loss:0.6700]\n",
      "Epoch [8/5, loss:0.4763]\n",
      "Epoch [8/6, loss:0.6336]\n",
      "Epoch [8/7, loss:0.9010]\n",
      "Epoch [8/8, loss:0.1418]\n",
      "Epoch [8/9, loss:0.5336]\n",
      "Epoch [8/10, loss:0.4874]\n",
      "Epoch [8/11, loss:0.4073]\n",
      "Epoch [8/12, loss:0.6015]\n",
      "Epoch [8/13, loss:2.5116]\n",
      "Epoch [8/14, loss:0.4827]\n",
      "Epoch [8/15, loss:1.5727]\n",
      "Epoch [8/16, loss:0.7992]\n",
      "Epoch [8/17, loss:1.1943]\n",
      "Epoch [8/18, loss:0.9109]\n",
      "Epoch [8/19, loss:0.4264]\n",
      "Epoch [8/20, loss:0.4978]\n",
      "Epoch [8/21, loss:0.3310]\n",
      "Epoch [8/22, loss:0.3566]\n",
      "Epoch [8/23, loss:0.9013]\n",
      "Epoch [8/24, loss:0.4379]\n",
      "Epoch [8/25, loss:1.2585]\n",
      "Epoch [8/26, loss:0.3877]\n",
      "Epoch [8/27, loss:0.6536]\n",
      "Epoch [8/28, loss:1.2846]\n",
      "Epoch [8/29, loss:0.5747]\n",
      "Epoch [8/30, loss:0.5504]\n",
      "Epoch [8/31, loss:0.5954]\n",
      "Epoch [8/32, loss:0.9892]\n",
      "Epoch [8/33, loss:2.9571]\n",
      "Epoch [8/34, loss:0.4729]\n",
      "Epoch [8/35, loss:0.3023]\n",
      "Epoch [8/36, loss:1.0503]\n",
      "Epoch [8/37, loss:2.2589]\n",
      "Epoch [8/38, loss:0.8884]\n",
      "Epoch [8/39, loss:0.2841]\n",
      "Epoch [8/40, loss:0.5391]\n",
      "Epoch [8/41, loss:1.9038]\n",
      "Epoch [8/42, loss:0.6391]\n",
      "Epoch [8/43, loss:1.2712]\n",
      "Epoch [8/44, loss:0.6879]\n",
      "Epoch [8/45, loss:0.8664]\n",
      "Epoch [8/46, loss:0.4147]\n",
      "Epoch [8/47, loss:0.5074]\n",
      "Epoch [8/48, loss:0.4147]\n",
      "Epoch [8/49, loss:1.3124]\n",
      "Epoch [8/50, loss:0.4987]\n",
      "Epoch [8/51, loss:0.5486]\n",
      "Epoch [8/52, loss:0.4546]\n",
      "Epoch [8/53, loss:0.9027]\n",
      "Epoch [8/54, loss:0.4925]\n",
      "Epoch [8/55, loss:2.9479]\n",
      "Epoch [8/56, loss:0.3312]\n",
      "Epoch [8/57, loss:0.4609]\n",
      "Epoch [8/58, loss:0.3749]\n",
      "Epoch [8/59, loss:0.3455]\n",
      "Epoch [8/60, loss:0.4108]\n",
      "Epoch [8/61, loss:0.2590]\n",
      "Epoch [8/62, loss:0.6425]\n",
      "Epoch [8/63, loss:0.5701]\n",
      "Epoch [8/64, loss:0.6844]\n",
      "Epoch [8/65, loss:0.5188]\n",
      "Epoch [8/66, loss:0.7375]\n",
      "Epoch [8/67, loss:0.9194]\n",
      "Epoch [8/68, loss:0.6023]\n",
      "Epoch [8/69, loss:0.7286]\n",
      "Epoch [8/70, loss:1.9233]\n",
      "Epoch [8/71, loss:0.7270]\n",
      "Epoch [8/72, loss:0.9491]\n",
      "Epoch [8/73, loss:0.9401]\n",
      "Epoch [8/74, loss:1.7388]\n",
      "Epoch [8/75, loss:0.3512]\n",
      "Epoch [8/76, loss:0.7116]\n",
      "Epoch [8/77, loss:0.1854]\n",
      "Epoch [8/78, loss:1.7972]\n",
      "Epoch [8/79, loss:0.8413]\n",
      "Epoch [8/80, loss:0.4492]\n",
      "Epoch [8/81, loss:0.7888]\n",
      "Epoch [8/82, loss:0.0529]\n",
      "Epoch [8/83, loss:1.0971]\n",
      "Epoch [8/84, loss:0.5662]\n",
      "Epoch [8/85, loss:0.2494]\n",
      "Epoch [8/86, loss:0.6683]\n",
      "Epoch [8/87, loss:0.3187]\n",
      "Epoch [8/88, loss:0.3697]\n",
      "Epoch [8/89, loss:1.4870]\n",
      "Epoch [8/90, loss:0.2327]\n",
      "Epoch [8/91, loss:0.5062]\n",
      "Epoch [8/92, loss:0.8621]\n",
      "Epoch [8/93, loss:0.8238]\n",
      "Epoch [8/94, loss:0.7506]\n",
      "Epoch [8/95, loss:0.5358]\n",
      "Epoch [8/96, loss:1.2883]\n",
      "Epoch [8/97, loss:0.9842]\n",
      "Epoch [8/98, loss:0.5395]\n",
      "Epoch [8/99, loss:0.4220]\n",
      "Epoch [8/100, loss:1.1581]\n",
      "Epoch [8/101, loss:0.1179]\n",
      "Epoch [8/102, loss:0.0750]\n",
      "Epoch [8/103, loss:0.9703]\n",
      "Epoch [8/104, loss:0.5235]\n",
      "Epoch [8/105, loss:0.4449]\n",
      "Epoch [8/106, loss:0.2101]\n",
      "Epoch [8/107, loss:0.0823]\n",
      "Epoch [8/108, loss:0.2359]\n",
      "Epoch [8/109, loss:1.1189]\n",
      "Epoch [8/110, loss:0.3794]\n",
      "Epoch [8/111, loss:2.4003]\n",
      "Epoch [8/112, loss:1.3062]\n",
      "Epoch [8/113, loss:0.3978]\n",
      "Epoch [8/114, loss:0.8945]\n",
      "Epoch [8/115, loss:0.8369]\n",
      "Epoch [8/116, loss:0.8517]\n",
      "Epoch [8/117, loss:1.3957]\n",
      "Epoch [8/118, loss:0.4819]\n",
      "Epoch [8/119, loss:0.3286]\n",
      "Epoch [8/120, loss:0.6496]\n",
      "Epoch [8/121, loss:0.5439]\n",
      "Epoch [8/122, loss:0.2129]\n",
      "Epoch [8/123, loss:0.3861]\n",
      "Epoch [8/124, loss:0.7586]\n",
      "Epoch [8/125, loss:0.8071]\n",
      "Epoch [8/126, loss:0.5691]\n",
      "Epoch [8/127, loss:0.4098]\n",
      "Epoch [8/128, loss:0.1767]\n",
      "Epoch [8/129, loss:2.7462]\n",
      "Epoch [8/130, loss:0.5934]\n",
      "Epoch [8/131, loss:0.5437]\n",
      "Epoch [8/132, loss:0.5428]\n",
      "Epoch [8/133, loss:0.9472]\n",
      "Epoch [8/134, loss:0.6472]\n",
      "Epoch [8/135, loss:1.4427]\n",
      "Epoch [8/136, loss:0.3001]\n",
      "Epoch [8/137, loss:0.4942]\n",
      "Epoch [8/138, loss:0.9872]\n",
      "Epoch [8/139, loss:0.5642]\n",
      "Epoch [8/140, loss:0.2031]\n",
      "Epoch [8/141, loss:0.5609]\n",
      "Epoch [8/142, loss:0.7957]\n",
      "Epoch [8/143, loss:0.2821]\n",
      "Epoch [8/144, loss:0.1711]\n",
      "Epoch [8/145, loss:0.3383]\n",
      "Epoch [8/146, loss:0.7530]\n",
      "Epoch [8/147, loss:0.5793]\n",
      "Epoch [8/148, loss:0.1785]\n",
      "Epoch [8/149, loss:0.5782]\n",
      "Epoch [8/150, loss:0.5367]\n",
      "Epoch [8/151, loss:0.5633]\n",
      "Epoch [8/152, loss:0.3646]\n",
      "Epoch [8/153, loss:0.6673]\n",
      "Epoch [8/154, loss:0.7613]\n",
      "Epoch [8/155, loss:0.5980]\n",
      "Epoch [8/156, loss:1.3432]\n",
      "Epoch [8/157, loss:0.2339]\n",
      "Epoch [8/158, loss:0.9038]\n",
      "Epoch [8/159, loss:0.6300]\n",
      "Epoch [8/160, loss:0.5148]\n",
      "Epoch [8/161, loss:0.2075]\n",
      "Epoch [8/162, loss:0.5205]\n",
      "Epoch [8/163, loss:0.4617]\n",
      "Epoch [8/164, loss:1.8358]\n",
      "Epoch [8/165, loss:0.4758]\n",
      "Epoch [8/166, loss:0.2107]\n",
      "Epoch [8/167, loss:2.4016]\n",
      "Epoch [8/168, loss:0.2282]\n",
      "Epoch [8/169, loss:0.8289]\n",
      "Epoch [8/170, loss:0.7516]\n",
      "Epoch [8/171, loss:0.5158]\n",
      "Epoch [8/172, loss:2.9585]\n",
      "Epoch [8/173, loss:0.5138]\n",
      "Epoch [8/174, loss:0.2888]\n",
      "Epoch [8/175, loss:0.7884]\n",
      "Epoch [8/176, loss:2.3060]\n",
      "Epoch [8/177, loss:0.8979]\n",
      "Epoch [8/178, loss:0.3461]\n",
      "Epoch [8/179, loss:0.8521]\n",
      "Epoch [8/180, loss:1.0534]\n",
      "Epoch [8/181, loss:0.3097]\n",
      "Epoch [8/182, loss:0.2381]\n",
      "Epoch [8/183, loss:0.7172]\n",
      "Epoch [8/184, loss:1.0010]\n",
      "Epoch [8/185, loss:0.5672]\n",
      "Epoch [8/186, loss:0.7125]\n",
      "Epoch [8/187, loss:0.3681]\n",
      "Epoch [8/188, loss:0.5643]\n",
      "Epoch [8/189, loss:0.5448]\n",
      "Epoch [8/190, loss:1.3173]\n",
      "Epoch [8/191, loss:0.6080]\n",
      "Epoch [8/192, loss:0.5328]\n",
      "Epoch [8/193, loss:0.2550]\n",
      "Epoch [8/194, loss:1.0490]\n",
      "Epoch [8/195, loss:0.0996]\n",
      "Epoch [8/196, loss:0.9446]\n",
      "Epoch [8/197, loss:0.6626]\n",
      "Epoch [8/198, loss:1.0033]\n",
      "Epoch [8/199, loss:0.7257]\n",
      "Epoch [8/200, loss:0.1916]\n",
      "Epoch [9/1, loss:0.4872]\n",
      "Epoch [9/2, loss:0.8627]\n",
      "Epoch [9/3, loss:1.5185]\n",
      "Epoch [9/4, loss:0.6230]\n",
      "Epoch [9/5, loss:0.4600]\n",
      "Epoch [9/6, loss:0.6320]\n",
      "Epoch [9/7, loss:0.8225]\n",
      "Epoch [9/8, loss:0.0858]\n",
      "Epoch [9/9, loss:0.5420]\n",
      "Epoch [9/10, loss:0.4675]\n",
      "Epoch [9/11, loss:0.3905]\n",
      "Epoch [9/12, loss:0.6078]\n",
      "Epoch [9/13, loss:2.3723]\n",
      "Epoch [9/14, loss:0.3964]\n",
      "Epoch [9/15, loss:1.3996]\n",
      "Epoch [9/16, loss:0.6566]\n",
      "Epoch [9/17, loss:1.2106]\n",
      "Epoch [9/18, loss:0.8366]\n",
      "Epoch [9/19, loss:0.3585]\n",
      "Epoch [9/20, loss:0.3459]\n",
      "Epoch [9/21, loss:0.2432]\n",
      "Epoch [9/22, loss:0.3510]\n",
      "Epoch [9/23, loss:0.7629]\n",
      "Epoch [9/24, loss:0.3009]\n",
      "Epoch [9/25, loss:1.2513]\n",
      "Epoch [9/26, loss:0.3646]\n",
      "Epoch [9/27, loss:0.5504]\n",
      "Epoch [9/28, loss:1.2661]\n",
      "Epoch [9/29, loss:0.5262]\n",
      "Epoch [9/30, loss:0.5157]\n",
      "Epoch [9/31, loss:0.5342]\n",
      "Epoch [9/32, loss:0.9609]\n",
      "Epoch [9/33, loss:2.8586]\n",
      "Epoch [9/34, loss:0.3462]\n",
      "Epoch [9/35, loss:0.2295]\n",
      "Epoch [9/36, loss:1.0603]\n",
      "Epoch [9/37, loss:2.4847]\n",
      "Epoch [9/38, loss:0.9488]\n",
      "Epoch [9/39, loss:0.1872]\n",
      "Epoch [9/40, loss:0.4141]\n",
      "Epoch [9/41, loss:1.7321]\n",
      "Epoch [9/42, loss:0.6603]\n",
      "Epoch [9/43, loss:1.3998]\n",
      "Epoch [9/44, loss:0.6760]\n",
      "Epoch [9/45, loss:0.8510]\n",
      "Epoch [9/46, loss:0.3808]\n",
      "Epoch [9/47, loss:0.4982]\n",
      "Epoch [9/48, loss:0.3877]\n",
      "Epoch [9/49, loss:1.2737]\n",
      "Epoch [9/50, loss:0.4770]\n",
      "Epoch [9/51, loss:0.5280]\n",
      "Epoch [9/52, loss:0.3667]\n",
      "Epoch [9/53, loss:1.0786]\n",
      "Epoch [9/54, loss:0.4837]\n",
      "Epoch [9/55, loss:2.8748]\n",
      "Epoch [9/56, loss:0.2405]\n",
      "Epoch [9/57, loss:0.3658]\n",
      "Epoch [9/58, loss:0.2682]\n",
      "Epoch [9/59, loss:0.2556]\n",
      "Epoch [9/60, loss:0.3928]\n",
      "Epoch [9/61, loss:0.2522]\n",
      "Epoch [9/62, loss:0.6197]\n",
      "Epoch [9/63, loss:0.5272]\n",
      "Epoch [9/64, loss:0.6854]\n",
      "Epoch [9/65, loss:0.5413]\n",
      "Epoch [9/66, loss:0.6518]\n",
      "Epoch [9/67, loss:0.7828]\n",
      "Epoch [9/68, loss:0.4848]\n",
      "Epoch [9/69, loss:0.7243]\n",
      "Epoch [9/70, loss:2.1609]\n",
      "Epoch [9/71, loss:0.6028]\n",
      "Epoch [9/72, loss:0.9903]\n",
      "Epoch [9/73, loss:0.9830]\n",
      "Epoch [9/74, loss:1.6897]\n",
      "Epoch [9/75, loss:0.3336]\n",
      "Epoch [9/76, loss:0.6031]\n",
      "Epoch [9/77, loss:0.1216]\n",
      "Epoch [9/78, loss:2.0085]\n",
      "Epoch [9/79, loss:0.6457]\n",
      "Epoch [9/80, loss:0.3411]\n",
      "Epoch [9/81, loss:0.7721]\n",
      "Epoch [9/82, loss:0.0457]\n",
      "Epoch [9/83, loss:1.0804]\n",
      "Epoch [9/84, loss:0.4374]\n",
      "Epoch [9/85, loss:0.1645]\n",
      "Epoch [9/86, loss:0.6485]\n",
      "Epoch [9/87, loss:0.2228]\n",
      "Epoch [9/88, loss:0.2949]\n",
      "Epoch [9/89, loss:1.7257]\n",
      "Epoch [9/90, loss:0.1642]\n",
      "Epoch [9/91, loss:0.5012]\n",
      "Epoch [9/92, loss:0.7397]\n",
      "Epoch [9/93, loss:0.8064]\n",
      "Epoch [9/94, loss:0.7340]\n",
      "Epoch [9/95, loss:0.5766]\n",
      "Epoch [9/96, loss:1.3133]\n",
      "Epoch [9/97, loss:1.0257]\n",
      "Epoch [9/98, loss:0.5364]\n",
      "Epoch [9/99, loss:0.3535]\n",
      "Epoch [9/100, loss:1.2578]\n",
      "Epoch [9/101, loss:0.0760]\n",
      "Epoch [9/102, loss:0.0634]\n",
      "Epoch [9/103, loss:1.0006]\n",
      "Epoch [9/104, loss:0.4446]\n",
      "Epoch [9/105, loss:0.3564]\n",
      "Epoch [9/106, loss:0.1548]\n",
      "Epoch [9/107, loss:0.0475]\n",
      "Epoch [9/108, loss:0.1707]\n",
      "Epoch [9/109, loss:1.3390]\n",
      "Epoch [9/110, loss:0.3635]\n",
      "Epoch [9/111, loss:2.6829]\n",
      "Epoch [9/112, loss:1.3735]\n",
      "Epoch [9/113, loss:0.3601]\n",
      "Epoch [9/114, loss:0.9186]\n",
      "Epoch [9/115, loss:0.7766]\n",
      "Epoch [9/116, loss:0.8327]\n",
      "Epoch [9/117, loss:1.3295]\n",
      "Epoch [9/118, loss:0.4749]\n",
      "Epoch [9/119, loss:0.3106]\n",
      "Epoch [9/120, loss:0.6235]\n",
      "Epoch [9/121, loss:0.3904]\n",
      "Epoch [9/122, loss:0.1677]\n",
      "Epoch [9/123, loss:0.3034]\n",
      "Epoch [9/124, loss:0.5566]\n",
      "Epoch [9/125, loss:0.7111]\n",
      "Epoch [9/126, loss:0.4673]\n",
      "Epoch [9/127, loss:0.3495]\n",
      "Epoch [9/128, loss:0.1257]\n",
      "Epoch [9/129, loss:2.8989]\n",
      "Epoch [9/130, loss:0.5678]\n",
      "Epoch [9/131, loss:0.4561]\n",
      "Epoch [9/132, loss:0.5220]\n",
      "Epoch [9/133, loss:0.9428]\n",
      "Epoch [9/134, loss:0.6657]\n",
      "Epoch [9/135, loss:1.4848]\n",
      "Epoch [9/136, loss:0.2229]\n",
      "Epoch [9/137, loss:0.4877]\n",
      "Epoch [9/138, loss:1.0280]\n",
      "Epoch [9/139, loss:0.5602]\n",
      "Epoch [9/140, loss:0.1856]\n",
      "Epoch [9/141, loss:0.5383]\n",
      "Epoch [9/142, loss:0.7730]\n",
      "Epoch [9/143, loss:0.2665]\n",
      "Epoch [9/144, loss:0.1541]\n",
      "Epoch [9/145, loss:0.2783]\n",
      "Epoch [9/146, loss:0.6840]\n",
      "Epoch [9/147, loss:0.5643]\n",
      "Epoch [9/148, loss:0.1713]\n",
      "Epoch [9/149, loss:0.5670]\n",
      "Epoch [9/150, loss:0.3799]\n",
      "Epoch [9/151, loss:0.5204]\n",
      "Epoch [9/152, loss:0.3597]\n",
      "Epoch [9/153, loss:0.6149]\n",
      "Epoch [9/154, loss:0.6638]\n",
      "Epoch [9/155, loss:0.5442]\n",
      "Epoch [9/156, loss:1.5224]\n",
      "Epoch [9/157, loss:0.1639]\n",
      "Epoch [9/158, loss:0.8905]\n",
      "Epoch [9/159, loss:0.6060]\n",
      "Epoch [9/160, loss:0.4477]\n",
      "Epoch [9/161, loss:0.1987]\n",
      "Epoch [9/162, loss:0.4741]\n",
      "Epoch [9/163, loss:0.4422]\n",
      "Epoch [9/164, loss:1.4325]\n",
      "Epoch [9/165, loss:0.4009]\n",
      "Epoch [9/166, loss:0.1541]\n",
      "Epoch [9/167, loss:2.2843]\n",
      "Epoch [9/168, loss:0.1546]\n",
      "Epoch [9/169, loss:0.7876]\n",
      "Epoch [9/170, loss:0.7499]\n",
      "Epoch [9/171, loss:0.4955]\n",
      "Epoch [9/172, loss:2.7269]\n",
      "Epoch [9/173, loss:0.4468]\n",
      "Epoch [9/174, loss:0.2780]\n",
      "Epoch [9/175, loss:0.8244]\n",
      "Epoch [9/176, loss:2.1709]\n",
      "Epoch [9/177, loss:0.8946]\n",
      "Epoch [9/178, loss:0.3102]\n",
      "Epoch [9/179, loss:0.8304]\n",
      "Epoch [9/180, loss:1.0020]\n",
      "Epoch [9/181, loss:0.2377]\n",
      "Epoch [9/182, loss:0.1852]\n",
      "Epoch [9/183, loss:0.7006]\n",
      "Epoch [9/184, loss:1.0089]\n",
      "Epoch [9/185, loss:0.5252]\n",
      "Epoch [9/186, loss:0.6962]\n",
      "Epoch [9/187, loss:0.3019]\n",
      "Epoch [9/188, loss:0.5642]\n",
      "Epoch [9/189, loss:0.5262]\n",
      "Epoch [9/190, loss:1.2344]\n",
      "Epoch [9/191, loss:0.6872]\n",
      "Epoch [9/192, loss:0.5196]\n",
      "Epoch [9/193, loss:0.1846]\n",
      "Epoch [9/194, loss:0.9581]\n",
      "Epoch [9/195, loss:0.0546]\n",
      "Epoch [9/196, loss:0.9520]\n",
      "Epoch [9/197, loss:0.6629]\n",
      "Epoch [9/198, loss:1.0212]\n",
      "Epoch [9/199, loss:0.7373]\n",
      "Epoch [9/200, loss:0.1431]\n",
      "Epoch [10/1, loss:0.4650]\n",
      "Epoch [10/2, loss:0.8628]\n",
      "Epoch [10/3, loss:1.7682]\n",
      "Epoch [10/4, loss:0.5937]\n",
      "Epoch [10/5, loss:0.4419]\n",
      "Epoch [10/6, loss:0.6282]\n",
      "Epoch [10/7, loss:0.7731]\n",
      "Epoch [10/8, loss:0.0573]\n",
      "Epoch [10/9, loss:0.5377]\n",
      "Epoch [10/10, loss:0.4449]\n",
      "Epoch [10/11, loss:0.3724]\n",
      "Epoch [10/12, loss:0.6117]\n",
      "Epoch [10/13, loss:2.2513]\n",
      "Epoch [10/14, loss:0.3297]\n",
      "Epoch [10/15, loss:1.2448]\n",
      "Epoch [10/16, loss:0.5378]\n",
      "Epoch [10/17, loss:1.2267]\n",
      "Epoch [10/18, loss:0.7723]\n",
      "Epoch [10/19, loss:0.2816]\n",
      "Epoch [10/20, loss:0.2440]\n",
      "Epoch [10/21, loss:0.1779]\n",
      "Epoch [10/22, loss:0.3448]\n",
      "Epoch [10/23, loss:0.6202]\n",
      "Epoch [10/24, loss:0.2084]\n",
      "Epoch [10/25, loss:1.2445]\n",
      "Epoch [10/26, loss:0.3483]\n",
      "Epoch [10/27, loss:0.4725]\n",
      "Epoch [10/28, loss:1.2373]\n",
      "Epoch [10/29, loss:0.4876]\n",
      "Epoch [10/30, loss:0.4887]\n",
      "Epoch [10/31, loss:0.4808]\n",
      "Epoch [10/32, loss:0.9289]\n",
      "Epoch [10/33, loss:2.7623]\n",
      "Epoch [10/34, loss:0.2540]\n",
      "Epoch [10/35, loss:0.1819]\n",
      "Epoch [10/36, loss:1.0630]\n",
      "Epoch [10/37, loss:2.6347]\n",
      "Epoch [10/38, loss:0.9777]\n",
      "Epoch [10/39, loss:0.1314]\n",
      "Epoch [10/40, loss:0.3191]\n",
      "Epoch [10/41, loss:1.4920]\n",
      "Epoch [10/42, loss:0.6871]\n",
      "Epoch [10/43, loss:1.4852]\n",
      "Epoch [10/44, loss:0.6595]\n",
      "Epoch [10/45, loss:0.8366]\n",
      "Epoch [10/46, loss:0.3468]\n",
      "Epoch [10/47, loss:0.4868]\n",
      "Epoch [10/48, loss:0.3606]\n",
      "Epoch [10/49, loss:1.2673]\n",
      "Epoch [10/50, loss:0.4555]\n",
      "Epoch [10/51, loss:0.5074]\n",
      "Epoch [10/52, loss:0.3067]\n",
      "Epoch [10/53, loss:1.2382]\n",
      "Epoch [10/54, loss:0.4790]\n",
      "Epoch [10/55, loss:2.7844]\n",
      "Epoch [10/56, loss:0.1791]\n",
      "Epoch [10/57, loss:0.3049]\n",
      "Epoch [10/58, loss:0.1960]\n",
      "Epoch [10/59, loss:0.1972]\n",
      "Epoch [10/60, loss:0.3767]\n",
      "Epoch [10/61, loss:0.2521]\n",
      "Epoch [10/62, loss:0.5981]\n",
      "Epoch [10/63, loss:0.5073]\n",
      "Epoch [10/64, loss:0.6838]\n",
      "Epoch [10/65, loss:0.5358]\n",
      "Epoch [10/66, loss:0.5756]\n",
      "Epoch [10/67, loss:0.6948]\n",
      "Epoch [10/68, loss:0.3981]\n",
      "Epoch [10/69, loss:0.7145]\n",
      "Epoch [10/70, loss:2.3824]\n",
      "Epoch [10/71, loss:0.4856]\n",
      "Epoch [10/72, loss:1.0104]\n",
      "Epoch [10/73, loss:1.0179]\n",
      "Epoch [10/74, loss:1.6136]\n",
      "Epoch [10/75, loss:0.3154]\n",
      "Epoch [10/76, loss:0.4966]\n",
      "Epoch [10/77, loss:0.0835]\n",
      "Epoch [10/78, loss:2.1724]\n",
      "Epoch [10/79, loss:0.5133]\n",
      "Epoch [10/80, loss:0.2714]\n",
      "Epoch [10/81, loss:0.7520]\n",
      "Epoch [10/82, loss:0.0393]\n",
      "Epoch [10/83, loss:1.0665]\n",
      "Epoch [10/84, loss:0.3500]\n",
      "Epoch [10/85, loss:0.1177]\n",
      "Epoch [10/86, loss:0.6278]\n",
      "Epoch [10/87, loss:0.1645]\n",
      "Epoch [10/88, loss:0.2391]\n",
      "Epoch [10/89, loss:1.9080]\n",
      "Epoch [10/90, loss:0.1168]\n",
      "Epoch [10/91, loss:0.4991]\n",
      "Epoch [10/92, loss:0.6153]\n",
      "Epoch [10/93, loss:0.7819]\n",
      "Epoch [10/94, loss:0.7224]\n",
      "Epoch [10/95, loss:0.6080]\n",
      "Epoch [10/96, loss:1.3346]\n",
      "Epoch [10/97, loss:1.0633]\n",
      "Epoch [10/98, loss:0.5259]\n",
      "Epoch [10/99, loss:0.2995]\n",
      "Epoch [10/100, loss:1.3319]\n",
      "Epoch [10/101, loss:0.0521]\n",
      "Epoch [10/102, loss:0.0539]\n",
      "Epoch [10/103, loss:1.0287]\n",
      "Epoch [10/104, loss:0.3594]\n",
      "Epoch [10/105, loss:0.2989]\n",
      "Epoch [10/106, loss:0.1179]\n",
      "Epoch [10/107, loss:0.0299]\n",
      "Epoch [10/108, loss:0.1269]\n",
      "Epoch [10/109, loss:1.4497]\n",
      "Epoch [10/110, loss:0.3485]\n",
      "Epoch [10/111, loss:2.8790]\n",
      "Epoch [10/112, loss:1.4355]\n",
      "Epoch [10/113, loss:0.3327]\n",
      "Epoch [10/114, loss:0.9348]\n",
      "Epoch [10/115, loss:0.7217]\n",
      "Epoch [10/116, loss:0.8095]\n",
      "Epoch [10/117, loss:1.2367]\n",
      "Epoch [10/118, loss:0.4566]\n",
      "Epoch [10/119, loss:0.2886]\n",
      "Epoch [10/120, loss:0.6052]\n",
      "Epoch [10/121, loss:0.2814]\n",
      "Epoch [10/122, loss:0.1334]\n",
      "Epoch [10/123, loss:0.2500]\n",
      "Epoch [10/124, loss:0.4132]\n",
      "Epoch [10/125, loss:0.6307]\n",
      "Epoch [10/126, loss:0.3854]\n",
      "Epoch [10/127, loss:0.2928]\n",
      "Epoch [10/128, loss:0.0942]\n",
      "Epoch [10/129, loss:2.9523]\n",
      "Epoch [10/130, loss:0.5343]\n",
      "Epoch [10/131, loss:0.3754]\n",
      "Epoch [10/132, loss:0.5006]\n",
      "Epoch [10/133, loss:0.9269]\n",
      "Epoch [10/134, loss:0.6629]\n",
      "Epoch [10/135, loss:1.5284]\n",
      "Epoch [10/136, loss:0.1709]\n",
      "Epoch [10/137, loss:0.4772]\n",
      "Epoch [10/138, loss:1.0615]\n",
      "Epoch [10/139, loss:0.5514]\n",
      "Epoch [10/140, loss:0.1687]\n",
      "Epoch [10/141, loss:0.5085]\n",
      "Epoch [10/142, loss:0.7459]\n",
      "Epoch [10/143, loss:0.2475]\n",
      "Epoch [10/144, loss:0.1381]\n",
      "Epoch [10/145, loss:0.2333]\n",
      "Epoch [10/146, loss:0.6226]\n",
      "Epoch [10/147, loss:0.5475]\n",
      "Epoch [10/148, loss:0.1623]\n",
      "Epoch [10/149, loss:0.5542]\n",
      "Epoch [10/150, loss:0.2865]\n",
      "Epoch [10/151, loss:0.4871]\n",
      "Epoch [10/152, loss:0.3511]\n",
      "Epoch [10/153, loss:0.5817]\n",
      "Epoch [10/154, loss:0.5848]\n",
      "Epoch [10/155, loss:0.4946]\n",
      "Epoch [10/156, loss:1.6659]\n",
      "Epoch [10/157, loss:0.1210]\n",
      "Epoch [10/158, loss:0.8701]\n",
      "Epoch [10/159, loss:0.5696]\n",
      "Epoch [10/160, loss:0.3944]\n",
      "Epoch [10/161, loss:0.1897]\n",
      "Epoch [10/162, loss:0.4424]\n",
      "Epoch [10/163, loss:0.4244]\n",
      "Epoch [10/164, loss:1.1480]\n",
      "Epoch [10/165, loss:0.3357]\n",
      "Epoch [10/166, loss:0.1212]\n",
      "Epoch [10/167, loss:2.2266]\n",
      "Epoch [10/168, loss:0.1162]\n",
      "Epoch [10/169, loss:0.7632]\n",
      "Epoch [10/170, loss:0.7421]\n",
      "Epoch [10/171, loss:0.4743]\n",
      "Epoch [10/172, loss:2.5901]\n",
      "Epoch [10/173, loss:0.3879]\n",
      "Epoch [10/174, loss:0.2646]\n",
      "Epoch [10/175, loss:0.8511]\n",
      "Epoch [10/176, loss:2.0775]\n",
      "Epoch [10/177, loss:0.8902]\n",
      "Epoch [10/178, loss:0.2918]\n",
      "Epoch [10/179, loss:0.8026]\n",
      "Epoch [10/180, loss:0.9641]\n",
      "Epoch [10/181, loss:0.1883]\n",
      "Epoch [10/182, loss:0.1567]\n",
      "Epoch [10/183, loss:0.6745]\n",
      "Epoch [10/184, loss:0.9676]\n",
      "Epoch [10/185, loss:0.4813]\n",
      "Epoch [10/186, loss:0.6544]\n",
      "Epoch [10/187, loss:0.2490]\n",
      "Epoch [10/188, loss:0.5639]\n",
      "Epoch [10/189, loss:0.5084]\n",
      "Epoch [10/190, loss:1.1247]\n",
      "Epoch [10/191, loss:0.7435]\n",
      "Epoch [10/192, loss:0.5026]\n",
      "Epoch [10/193, loss:0.1451]\n",
      "Epoch [10/194, loss:0.8677]\n",
      "Epoch [10/195, loss:0.0358]\n",
      "Epoch [10/196, loss:0.9563]\n",
      "Epoch [10/197, loss:0.6609]\n",
      "Epoch [10/198, loss:1.0247]\n",
      "Epoch [10/199, loss:0.7423]\n",
      "Epoch [10/200, loss:0.1161]\n",
      "Süre 84.70733261108398\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "model = Net()\n",
    "\n",
    "optimizer = torch.optim.Adamax(model.parameters(), lr=0.001)\n",
    "error = torch.nn.CrossEntropyLoss()\n",
    "epoch = 10\n",
    "\n",
    "for i in range(epoch):\n",
    "    for j, (images, label) in enumerate(train_loader):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(images)\n",
    "        loss = error(out, label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(\"Epoch [{}/{}, loss:{:.4f}]\".format(i+1, j+1, loss.item()))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Süre\", end-start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelin Testi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dogruluk (loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # test modu \n",
    "\n",
    "    with torch.no_grad(): # gradient (türev hesaplama)\n",
    "        for x,y in loader:\n",
    "            tahmin = model(x) # images\n",
    "            _,pred = tahmin.max(1)\n",
    "            num_correct += (pred==y).sum()\n",
    "            num_samples += (pred.size(0))\n",
    "\n",
    "        print(f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct) / float(num_samples) * 100:.2f}\")\n",
    "\n",
    "        model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train doğruluk:\n",
      "Got 150 / 200 with accuracy 75.00\n",
      "test doğruluk:\n",
      "Got 50 / 79 with accuracy 63.29\n"
     ]
    }
   ],
   "source": [
    "print(\"train doğruluk:\")\n",
    "dogruluk(train_loader, model)\n",
    "\n",
    "print(\"test doğruluk:\")\n",
    "dogruluk(test_loader, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelin Eğitim ve Testi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  100 Loss: 1.3476 Accuracy: 26.5823 Error: 73.4177\n",
      "iteration:  200 Loss: 1.2492 Accuracy: 31.6456 Error: 68.3544\n",
      "iteration:  300 Loss: 1.7446 Accuracy: 53.1646 Error: 46.8354\n",
      "iteration:  400 Loss: 0.0648 Accuracy: 49.3671 Error: 50.6329\n",
      "iteration:  500 Loss: 0.3081 Accuracy: 73.4177 Error: 26.5823\n",
      "iteration:  600 Loss: 0.0235 Accuracy: 53.1646 Error: 46.8354\n",
      "iteration:  700 Loss: 0.1513 Accuracy: 73.4177 Error: 26.5823\n",
      "iteration:  800 Loss: 0.0140 Accuracy: 54.4304 Error: 45.5696\n",
      "iteration:  900 Loss: 0.1341 Accuracy: 74.6835 Error: 25.3165\n",
      "iteration: 1000 Loss: 0.0268 Accuracy: 60.7595 Error: 39.2405\n",
      "iteration: 1100 Loss: 0.1228 Accuracy: 77.2152 Error: 22.7848\n",
      "iteration: 1200 Loss: 0.0041 Accuracy: 62.0253 Error: 37.9747\n",
      "iteration: 1300 Loss: 0.0586 Accuracy: 74.6835 Error: 25.3165\n",
      "iteration: 1400 Loss: 0.0033 Accuracy: 75.9494 Error: 24.0506\n",
      "iteration: 1500 Loss: 0.0377 Accuracy: 73.4177 Error: 26.5823\n",
      "iteration: 1600 Loss: 0.0024 Accuracy: 73.4177 Error: 26.5823\n",
      "iteration: 1700 Loss: 0.0525 Accuracy: 70.8861 Error: 29.1139\n",
      "iteration: 1800 Loss: 0.0006 Accuracy: 77.2152 Error: 22.7848\n",
      "iteration: 1900 Loss: 0.0096 Accuracy: 77.2152 Error: 22.7848\n",
      "iteration: 2000 Loss: 0.6891 Accuracy: 62.0253 Error: 37.9747\n",
      "Süre: 152.03984379768372\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model = Net()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "error = torch.nn.CrossEntropyLoss()\n",
    "epoch = 10\n",
    "\n",
    "kayip = []\n",
    "count = 0\n",
    "iterasyon = []\n",
    "\n",
    "for i in range(epoch):\n",
    "    for j , (images, label) in enumerate (train_loader):\n",
    "\n",
    "        tahmin = model(images)\n",
    "        optimizer.zero_grad()\n",
    "        loss = error(tahmin, label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        count += 1\n",
    "\n",
    "        if count % 100 == 0:\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            err = 0\n",
    "\n",
    "            for images, labels in test_loader:\n",
    "                out = model(images)\n",
    "                pred = torch.max(out.data, 1)[1]\n",
    "                total += len(label)\n",
    "\n",
    "                correct+= (pred==labels).sum()\n",
    "                err += (pred != labels).sum()\n",
    "\n",
    "            dogruluk = 100 * correct / float(total)\n",
    "            hata = 100 * err / float(total)\n",
    "            kayip.append(loss.data)\n",
    "            iterasyon.append(count)\n",
    "\n",
    "        if count % 100 == 0:\n",
    "            print(\"iteration: {:4} Loss: {:3.4f} Accuracy: {:3.4f} Error: {:3.4f}\".format(count, loss.data, dogruluk, hata))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Süre:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  100 Loss: 1.3058 Accuracy: 20.2532 Error: 79.7468\n",
      "iteration:  200 Loss: 1.2547 Accuracy: 20.2532 Error: 79.7468\n",
      "iteration:  300 Loss: 1.2737 Accuracy: 35.4430 Error: 64.5570\n",
      "iteration:  400 Loss: 0.9293 Accuracy: 43.0380 Error: 56.9620\n",
      "iteration:  500 Loss: 1.0857 Accuracy: 53.1646 Error: 46.8354\n",
      "iteration:  600 Loss: 0.7845 Accuracy: 44.3038 Error: 55.6962\n",
      "iteration:  700 Loss: 1.1097 Accuracy: 55.6962 Error: 44.3038\n",
      "iteration:  800 Loss: 0.7037 Accuracy: 46.8354 Error: 53.1646\n",
      "iteration:  900 Loss: 1.0514 Accuracy: 54.4304 Error: 45.5696\n",
      "iteration: 1000 Loss: 0.6220 Accuracy: 46.8354 Error: 53.1646\n",
      "iteration: 1100 Loss: 1.0069 Accuracy: 60.7595 Error: 39.2405\n",
      "iteration: 1200 Loss: 0.5648 Accuracy: 48.1013 Error: 51.8987\n",
      "iteration: 1300 Loss: 1.0242 Accuracy: 63.2911 Error: 36.7089\n",
      "iteration: 1400 Loss: 0.5100 Accuracy: 51.8987 Error: 48.1013\n",
      "iteration: 1500 Loss: 1.1293 Accuracy: 67.0886 Error: 32.9114\n",
      "iteration: 1600 Loss: 0.4492 Accuracy: 63.2911 Error: 36.7089\n",
      "iteration: 1700 Loss: 1.3406 Accuracy: 69.6203 Error: 30.3797\n",
      "iteration: 1800 Loss: 0.4025 Accuracy: 70.8861 Error: 29.1139\n",
      "iteration: 1900 Loss: 1.5782 Accuracy: 69.6203 Error: 30.3797\n",
      "iteration: 2000 Loss: 0.3858 Accuracy: 72.1519 Error: 27.8481\n",
      "Süre: 149.89670968055725\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model = Net()\n",
    "\n",
    "optimizer = torch.optim.Adamax(model.parameters(), lr=0.001)\n",
    "error = torch.nn.CrossEntropyLoss()\n",
    "epoch = 10\n",
    "\n",
    "kayip = []\n",
    "count = 0\n",
    "iterasyon = []\n",
    "\n",
    "for i in range(epoch):\n",
    "    for j , (images, label) in enumerate (train_loader):\n",
    "\n",
    "        tahmin = model(images)\n",
    "        optimizer.zero_grad()\n",
    "        loss = error(tahmin, label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        count += 1\n",
    "\n",
    "        if count % 100 == 0:\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            err = 0\n",
    "\n",
    "            for images, labels in test_loader:\n",
    "                out = model(images)\n",
    "                pred = torch.max(out.data, 1)[1]\n",
    "                total += len(label)\n",
    "\n",
    "                correct+= (pred==labels).sum()\n",
    "                err += (pred != labels).sum()\n",
    "\n",
    "            dogruluk = 100 * correct / float(total)\n",
    "            hata = 100 * err / float(total)\n",
    "            kayip.append(loss.data)\n",
    "            iterasyon.append(count)\n",
    "\n",
    "        if count % 100 == 0:\n",
    "            print(\"iteration: {:4} Loss: {:3.4f} Accuracy: {:3.4f} Error: {:3.4f}\".format(count, loss.data, dogruluk, hata))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Süre:\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"../Model_Save/modelsave.pth\") # modelin tamamı kayıt edildi\n",
    "torch.save(model.state_dict(),\"../Model_Save/modelstatedict.pth\") # modelin ağırlıkları kayıt edildi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "833b1e0daebd69276f47cc9e2e2c8387bf0a407b51837849a04c5beaa21d9be9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
