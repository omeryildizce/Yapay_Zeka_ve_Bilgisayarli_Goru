{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Veri Hazırlama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kütüphaneler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import (Dataset, DataLoader)\n",
    "from skimage import io\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class veri(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n",
    "        image = io.imread(img_path)\n",
    "        y_label = torch.tensor(int(self.annotations.iloc[index, 1]))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return(image, y_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veri Hazırlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = veri(csv_file=r\"../../veriler/f1_classification/f111.csv\", root_dir=r\"../../veriler/f1_classification\", transform=transforms.Compose([\n",
    "\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(size=(28, 28)),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.veri at 0x19707bf4880>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veri Ön İşleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = torch.utils.data.random_split(dataset, [200, 79])\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=1, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x19707bf43a0>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x19707bf4220>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veri Görselleştirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mclaren\n",
      "torch.Size([1, 3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "batch_size = 1\n",
    "\n",
    "classes = [\"Ferrari\", \"Mclaren\", \"Mercedes\", \"Redbull\"]\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(batch_size)))\n",
    "print(images.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Mimarisini Oluşturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3,  out_channels=4,  kernel_size=(5, 5))\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=4,  out_channels=8,  kernel_size=(3, 3))\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=8,  out_channels=16, kernel_size=(2, 2))\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=16, out_channels=32, kernel_size=(2, 2))\n",
    "\n",
    "        self.max = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.func = nn.ELU()\n",
    "        self.func1 = nn.ReLU()\n",
    "\n",
    "        self.fullyconnect1 = nn.Linear(in_features=32, out_features=50)\n",
    "        self.fullyconnect2 = nn.Linear(in_features=50, out_features=50)\n",
    "        self.fullyconnect3 = nn.Linear(in_features=50, out_features=100)\n",
    "        self.fullyconnect4 = nn.Linear(in_features=100, out_features=4)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.func(x)\n",
    "        x = self.max(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.func(x)\n",
    "        x = self.max(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.func(x)\n",
    "        x = self.max(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.func(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # flaten\n",
    "        \n",
    "        x = self.fullyconnect1(x)\n",
    "        x = self.func(x)\n",
    "        x = self.fullyconnect2(x)\n",
    "        x = self.func(x)\n",
    "        x = self.fullyconnect3(x)\n",
    "        x = self.func(x)\n",
    "        \n",
    "        x = self.fullyconnect4(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelin Eğitimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1, loss:1.4268]\n",
      "Epoch [1/2, loss:1.4202]\n",
      "Epoch [1/3, loss:1.4465]\n",
      "Epoch [1/4, loss:1.3998]\n",
      "Epoch [1/5, loss:1.3870]\n",
      "Epoch [1/6, loss:1.3732]\n",
      "Epoch [1/7, loss:1.3566]\n",
      "Epoch [1/8, loss:1.3446]\n",
      "Epoch [1/9, loss:1.3272]\n",
      "Epoch [1/10, loss:1.3843]\n",
      "Epoch [1/11, loss:1.4618]\n",
      "Epoch [1/12, loss:1.4630]\n",
      "Epoch [1/13, loss:1.3894]\n",
      "Epoch [1/14, loss:1.3884]\n",
      "Epoch [1/15, loss:1.3817]\n",
      "Epoch [1/16, loss:1.4611]\n",
      "Epoch [1/17, loss:1.4571]\n",
      "Epoch [1/18, loss:1.4715]\n",
      "Epoch [1/19, loss:1.2789]\n",
      "Epoch [1/20, loss:1.2779]\n",
      "Epoch [1/21, loss:1.3682]\n",
      "Epoch [1/22, loss:1.4448]\n",
      "Epoch [1/23, loss:1.3620]\n",
      "Epoch [1/24, loss:1.2711]\n",
      "Epoch [1/25, loss:1.4988]\n",
      "Epoch [1/26, loss:1.2623]\n",
      "Epoch [1/27, loss:1.2646]\n",
      "Epoch [1/28, loss:1.2519]\n",
      "Epoch [1/29, loss:1.4494]\n",
      "Epoch [1/30, loss:1.2408]\n",
      "Epoch [1/31, loss:1.4502]\n",
      "Epoch [1/32, loss:1.4472]\n",
      "Epoch [1/33, loss:1.5371]\n",
      "Epoch [1/34, loss:1.3809]\n",
      "Epoch [1/35, loss:1.4280]\n",
      "Epoch [1/36, loss:1.4187]\n",
      "Epoch [1/37, loss:1.3882]\n",
      "Epoch [1/38, loss:1.4120]\n",
      "Epoch [1/39, loss:1.2213]\n",
      "Epoch [1/40, loss:1.3973]\n",
      "Epoch [1/41, loss:1.2184]\n",
      "Epoch [1/42, loss:1.3957]\n",
      "Epoch [1/43, loss:1.2108]\n",
      "Epoch [1/44, loss:1.3894]\n",
      "Epoch [1/45, loss:1.3885]\n",
      "Epoch [1/46, loss:1.3843]\n",
      "Epoch [1/47, loss:1.2114]\n",
      "Epoch [1/48, loss:1.3830]\n",
      "Epoch [1/49, loss:1.6173]\n",
      "Epoch [1/50, loss:1.6260]\n",
      "Epoch [1/51, loss:1.3710]\n",
      "Epoch [1/52, loss:1.3709]\n",
      "Epoch [1/53, loss:1.6067]\n",
      "Epoch [1/54, loss:1.3587]\n",
      "Epoch [1/55, loss:1.6097]\n",
      "Epoch [1/56, loss:1.3470]\n",
      "Epoch [1/57, loss:1.3903]\n",
      "Epoch [1/58, loss:1.2421]\n",
      "Epoch [1/59, loss:1.3314]\n",
      "Epoch [1/60, loss:1.3238]\n",
      "Epoch [1/61, loss:1.5863]\n",
      "Epoch [1/62, loss:1.4042]\n",
      "Epoch [1/63, loss:1.2711]\n",
      "Epoch [1/64, loss:1.5766]\n",
      "Epoch [1/65, loss:1.2690]\n",
      "Epoch [1/66, loss:1.5746]\n",
      "Epoch [1/67, loss:1.4170]\n",
      "Epoch [1/68, loss:1.5685]\n",
      "Epoch [1/69, loss:1.3021]\n",
      "Epoch [1/70, loss:1.3000]\n",
      "Epoch [1/71, loss:1.5472]\n",
      "Epoch [1/72, loss:1.2969]\n",
      "Epoch [1/73, loss:1.3056]\n",
      "Epoch [1/74, loss:1.5359]\n",
      "Epoch [1/75, loss:1.2912]\n",
      "Epoch [1/76, loss:1.5351]\n",
      "Epoch [1/77, loss:1.2981]\n",
      "Epoch [1/78, loss:1.2845]\n",
      "Epoch [1/79, loss:1.2980]\n",
      "Epoch [1/80, loss:1.5120]\n",
      "Epoch [1/81, loss:1.2930]\n",
      "Epoch [1/82, loss:1.4998]\n",
      "Epoch [1/83, loss:1.2900]\n",
      "Epoch [1/84, loss:1.4926]\n",
      "Epoch [1/85, loss:1.4891]\n",
      "Epoch [1/86, loss:1.2970]\n",
      "Epoch [1/87, loss:1.2812]\n",
      "Epoch [1/88, loss:1.4820]\n",
      "Epoch [1/89, loss:1.3101]\n",
      "Epoch [1/90, loss:1.4863]\n",
      "Epoch [1/91, loss:1.4801]\n",
      "Epoch [1/92, loss:1.4846]\n",
      "Epoch [1/93, loss:1.4989]\n",
      "Epoch [1/94, loss:1.2817]\n",
      "Epoch [1/95, loss:1.2817]\n",
      "Epoch [1/96, loss:1.3092]\n",
      "Epoch [1/97, loss:1.2778]\n",
      "Epoch [1/98, loss:1.4588]\n",
      "Epoch [1/99, loss:1.4747]\n",
      "Epoch [1/100, loss:1.4803]\n",
      "Epoch [1/101, loss:1.3189]\n",
      "Epoch [1/102, loss:1.4577]\n",
      "Epoch [1/103, loss:1.2752]\n",
      "Epoch [1/104, loss:1.2764]\n",
      "Epoch [1/105, loss:1.4489]\n",
      "Epoch [1/106, loss:1.3157]\n",
      "Epoch [1/107, loss:1.4442]\n",
      "Epoch [1/108, loss:1.4622]\n",
      "Epoch [1/109, loss:1.4358]\n",
      "Epoch [1/110, loss:1.4630]\n",
      "Epoch [1/111, loss:1.3470]\n",
      "Epoch [1/112, loss:1.3451]\n",
      "Epoch [1/113, loss:1.2802]\n",
      "Epoch [1/114, loss:1.4252]\n",
      "Epoch [1/115, loss:1.4120]\n",
      "Epoch [1/116, loss:1.2866]\n",
      "Epoch [1/117, loss:1.4277]\n",
      "Epoch [1/118, loss:1.3461]\n",
      "Epoch [1/119, loss:1.2864]\n",
      "Epoch [1/120, loss:1.4909]\n",
      "Epoch [1/121, loss:1.2849]\n",
      "Epoch [1/122, loss:1.4172]\n",
      "Epoch [1/123, loss:1.4632]\n",
      "Epoch [1/124, loss:1.4101]\n",
      "Epoch [1/125, loss:1.2825]\n",
      "Epoch [1/126, loss:1.4541]\n",
      "Epoch [1/127, loss:1.3851]\n",
      "Epoch [1/128, loss:1.2916]\n",
      "Epoch [1/129, loss:1.4647]\n",
      "Epoch [1/130, loss:1.4179]\n",
      "Epoch [1/131, loss:1.4095]\n",
      "Epoch [1/132, loss:1.4030]\n",
      "Epoch [1/133, loss:1.4023]\n",
      "Epoch [1/134, loss:1.3401]\n",
      "Epoch [1/135, loss:1.3956]\n",
      "Epoch [1/136, loss:1.4181]\n",
      "Epoch [1/137, loss:1.3003]\n",
      "Epoch [1/138, loss:1.3887]\n",
      "Epoch [1/139, loss:1.3810]\n",
      "Epoch [1/140, loss:1.4114]\n",
      "Epoch [1/141, loss:1.3321]\n",
      "Epoch [1/142, loss:1.2996]\n",
      "Epoch [1/143, loss:1.4857]\n",
      "Epoch [1/144, loss:1.3212]\n",
      "Epoch [1/145, loss:1.3708]\n",
      "Epoch [1/146, loss:1.4415]\n",
      "Epoch [1/147, loss:1.2819]\n",
      "Epoch [1/148, loss:1.4743]\n",
      "Epoch [1/149, loss:1.3724]\n",
      "Epoch [1/150, loss:1.1010]\n",
      "Epoch [1/151, loss:1.3879]\n",
      "Epoch [1/152, loss:1.2379]\n",
      "Epoch [1/153, loss:1.3500]\n",
      "Epoch [1/154, loss:1.3659]\n",
      "Epoch [1/155, loss:1.3767]\n",
      "Epoch [1/156, loss:1.4509]\n",
      "Epoch [1/157, loss:1.4860]\n",
      "Epoch [1/158, loss:1.3634]\n",
      "Epoch [1/159, loss:1.5212]\n",
      "Epoch [1/160, loss:1.3502]\n",
      "Epoch [1/161, loss:1.1994]\n",
      "Epoch [1/162, loss:1.2286]\n",
      "Epoch [1/163, loss:1.2868]\n",
      "Epoch [1/164, loss:1.2880]\n",
      "Epoch [1/165, loss:1.3607]\n",
      "Epoch [1/166, loss:1.3338]\n",
      "Epoch [1/167, loss:1.4140]\n",
      "Epoch [1/168, loss:1.4137]\n",
      "Epoch [1/169, loss:1.3454]\n",
      "Epoch [1/170, loss:1.3993]\n",
      "Epoch [1/171, loss:1.3684]\n",
      "Epoch [1/172, loss:1.3500]\n",
      "Epoch [1/173, loss:1.3803]\n",
      "Epoch [1/174, loss:1.3525]\n",
      "Epoch [1/175, loss:1.4179]\n",
      "Epoch [1/176, loss:1.3075]\n",
      "Epoch [1/177, loss:1.3588]\n",
      "Epoch [1/178, loss:1.3399]\n",
      "Epoch [1/179, loss:1.3325]\n",
      "Epoch [1/180, loss:1.4305]\n",
      "Epoch [1/181, loss:1.2595]\n",
      "Epoch [1/182, loss:1.3297]\n",
      "Epoch [1/183, loss:1.2621]\n",
      "Epoch [1/184, loss:1.3899]\n",
      "Epoch [1/185, loss:1.3212]\n",
      "Epoch [1/186, loss:1.3450]\n",
      "Epoch [1/187, loss:1.3485]\n",
      "Epoch [1/188, loss:1.3443]\n",
      "Epoch [1/189, loss:1.3438]\n",
      "Epoch [1/190, loss:1.2637]\n",
      "Epoch [1/191, loss:1.3396]\n",
      "Epoch [1/192, loss:1.4220]\n",
      "Epoch [1/193, loss:1.2027]\n",
      "Epoch [1/194, loss:1.2922]\n",
      "Epoch [1/195, loss:1.3173]\n",
      "Epoch [1/196, loss:1.3746]\n",
      "Epoch [1/197, loss:1.1708]\n",
      "Epoch [1/198, loss:1.3093]\n",
      "Epoch [1/199, loss:1.3150]\n",
      "Epoch [1/200, loss:0.9683]\n",
      "Epoch [2/1, loss:1.3101]\n",
      "Epoch [2/2, loss:1.3296]\n",
      "Epoch [2/3, loss:1.3252]\n",
      "Epoch [2/4, loss:0.9786]\n",
      "Epoch [2/5, loss:1.0574]\n",
      "Epoch [2/6, loss:1.3494]\n",
      "Epoch [2/7, loss:0.9254]\n",
      "Epoch [2/8, loss:0.9475]\n",
      "Epoch [2/9, loss:0.9573]\n",
      "Epoch [2/10, loss:1.3483]\n",
      "Epoch [2/11, loss:0.6971]\n",
      "Epoch [2/12, loss:1.7664]\n",
      "Epoch [2/13, loss:1.3453]\n",
      "Epoch [2/14, loss:1.3486]\n",
      "Epoch [2/15, loss:1.3785]\n",
      "Epoch [2/16, loss:0.5886]\n",
      "Epoch [2/17, loss:0.5271]\n",
      "Epoch [2/18, loss:1.5033]\n",
      "Epoch [2/19, loss:0.9169]\n",
      "Epoch [2/20, loss:0.7932]\n",
      "Epoch [2/21, loss:1.3415]\n",
      "Epoch [2/22, loss:0.9460]\n",
      "Epoch [2/23, loss:1.3452]\n",
      "Epoch [2/24, loss:0.9451]\n",
      "Epoch [2/25, loss:1.3483]\n",
      "Epoch [2/26, loss:0.5496]\n",
      "Epoch [2/27, loss:0.7858]\n",
      "Epoch [2/28, loss:0.6255]\n",
      "Epoch [2/29, loss:1.1378]\n",
      "Epoch [2/30, loss:1.5157]\n",
      "Epoch [2/31, loss:0.9275]\n",
      "Epoch [2/32, loss:1.4048]\n",
      "Epoch [2/33, loss:1.7212]\n",
      "Epoch [2/34, loss:1.3178]\n",
      "Epoch [2/35, loss:0.4117]\n",
      "Epoch [2/36, loss:0.2758]\n",
      "Epoch [2/37, loss:1.3609]\n",
      "Epoch [2/38, loss:0.7363]\n",
      "Epoch [2/39, loss:0.6363]\n",
      "Epoch [2/40, loss:1.4733]\n",
      "Epoch [2/41, loss:0.7263]\n",
      "Epoch [2/42, loss:1.3937]\n",
      "Epoch [2/43, loss:0.2107]\n",
      "Epoch [2/44, loss:1.3561]\n",
      "Epoch [2/45, loss:1.4456]\n",
      "Epoch [2/46, loss:0.3136]\n",
      "Epoch [2/47, loss:0.5137]\n",
      "Epoch [2/48, loss:0.2887]\n",
      "Epoch [2/49, loss:1.6536]\n",
      "Epoch [2/50, loss:1.6181]\n",
      "Epoch [2/51, loss:1.5117]\n",
      "Epoch [2/52, loss:1.3670]\n",
      "Epoch [2/53, loss:3.0711]\n",
      "Epoch [2/54, loss:1.4896]\n",
      "Epoch [2/55, loss:2.0690]\n",
      "Epoch [2/56, loss:1.3160]\n",
      "Epoch [2/57, loss:0.4271]\n",
      "Epoch [2/58, loss:0.4427]\n",
      "Epoch [2/59, loss:1.2829]\n",
      "Epoch [2/60, loss:1.3151]\n",
      "Epoch [2/61, loss:2.2673]\n",
      "Epoch [2/62, loss:0.7606]\n",
      "Epoch [2/63, loss:0.9345]\n",
      "Epoch [2/64, loss:1.4099]\n",
      "Epoch [2/65, loss:0.2906]\n",
      "Epoch [2/66, loss:1.3947]\n",
      "Epoch [2/67, loss:0.9578]\n",
      "Epoch [2/68, loss:1.3831]\n",
      "Epoch [2/69, loss:1.3728]\n",
      "Epoch [2/70, loss:1.2847]\n",
      "Epoch [2/71, loss:1.6984]\n",
      "Epoch [2/72, loss:0.4459]\n",
      "Epoch [2/73, loss:0.5809]\n",
      "Epoch [2/74, loss:1.3679]\n",
      "Epoch [2/75, loss:0.4085]\n",
      "Epoch [2/76, loss:2.3825]\n",
      "Epoch [2/77, loss:1.2446]\n",
      "Epoch [2/78, loss:0.2543]\n",
      "Epoch [2/79, loss:1.3086]\n",
      "Epoch [2/80, loss:1.3976]\n",
      "Epoch [2/81, loss:1.2786]\n",
      "Epoch [2/82, loss:1.3676]\n",
      "Epoch [2/83, loss:1.2490]\n",
      "Epoch [2/84, loss:1.2172]\n",
      "Epoch [2/85, loss:0.7671]\n",
      "Epoch [2/86, loss:0.3834]\n",
      "Epoch [2/87, loss:1.2450]\n",
      "Epoch [2/88, loss:1.4878]\n",
      "Epoch [2/89, loss:1.0773]\n",
      "Epoch [2/90, loss:0.4989]\n",
      "Epoch [2/91, loss:1.4355]\n",
      "Epoch [2/92, loss:2.3095]\n",
      "Epoch [2/93, loss:1.1410]\n",
      "Epoch [2/94, loss:1.2150]\n",
      "Epoch [2/95, loss:1.6096]\n",
      "Epoch [2/96, loss:0.3445]\n",
      "Epoch [2/97, loss:1.2690]\n",
      "Epoch [2/98, loss:1.5207]\n",
      "Epoch [2/99, loss:0.3676]\n",
      "Epoch [2/100, loss:0.3656]\n",
      "Epoch [2/101, loss:0.3389]\n",
      "Epoch [2/102, loss:2.1874]\n",
      "Epoch [2/103, loss:1.3139]\n",
      "Epoch [2/104, loss:1.3118]\n",
      "Epoch [2/105, loss:1.6028]\n",
      "Epoch [2/106, loss:0.1949]\n",
      "Epoch [2/107, loss:1.4052]\n",
      "Epoch [2/108, loss:0.3541]\n",
      "Epoch [2/109, loss:1.4727]\n",
      "Epoch [2/110, loss:0.3737]\n",
      "Epoch [2/111, loss:0.6483]\n",
      "Epoch [2/112, loss:0.5928]\n",
      "Epoch [2/113, loss:1.2152]\n",
      "Epoch [2/114, loss:1.3488]\n",
      "Epoch [2/115, loss:0.2039]\n",
      "Epoch [2/116, loss:1.2137]\n",
      "Epoch [2/117, loss:1.4613]\n",
      "Epoch [2/118, loss:0.7809]\n",
      "Epoch [2/119, loss:1.2114]\n",
      "Epoch [2/120, loss:1.2437]\n",
      "Epoch [2/121, loss:1.3633]\n",
      "Epoch [2/122, loss:1.3220]\n",
      "Epoch [2/123, loss:0.5094]\n",
      "Epoch [2/124, loss:1.3041]\n",
      "Epoch [2/125, loss:1.2340]\n",
      "Epoch [2/126, loss:0.6668]\n",
      "Epoch [2/127, loss:0.2128]\n",
      "Epoch [2/128, loss:1.3918]\n",
      "Epoch [2/129, loss:0.8358]\n",
      "Epoch [2/130, loss:0.5130]\n",
      "Epoch [2/131, loss:1.8632]\n",
      "Epoch [2/132, loss:1.9438]\n",
      "Epoch [2/133, loss:1.6117]\n",
      "Epoch [2/134, loss:0.2865]\n",
      "Epoch [2/135, loss:1.2806]\n",
      "Epoch [2/136, loss:0.4649]\n",
      "Epoch [2/137, loss:0.2615]\n",
      "Epoch [2/138, loss:2.0969]\n",
      "Epoch [2/139, loss:1.9042]\n",
      "Epoch [2/140, loss:2.5389]\n",
      "Epoch [2/141, loss:1.3194]\n",
      "Epoch [2/142, loss:0.4683]\n",
      "Epoch [2/143, loss:0.6312]\n",
      "Epoch [2/144, loss:1.2281]\n",
      "Epoch [2/145, loss:1.8119]\n",
      "Epoch [2/146, loss:0.3550]\n",
      "Epoch [2/147, loss:0.6158]\n",
      "Epoch [2/148, loss:0.6275]\n",
      "Epoch [2/149, loss:1.3593]\n",
      "Epoch [2/150, loss:0.1571]\n",
      "Epoch [2/151, loss:1.9994]\n",
      "Epoch [2/152, loss:0.6400]\n",
      "Epoch [2/153, loss:1.2016]\n",
      "Epoch [2/154, loss:1.4734]\n",
      "Epoch [2/155, loss:1.2693]\n",
      "Epoch [2/156, loss:0.5248]\n",
      "Epoch [2/157, loss:0.4560]\n",
      "Epoch [2/158, loss:1.2059]\n",
      "Epoch [2/159, loss:1.2038]\n",
      "Epoch [2/160, loss:1.1826]\n",
      "Epoch [2/161, loss:0.5025]\n",
      "Epoch [2/162, loss:0.8847]\n",
      "Epoch [2/163, loss:1.1782]\n",
      "Epoch [2/164, loss:0.1999]\n",
      "Epoch [2/165, loss:1.6345]\n",
      "Epoch [2/166, loss:1.3253]\n",
      "Epoch [2/167, loss:1.9704]\n",
      "Epoch [2/168, loss:1.6355]\n",
      "Epoch [2/169, loss:1.2276]\n",
      "Epoch [2/170, loss:1.6029]\n",
      "Epoch [2/171, loss:1.3984]\n",
      "Epoch [2/172, loss:0.4956]\n",
      "Epoch [2/173, loss:1.2452]\n",
      "Epoch [2/174, loss:1.5823]\n",
      "Epoch [2/175, loss:0.4528]\n",
      "Epoch [2/176, loss:0.3260]\n",
      "Epoch [2/177, loss:1.7176]\n",
      "Epoch [2/178, loss:1.1909]\n",
      "Epoch [2/179, loss:1.5347]\n",
      "Epoch [2/180, loss:1.0450]\n",
      "Epoch [2/181, loss:0.6506]\n",
      "Epoch [2/182, loss:1.5357]\n",
      "Epoch [2/183, loss:0.6683]\n",
      "Epoch [2/184, loss:1.5102]\n",
      "Epoch [2/185, loss:1.2417]\n",
      "Epoch [2/186, loss:1.1938]\n",
      "Epoch [2/187, loss:1.2281]\n",
      "Epoch [2/188, loss:1.2563]\n",
      "Epoch [2/189, loss:1.1701]\n",
      "Epoch [2/190, loss:0.4973]\n",
      "Epoch [2/191, loss:1.1846]\n",
      "Epoch [2/192, loss:1.3348]\n",
      "Epoch [2/193, loss:0.4204]\n",
      "Epoch [2/194, loss:0.7512]\n",
      "Epoch [2/195, loss:0.7482]\n",
      "Epoch [2/196, loss:2.4898]\n",
      "Epoch [2/197, loss:0.4656]\n",
      "Epoch [2/198, loss:1.1873]\n",
      "Epoch [2/199, loss:0.7622]\n",
      "Epoch [2/200, loss:0.2823]\n",
      "Epoch [3/1, loss:1.2377]\n",
      "Epoch [3/2, loss:0.8989]\n",
      "Epoch [3/3, loss:0.7628]\n",
      "Epoch [3/4, loss:0.2747]\n",
      "Epoch [3/5, loss:0.3623]\n",
      "Epoch [3/6, loss:1.1781]\n",
      "Epoch [3/7, loss:0.2645]\n",
      "Epoch [3/8, loss:0.3357]\n",
      "Epoch [3/9, loss:0.3521]\n",
      "Epoch [3/10, loss:1.1659]\n",
      "Epoch [3/11, loss:0.1904]\n",
      "Epoch [3/12, loss:2.3184]\n",
      "Epoch [3/13, loss:1.1558]\n",
      "Epoch [3/14, loss:1.1825]\n",
      "Epoch [3/15, loss:1.4558]\n",
      "Epoch [3/16, loss:0.1681]\n",
      "Epoch [3/17, loss:0.1544]\n",
      "Epoch [3/18, loss:1.7544]\n",
      "Epoch [3/19, loss:0.4051]\n",
      "Epoch [3/20, loss:0.3097]\n",
      "Epoch [3/21, loss:1.1406]\n",
      "Epoch [3/22, loss:0.5176]\n",
      "Epoch [3/23, loss:1.1316]\n",
      "Epoch [3/24, loss:0.6135]\n",
      "Epoch [3/25, loss:1.3020]\n",
      "Epoch [3/26, loss:0.2297]\n",
      "Epoch [3/27, loss:0.5265]\n",
      "Epoch [3/28, loss:0.3426]\n",
      "Epoch [3/29, loss:0.7448]\n",
      "Epoch [3/30, loss:1.4494]\n",
      "Epoch [3/31, loss:0.5708]\n",
      "Epoch [3/32, loss:1.0291]\n",
      "Epoch [3/33, loss:1.9025]\n",
      "Epoch [3/34, loss:1.1206]\n",
      "Epoch [3/35, loss:0.2244]\n",
      "Epoch [3/36, loss:0.1477]\n",
      "Epoch [3/37, loss:1.1614]\n",
      "Epoch [3/38, loss:0.5129]\n",
      "Epoch [3/39, loss:0.4293]\n",
      "Epoch [3/40, loss:1.4017]\n",
      "Epoch [3/41, loss:0.4394]\n",
      "Epoch [3/42, loss:1.2111]\n",
      "Epoch [3/43, loss:0.0909]\n",
      "Epoch [3/44, loss:1.1777]\n",
      "Epoch [3/45, loss:1.3580]\n",
      "Epoch [3/46, loss:0.2241]\n",
      "Epoch [3/47, loss:0.3827]\n",
      "Epoch [3/48, loss:0.2154]\n",
      "Epoch [3/49, loss:1.5327]\n",
      "Epoch [3/50, loss:1.4594]\n",
      "Epoch [3/51, loss:1.4289]\n",
      "Epoch [3/52, loss:1.1198]\n",
      "Epoch [3/53, loss:3.6817]\n",
      "Epoch [3/54, loss:1.3518]\n",
      "Epoch [3/55, loss:2.6078]\n",
      "Epoch [3/56, loss:1.0833]\n",
      "Epoch [3/57, loss:0.3555]\n",
      "Epoch [3/58, loss:0.3125]\n",
      "Epoch [3/59, loss:1.0546]\n",
      "Epoch [3/60, loss:1.0951]\n",
      "Epoch [3/61, loss:2.7867]\n",
      "Epoch [3/62, loss:0.6400]\n",
      "Epoch [3/63, loss:1.0351]\n",
      "Epoch [3/64, loss:1.3894]\n",
      "Epoch [3/65, loss:0.1700]\n",
      "Epoch [3/66, loss:1.2208]\n",
      "Epoch [3/67, loss:0.8193]\n",
      "Epoch [3/68, loss:1.2443]\n",
      "Epoch [3/69, loss:1.1786]\n",
      "Epoch [3/70, loss:1.0447]\n",
      "Epoch [3/71, loss:1.8392]\n",
      "Epoch [3/72, loss:0.2451]\n",
      "Epoch [3/73, loss:0.3824]\n",
      "Epoch [3/74, loss:1.2103]\n",
      "Epoch [3/75, loss:0.2792]\n",
      "Epoch [3/76, loss:2.4976]\n",
      "Epoch [3/77, loss:1.0503]\n",
      "Epoch [3/78, loss:0.1510]\n",
      "Epoch [3/79, loss:1.1281]\n",
      "Epoch [3/80, loss:1.3408]\n",
      "Epoch [3/81, loss:1.0448]\n",
      "Epoch [3/82, loss:1.2045]\n",
      "Epoch [3/83, loss:1.0010]\n",
      "Epoch [3/84, loss:1.1581]\n",
      "Epoch [3/85, loss:0.8572]\n",
      "Epoch [3/86, loss:0.2499]\n",
      "Epoch [3/87, loss:1.0133]\n",
      "Epoch [3/88, loss:1.4466]\n",
      "Epoch [3/89, loss:0.8942]\n",
      "Epoch [3/90, loss:0.5810]\n",
      "Epoch [3/91, loss:1.3054]\n",
      "Epoch [3/92, loss:2.3946]\n",
      "Epoch [3/93, loss:1.2600]\n",
      "Epoch [3/94, loss:0.9746]\n",
      "Epoch [3/95, loss:1.8580]\n",
      "Epoch [3/96, loss:0.2498]\n",
      "Epoch [3/97, loss:1.0914]\n",
      "Epoch [3/98, loss:1.4144]\n",
      "Epoch [3/99, loss:0.4506]\n",
      "Epoch [3/100, loss:0.4398]\n",
      "Epoch [3/101, loss:0.2160]\n",
      "Epoch [3/102, loss:2.2145]\n",
      "Epoch [3/103, loss:1.1371]\n",
      "Epoch [3/104, loss:1.0437]\n",
      "Epoch [3/105, loss:1.6333]\n",
      "Epoch [3/106, loss:0.1352]\n",
      "Epoch [3/107, loss:1.3613]\n",
      "Epoch [3/108, loss:0.4141]\n",
      "Epoch [3/109, loss:1.3032]\n",
      "Epoch [3/110, loss:0.4328]\n",
      "Epoch [3/111, loss:0.5684]\n",
      "Epoch [3/112, loss:0.4811]\n",
      "Epoch [3/113, loss:0.9912]\n",
      "Epoch [3/114, loss:1.2255]\n",
      "Epoch [3/115, loss:0.2563]\n",
      "Epoch [3/116, loss:0.9915]\n",
      "Epoch [3/117, loss:1.2743]\n",
      "Epoch [3/118, loss:0.8101]\n",
      "Epoch [3/119, loss:0.9928]\n",
      "Epoch [3/120, loss:1.1273]\n",
      "Epoch [3/121, loss:1.2344]\n",
      "Epoch [3/122, loss:1.1589]\n",
      "Epoch [3/123, loss:0.5192]\n",
      "Epoch [3/124, loss:1.1457]\n",
      "Epoch [3/125, loss:1.0796]\n",
      "Epoch [3/126, loss:0.7057]\n",
      "Epoch [3/127, loss:0.2511]\n",
      "Epoch [3/128, loss:1.1221]\n",
      "Epoch [3/129, loss:0.8396]\n",
      "Epoch [3/130, loss:0.5656]\n",
      "Epoch [3/131, loss:1.7454]\n",
      "Epoch [3/132, loss:1.9337]\n",
      "Epoch [3/133, loss:1.4792]\n",
      "Epoch [3/134, loss:0.3237]\n",
      "Epoch [3/135, loss:1.1065]\n",
      "Epoch [3/136, loss:0.3563]\n",
      "Epoch [3/137, loss:0.2855]\n",
      "Epoch [3/138, loss:2.1185]\n",
      "Epoch [3/139, loss:1.7542]\n",
      "Epoch [3/140, loss:2.7990]\n",
      "Epoch [3/141, loss:1.0968]\n",
      "Epoch [3/142, loss:0.4794]\n",
      "Epoch [3/143, loss:0.5201]\n",
      "Epoch [3/144, loss:1.0437]\n",
      "Epoch [3/145, loss:1.5648]\n",
      "Epoch [3/146, loss:0.2864]\n",
      "Epoch [3/147, loss:0.6463]\n",
      "Epoch [3/148, loss:0.5561]\n",
      "Epoch [3/149, loss:1.1593]\n",
      "Epoch [3/150, loss:0.1641]\n",
      "Epoch [3/151, loss:2.1129]\n",
      "Epoch [3/152, loss:0.6596]\n",
      "Epoch [3/153, loss:1.0310]\n",
      "Epoch [3/154, loss:1.2824]\n",
      "Epoch [3/155, loss:1.0415]\n",
      "Epoch [3/156, loss:0.4316]\n",
      "Epoch [3/157, loss:0.3603]\n",
      "Epoch [3/158, loss:1.0202]\n",
      "Epoch [3/159, loss:1.2777]\n",
      "Epoch [3/160, loss:1.0148]\n",
      "Epoch [3/161, loss:0.4892]\n",
      "Epoch [3/162, loss:0.9459]\n",
      "Epoch [3/163, loss:1.2044]\n",
      "Epoch [3/164, loss:0.1750]\n",
      "Epoch [3/165, loss:1.5313]\n",
      "Epoch [3/166, loss:1.2748]\n",
      "Epoch [3/167, loss:1.8832]\n",
      "Epoch [3/168, loss:1.6551]\n",
      "Epoch [3/169, loss:1.2445]\n",
      "Epoch [3/170, loss:1.6360]\n",
      "Epoch [3/171, loss:1.2102]\n",
      "Epoch [3/172, loss:0.5174]\n",
      "Epoch [3/173, loss:1.0661]\n",
      "Epoch [3/174, loss:1.4225]\n",
      "Epoch [3/175, loss:0.4053]\n",
      "Epoch [3/176, loss:0.3013]\n",
      "Epoch [3/177, loss:1.7290]\n",
      "Epoch [3/178, loss:1.0482]\n",
      "Epoch [3/179, loss:1.3636]\n",
      "Epoch [3/180, loss:1.1949]\n",
      "Epoch [3/181, loss:0.6307]\n",
      "Epoch [3/182, loss:1.3452]\n",
      "Epoch [3/183, loss:0.6407]\n",
      "Epoch [3/184, loss:1.6837]\n",
      "Epoch [3/185, loss:1.0542]\n",
      "Epoch [3/186, loss:1.0101]\n",
      "Epoch [3/187, loss:1.0671]\n",
      "Epoch [3/188, loss:1.1199]\n",
      "Epoch [3/189, loss:1.0009]\n",
      "Epoch [3/190, loss:0.4797]\n",
      "Epoch [3/191, loss:1.0105]\n",
      "Epoch [3/192, loss:1.5259]\n",
      "Epoch [3/193, loss:0.3977]\n",
      "Epoch [3/194, loss:0.7741]\n",
      "Epoch [3/195, loss:0.7308]\n",
      "Epoch [3/196, loss:2.7012]\n",
      "Epoch [3/197, loss:0.4561]\n",
      "Epoch [3/198, loss:0.9953]\n",
      "Epoch [3/199, loss:0.7526]\n",
      "Epoch [3/200, loss:0.2753]\n",
      "Epoch [4/1, loss:1.0613]\n",
      "Epoch [4/2, loss:0.8268]\n",
      "Epoch [4/3, loss:0.7111]\n",
      "Epoch [4/4, loss:0.2638]\n",
      "Epoch [4/5, loss:0.3425]\n",
      "Epoch [4/6, loss:1.0141]\n",
      "Epoch [4/7, loss:0.2496]\n",
      "Epoch [4/8, loss:0.3257]\n",
      "Epoch [4/9, loss:0.3348]\n",
      "Epoch [4/10, loss:1.0687]\n",
      "Epoch [4/11, loss:0.1768]\n",
      "Epoch [4/12, loss:2.5053]\n",
      "Epoch [4/13, loss:1.0094]\n",
      "Epoch [4/14, loss:1.0512]\n",
      "Epoch [4/15, loss:1.3608]\n",
      "Epoch [4/16, loss:0.1557]\n",
      "Epoch [4/17, loss:0.1459]\n",
      "Epoch [4/18, loss:1.6130]\n",
      "Epoch [4/19, loss:0.3836]\n",
      "Epoch [4/20, loss:0.2895]\n",
      "Epoch [4/21, loss:1.0046]\n",
      "Epoch [4/22, loss:0.5127]\n",
      "Epoch [4/23, loss:0.9721]\n",
      "Epoch [4/24, loss:0.6125]\n",
      "Epoch [4/25, loss:1.1906]\n",
      "Epoch [4/26, loss:0.2261]\n",
      "Epoch [4/27, loss:0.5553]\n",
      "Epoch [4/28, loss:0.3402]\n",
      "Epoch [4/29, loss:0.7321]\n",
      "Epoch [4/30, loss:1.1116]\n",
      "Epoch [4/31, loss:0.5927]\n",
      "Epoch [4/32, loss:0.9773]\n",
      "Epoch [4/33, loss:1.7917]\n",
      "Epoch [4/34, loss:0.9774]\n",
      "Epoch [4/35, loss:0.2188]\n",
      "Epoch [4/36, loss:0.1401]\n",
      "Epoch [4/37, loss:1.0178]\n",
      "Epoch [4/38, loss:0.5193]\n",
      "Epoch [4/39, loss:0.4175]\n",
      "Epoch [4/40, loss:1.2691]\n",
      "Epoch [4/41, loss:0.3665]\n",
      "Epoch [4/42, loss:1.0638]\n",
      "Epoch [4/43, loss:0.0914]\n",
      "Epoch [4/44, loss:1.0406]\n",
      "Epoch [4/45, loss:1.2580]\n",
      "Epoch [4/46, loss:0.2185]\n",
      "Epoch [4/47, loss:0.3698]\n",
      "Epoch [4/48, loss:0.2126]\n",
      "Epoch [4/49, loss:1.3699]\n",
      "Epoch [4/50, loss:1.2773]\n",
      "Epoch [4/51, loss:1.3542]\n",
      "Epoch [4/52, loss:0.9760]\n",
      "Epoch [4/53, loss:3.7577]\n",
      "Epoch [4/54, loss:1.2434]\n",
      "Epoch [4/55, loss:2.7421]\n",
      "Epoch [4/56, loss:0.9239]\n",
      "Epoch [4/57, loss:0.3729]\n",
      "Epoch [4/58, loss:0.2855]\n",
      "Epoch [4/59, loss:0.9041]\n",
      "Epoch [4/60, loss:0.9518]\n",
      "Epoch [4/61, loss:2.8840]\n",
      "Epoch [4/62, loss:0.6899]\n",
      "Epoch [4/63, loss:1.0651]\n",
      "Epoch [4/64, loss:1.1754]\n",
      "Epoch [4/65, loss:0.1515]\n",
      "Epoch [4/66, loss:1.0570]\n",
      "Epoch [4/67, loss:0.8580]\n",
      "Epoch [4/68, loss:1.0976]\n",
      "Epoch [4/69, loss:1.0082]\n",
      "Epoch [4/70, loss:0.8906]\n",
      "Epoch [4/71, loss:1.6887]\n",
      "Epoch [4/72, loss:0.2058]\n",
      "Epoch [4/73, loss:0.3523]\n",
      "Epoch [4/74, loss:1.0347]\n",
      "Epoch [4/75, loss:0.2664]\n",
      "Epoch [4/76, loss:2.4138]\n",
      "Epoch [4/77, loss:0.9143]\n",
      "Epoch [4/78, loss:0.1393]\n",
      "Epoch [4/79, loss:0.9387]\n",
      "Epoch [4/80, loss:1.2822]\n",
      "Epoch [4/81, loss:0.8818]\n",
      "Epoch [4/82, loss:1.0160]\n",
      "Epoch [4/83, loss:0.8555]\n",
      "Epoch [4/84, loss:1.2687]\n",
      "Epoch [4/85, loss:0.9267]\n",
      "Epoch [4/86, loss:0.2334]\n",
      "Epoch [4/87, loss:0.8741]\n",
      "Epoch [4/88, loss:1.2310]\n",
      "Epoch [4/89, loss:0.8536]\n",
      "Epoch [4/90, loss:0.6420]\n",
      "Epoch [4/91, loss:1.1440]\n",
      "Epoch [4/92, loss:2.3095]\n",
      "Epoch [4/93, loss:1.4092]\n",
      "Epoch [4/94, loss:0.8183]\n",
      "Epoch [4/95, loss:1.9690]\n",
      "Epoch [4/96, loss:0.2415]\n",
      "Epoch [4/97, loss:0.9303]\n",
      "Epoch [4/98, loss:1.2712]\n",
      "Epoch [4/99, loss:0.4857]\n",
      "Epoch [4/100, loss:0.4732]\n",
      "Epoch [4/101, loss:0.1968]\n",
      "Epoch [4/102, loss:2.0789]\n",
      "Epoch [4/103, loss:0.9813]\n",
      "Epoch [4/104, loss:0.9136]\n",
      "Epoch [4/105, loss:1.4535]\n",
      "Epoch [4/106, loss:0.1407]\n",
      "Epoch [4/107, loss:1.2485]\n",
      "Epoch [4/108, loss:0.4391]\n",
      "Epoch [4/109, loss:0.9814]\n",
      "Epoch [4/110, loss:0.4374]\n",
      "Epoch [4/111, loss:0.5639]\n",
      "Epoch [4/112, loss:0.4706]\n",
      "Epoch [4/113, loss:0.8645]\n",
      "Epoch [4/114, loss:0.9898]\n",
      "Epoch [4/115, loss:0.2435]\n",
      "Epoch [4/116, loss:0.8624]\n",
      "Epoch [4/117, loss:1.0880]\n",
      "Epoch [4/118, loss:0.8936]\n",
      "Epoch [4/119, loss:0.8595]\n",
      "Epoch [4/120, loss:1.0758]\n",
      "Epoch [4/121, loss:1.0918]\n",
      "Epoch [4/122, loss:1.0082]\n",
      "Epoch [4/123, loss:0.5012]\n",
      "Epoch [4/124, loss:0.9773]\n",
      "Epoch [4/125, loss:0.9476]\n",
      "Epoch [4/126, loss:0.7173]\n",
      "Epoch [4/127, loss:0.2246]\n",
      "Epoch [4/128, loss:1.0132]\n",
      "Epoch [4/129, loss:0.8822]\n",
      "Epoch [4/130, loss:0.5586]\n",
      "Epoch [4/131, loss:1.5457]\n",
      "Epoch [4/132, loss:1.7206]\n",
      "Epoch [4/133, loss:1.2568]\n",
      "Epoch [4/134, loss:0.3040]\n",
      "Epoch [4/135, loss:0.8938]\n",
      "Epoch [4/136, loss:0.3448]\n",
      "Epoch [4/137, loss:0.2498]\n",
      "Epoch [4/138, loss:1.9395]\n",
      "Epoch [4/139, loss:1.5028]\n",
      "Epoch [4/140, loss:3.2988]\n",
      "Epoch [4/141, loss:0.9992]\n",
      "Epoch [4/142, loss:0.4540]\n",
      "Epoch [4/143, loss:0.5132]\n",
      "Epoch [4/144, loss:0.9299]\n",
      "Epoch [4/145, loss:1.5739]\n",
      "Epoch [4/146, loss:0.3155]\n",
      "Epoch [4/147, loss:0.6446]\n",
      "Epoch [4/148, loss:0.5594]\n",
      "Epoch [4/149, loss:0.9500]\n",
      "Epoch [4/150, loss:0.1255]\n",
      "Epoch [4/151, loss:2.0881]\n",
      "Epoch [4/152, loss:0.6706]\n",
      "Epoch [4/153, loss:0.9279]\n",
      "Epoch [4/154, loss:1.0702]\n",
      "Epoch [4/155, loss:0.9507]\n",
      "Epoch [4/156, loss:0.4509]\n",
      "Epoch [4/157, loss:0.3698]\n",
      "Epoch [4/158, loss:0.9202]\n",
      "Epoch [4/159, loss:1.3228]\n",
      "Epoch [4/160, loss:0.9100]\n",
      "Epoch [4/161, loss:0.4494]\n",
      "Epoch [4/162, loss:0.9884]\n",
      "Epoch [4/163, loss:1.3183]\n",
      "Epoch [4/164, loss:0.2139]\n",
      "Epoch [4/165, loss:1.3236]\n",
      "Epoch [4/166, loss:1.2441]\n",
      "Epoch [4/167, loss:1.5461]\n",
      "Epoch [4/168, loss:1.6067]\n",
      "Epoch [4/169, loss:1.3969]\n",
      "Epoch [4/170, loss:1.5315]\n",
      "Epoch [4/171, loss:1.0118]\n",
      "Epoch [4/172, loss:0.5567]\n",
      "Epoch [4/173, loss:0.8615]\n",
      "Epoch [4/174, loss:1.2229]\n",
      "Epoch [4/175, loss:0.4325]\n",
      "Epoch [4/176, loss:0.3363]\n",
      "Epoch [4/177, loss:1.5296]\n",
      "Epoch [4/178, loss:1.0267]\n",
      "Epoch [4/179, loss:1.1590]\n",
      "Epoch [4/180, loss:1.3769]\n",
      "Epoch [4/181, loss:0.5813]\n",
      "Epoch [4/182, loss:1.1261]\n",
      "Epoch [4/183, loss:0.5514]\n",
      "Epoch [4/184, loss:1.9676]\n",
      "Epoch [4/185, loss:0.8816]\n",
      "Epoch [4/186, loss:0.8995]\n",
      "Epoch [4/187, loss:1.0087]\n",
      "Epoch [4/188, loss:1.0102]\n",
      "Epoch [4/189, loss:0.9048]\n",
      "Epoch [4/190, loss:0.5203]\n",
      "Epoch [4/191, loss:0.9029]\n",
      "Epoch [4/192, loss:1.6306]\n",
      "Epoch [4/193, loss:0.4385]\n",
      "Epoch [4/194, loss:0.8164]\n",
      "Epoch [4/195, loss:0.6873]\n",
      "Epoch [4/196, loss:2.8499]\n",
      "Epoch [4/197, loss:0.3884]\n",
      "Epoch [4/198, loss:0.7601]\n",
      "Epoch [4/199, loss:0.6940]\n",
      "Epoch [4/200, loss:0.2160]\n",
      "Epoch [5/1, loss:0.8158]\n",
      "Epoch [5/2, loss:0.8100]\n",
      "Epoch [5/3, loss:0.6559]\n",
      "Epoch [5/4, loss:0.2975]\n",
      "Epoch [5/5, loss:0.3666]\n",
      "Epoch [5/6, loss:0.9049]\n",
      "Epoch [5/7, loss:0.2787]\n",
      "Epoch [5/8, loss:0.3403]\n",
      "Epoch [5/9, loss:0.3442]\n",
      "Epoch [5/10, loss:1.0536]\n",
      "Epoch [5/11, loss:0.1234]\n",
      "Epoch [5/12, loss:2.8803]\n",
      "Epoch [5/13, loss:0.9272]\n",
      "Epoch [5/14, loss:0.9198]\n",
      "Epoch [5/15, loss:1.4785]\n",
      "Epoch [5/16, loss:0.1114]\n",
      "Epoch [5/17, loss:0.1069]\n",
      "Epoch [5/18, loss:1.4965]\n",
      "Epoch [5/19, loss:0.3963]\n",
      "Epoch [5/20, loss:0.2929]\n",
      "Epoch [5/21, loss:0.9277]\n",
      "Epoch [5/22, loss:0.4764]\n",
      "Epoch [5/23, loss:0.8572]\n",
      "Epoch [5/24, loss:0.6331]\n",
      "Epoch [5/25, loss:0.9921]\n",
      "Epoch [5/26, loss:0.2271]\n",
      "Epoch [5/27, loss:0.5674]\n",
      "Epoch [5/28, loss:0.3322]\n",
      "Epoch [5/29, loss:0.7045]\n",
      "Epoch [5/30, loss:0.8608]\n",
      "Epoch [5/31, loss:0.6157]\n",
      "Epoch [5/32, loss:0.9304]\n",
      "Epoch [5/33, loss:1.7004]\n",
      "Epoch [5/34, loss:0.8641]\n",
      "Epoch [5/35, loss:0.1877]\n",
      "Epoch [5/36, loss:0.1124]\n",
      "Epoch [5/37, loss:0.8964]\n",
      "Epoch [5/38, loss:0.4912]\n",
      "Epoch [5/39, loss:0.4109]\n",
      "Epoch [5/40, loss:1.1486]\n",
      "Epoch [5/41, loss:0.3422]\n",
      "Epoch [5/42, loss:0.9395]\n",
      "Epoch [5/43, loss:0.0970]\n",
      "Epoch [5/44, loss:0.9504]\n",
      "Epoch [5/45, loss:1.2200]\n",
      "Epoch [5/46, loss:0.1930]\n",
      "Epoch [5/47, loss:0.3471]\n",
      "Epoch [5/48, loss:0.1912]\n",
      "Epoch [5/49, loss:1.2692]\n",
      "Epoch [5/50, loss:1.1685]\n",
      "Epoch [5/51, loss:1.3443]\n",
      "Epoch [5/52, loss:0.8975]\n",
      "Epoch [5/53, loss:3.6562]\n",
      "Epoch [5/54, loss:1.2010]\n",
      "Epoch [5/55, loss:2.7453]\n",
      "Epoch [5/56, loss:0.7980]\n",
      "Epoch [5/57, loss:0.3754]\n",
      "Epoch [5/58, loss:0.2631]\n",
      "Epoch [5/59, loss:0.7846]\n",
      "Epoch [5/60, loss:0.8686]\n",
      "Epoch [5/61, loss:2.8435]\n",
      "Epoch [5/62, loss:0.7359]\n",
      "Epoch [5/63, loss:1.0152]\n",
      "Epoch [5/64, loss:0.8584]\n",
      "Epoch [5/65, loss:0.1410]\n",
      "Epoch [5/66, loss:0.8754]\n",
      "Epoch [5/67, loss:0.8975]\n",
      "Epoch [5/68, loss:0.9221]\n",
      "Epoch [5/69, loss:0.8735]\n",
      "Epoch [5/70, loss:0.7884]\n",
      "Epoch [5/71, loss:1.3886]\n",
      "Epoch [5/72, loss:0.1918]\n",
      "Epoch [5/73, loss:0.3588]\n",
      "Epoch [5/74, loss:0.8602]\n",
      "Epoch [5/75, loss:0.2707]\n",
      "Epoch [5/76, loss:2.3616]\n",
      "Epoch [5/77, loss:0.7714]\n",
      "Epoch [5/78, loss:0.1390]\n",
      "Epoch [5/79, loss:0.7603]\n",
      "Epoch [5/80, loss:1.2641]\n",
      "Epoch [5/81, loss:0.7561]\n",
      "Epoch [5/82, loss:0.8224]\n",
      "Epoch [5/83, loss:0.7330]\n",
      "Epoch [5/84, loss:1.3910]\n",
      "Epoch [5/85, loss:0.9316]\n",
      "Epoch [5/86, loss:0.2346]\n",
      "Epoch [5/87, loss:0.7922]\n",
      "Epoch [5/88, loss:0.9159]\n",
      "Epoch [5/89, loss:0.8993]\n",
      "Epoch [5/90, loss:0.6535]\n",
      "Epoch [5/91, loss:0.9752]\n",
      "Epoch [5/92, loss:2.2389]\n",
      "Epoch [5/93, loss:1.5398]\n",
      "Epoch [5/94, loss:0.7058]\n",
      "Epoch [5/95, loss:2.1137]\n",
      "Epoch [5/96, loss:0.2407]\n",
      "Epoch [5/97, loss:0.7938]\n",
      "Epoch [5/98, loss:1.1330]\n",
      "Epoch [5/99, loss:0.4746]\n",
      "Epoch [5/100, loss:0.4656]\n",
      "Epoch [5/101, loss:0.1944]\n",
      "Epoch [5/102, loss:1.8996]\n",
      "Epoch [5/103, loss:0.8680]\n",
      "Epoch [5/104, loss:0.8403]\n",
      "Epoch [5/105, loss:1.1070]\n",
      "Epoch [5/106, loss:0.1602]\n",
      "Epoch [5/107, loss:1.0697]\n",
      "Epoch [5/108, loss:0.4345]\n",
      "Epoch [5/109, loss:0.6632]\n",
      "Epoch [5/110, loss:0.4047]\n",
      "Epoch [5/111, loss:0.5501]\n",
      "Epoch [5/112, loss:0.4759]\n",
      "Epoch [5/113, loss:0.7790]\n",
      "Epoch [5/114, loss:0.7146]\n",
      "Epoch [5/115, loss:0.2039]\n",
      "Epoch [5/116, loss:0.7737]\n",
      "Epoch [5/117, loss:0.9183]\n",
      "Epoch [5/118, loss:1.0180]\n",
      "Epoch [5/119, loss:0.7640]\n",
      "Epoch [5/120, loss:1.0054]\n",
      "Epoch [5/121, loss:0.9210]\n",
      "Epoch [5/122, loss:0.8972]\n",
      "Epoch [5/123, loss:0.4586]\n",
      "Epoch [5/124, loss:0.7972]\n",
      "Epoch [5/125, loss:0.8067]\n",
      "Epoch [5/126, loss:0.6967]\n",
      "Epoch [5/127, loss:0.1813]\n",
      "Epoch [5/128, loss:0.9539]\n",
      "Epoch [5/129, loss:0.9220]\n",
      "Epoch [5/130, loss:0.5233]\n",
      "Epoch [5/131, loss:1.3605]\n",
      "Epoch [5/132, loss:1.3628]\n",
      "Epoch [5/133, loss:0.9905]\n",
      "Epoch [5/134, loss:0.2707]\n",
      "Epoch [5/135, loss:0.6822]\n",
      "Epoch [5/136, loss:0.3708]\n",
      "Epoch [5/137, loss:0.2057]\n",
      "Epoch [5/138, loss:1.6058]\n",
      "Epoch [5/139, loss:1.2385]\n",
      "Epoch [5/140, loss:3.8511]\n",
      "Epoch [5/141, loss:0.9303]\n",
      "Epoch [5/142, loss:0.4217]\n",
      "Epoch [5/143, loss:0.5404]\n",
      "Epoch [5/144, loss:0.8411]\n",
      "Epoch [5/145, loss:1.6322]\n",
      "Epoch [5/146, loss:0.3819]\n",
      "Epoch [5/147, loss:0.6305]\n",
      "Epoch [5/148, loss:0.5880]\n",
      "Epoch [5/149, loss:0.7716]\n",
      "Epoch [5/150, loss:0.0904]\n",
      "Epoch [5/151, loss:1.9589]\n",
      "Epoch [5/152, loss:0.6836]\n",
      "Epoch [5/153, loss:0.8493]\n",
      "Epoch [5/154, loss:0.9111]\n",
      "Epoch [5/155, loss:0.9919]\n",
      "Epoch [5/156, loss:0.5254]\n",
      "Epoch [5/157, loss:0.4012]\n",
      "Epoch [5/158, loss:0.8492]\n",
      "Epoch [5/159, loss:1.3583]\n",
      "Epoch [5/160, loss:0.8209]\n",
      "Epoch [5/161, loss:0.4010]\n",
      "Epoch [5/162, loss:0.9944]\n",
      "Epoch [5/163, loss:1.4398]\n",
      "Epoch [5/164, loss:0.2742]\n",
      "Epoch [5/165, loss:1.1229]\n",
      "Epoch [5/166, loss:1.2023]\n",
      "Epoch [5/167, loss:1.0838]\n",
      "Epoch [5/168, loss:1.5537]\n",
      "Epoch [5/169, loss:1.5831]\n",
      "Epoch [5/170, loss:1.3633]\n",
      "Epoch [5/171, loss:0.8636]\n",
      "Epoch [5/172, loss:0.5724]\n",
      "Epoch [5/173, loss:0.6682]\n",
      "Epoch [5/174, loss:1.0890]\n",
      "Epoch [5/175, loss:0.4625]\n",
      "Epoch [5/176, loss:0.3645]\n",
      "Epoch [5/177, loss:1.2381]\n",
      "Epoch [5/178, loss:1.0796]\n",
      "Epoch [5/179, loss:1.0136]\n",
      "Epoch [5/180, loss:1.5904]\n",
      "Epoch [5/181, loss:0.5095]\n",
      "Epoch [5/182, loss:0.9596]\n",
      "Epoch [5/183, loss:0.4412]\n",
      "Epoch [5/184, loss:2.1489]\n",
      "Epoch [5/185, loss:0.7608]\n",
      "Epoch [5/186, loss:0.8011]\n",
      "Epoch [5/187, loss:0.9930]\n",
      "Epoch [5/188, loss:0.8822]\n",
      "Epoch [5/189, loss:0.8273]\n",
      "Epoch [5/190, loss:0.5552]\n",
      "Epoch [5/191, loss:0.8101]\n",
      "Epoch [5/192, loss:1.7047]\n",
      "Epoch [5/193, loss:0.4694]\n",
      "Epoch [5/194, loss:0.8357]\n",
      "Epoch [5/195, loss:0.6379]\n",
      "Epoch [5/196, loss:2.9387]\n",
      "Epoch [5/197, loss:0.3220]\n",
      "Epoch [5/198, loss:0.5568]\n",
      "Epoch [5/199, loss:0.6293]\n",
      "Epoch [5/200, loss:0.1665]\n",
      "Epoch [6/1, loss:0.5853]\n",
      "Epoch [6/2, loss:0.7726]\n",
      "Epoch [6/3, loss:0.6089]\n",
      "Epoch [6/4, loss:0.3142]\n",
      "Epoch [6/5, loss:0.3712]\n",
      "Epoch [6/6, loss:0.7989]\n",
      "Epoch [6/7, loss:0.3032]\n",
      "Epoch [6/8, loss:0.3277]\n",
      "Epoch [6/9, loss:0.3306]\n",
      "Epoch [6/10, loss:1.1193]\n",
      "Epoch [6/11, loss:0.0850]\n",
      "Epoch [6/12, loss:3.2899]\n",
      "Epoch [6/13, loss:0.8595]\n",
      "Epoch [6/14, loss:0.8137]\n",
      "Epoch [6/15, loss:1.6282]\n",
      "Epoch [6/16, loss:0.0799]\n",
      "Epoch [6/17, loss:0.0787]\n",
      "Epoch [6/18, loss:1.3961]\n",
      "Epoch [6/19, loss:0.3828]\n",
      "Epoch [6/20, loss:0.2727]\n",
      "Epoch [6/21, loss:0.8667]\n",
      "Epoch [6/22, loss:0.4472]\n",
      "Epoch [6/23, loss:0.7517]\n",
      "Epoch [6/24, loss:0.6416]\n",
      "Epoch [6/25, loss:0.7963]\n",
      "Epoch [6/26, loss:0.2100]\n",
      "Epoch [6/27, loss:0.5408]\n",
      "Epoch [6/28, loss:0.3020]\n",
      "Epoch [6/29, loss:0.6904]\n",
      "Epoch [6/30, loss:0.8029]\n",
      "Epoch [6/31, loss:0.6473]\n",
      "Epoch [6/32, loss:0.9111]\n",
      "Epoch [6/33, loss:1.6126]\n",
      "Epoch [6/34, loss:0.7464]\n",
      "Epoch [6/35, loss:0.1626]\n",
      "Epoch [6/36, loss:0.0910]\n",
      "Epoch [6/37, loss:0.7707]\n",
      "Epoch [6/38, loss:0.4699]\n",
      "Epoch [6/39, loss:0.4060]\n",
      "Epoch [6/40, loss:0.9980]\n",
      "Epoch [6/41, loss:0.3678]\n",
      "Epoch [6/42, loss:0.8064]\n",
      "Epoch [6/43, loss:0.0976]\n",
      "Epoch [6/44, loss:0.8669]\n",
      "Epoch [6/45, loss:1.1709]\n",
      "Epoch [6/46, loss:0.1734]\n",
      "Epoch [6/47, loss:0.3065]\n",
      "Epoch [6/48, loss:0.1748]\n",
      "Epoch [6/49, loss:1.2335]\n",
      "Epoch [6/50, loss:1.1330]\n",
      "Epoch [6/51, loss:1.3228]\n",
      "Epoch [6/52, loss:0.8624]\n",
      "Epoch [6/53, loss:3.3657]\n",
      "Epoch [6/54, loss:1.1562]\n",
      "Epoch [6/55, loss:2.6620]\n",
      "Epoch [6/56, loss:0.6789]\n",
      "Epoch [6/57, loss:0.3808]\n",
      "Epoch [6/58, loss:0.2499]\n",
      "Epoch [6/59, loss:0.6765]\n",
      "Epoch [6/60, loss:0.8137]\n",
      "Epoch [6/61, loss:2.7210]\n",
      "Epoch [6/62, loss:0.7842]\n",
      "Epoch [6/63, loss:0.9225]\n",
      "Epoch [6/64, loss:0.6012]\n",
      "Epoch [6/65, loss:0.1250]\n",
      "Epoch [6/66, loss:0.7054]\n",
      "Epoch [6/67, loss:0.9420]\n",
      "Epoch [6/68, loss:0.7567]\n",
      "Epoch [6/69, loss:0.7564]\n",
      "Epoch [6/70, loss:0.7047]\n",
      "Epoch [6/71, loss:1.0236]\n",
      "Epoch [6/72, loss:0.1686]\n",
      "Epoch [6/73, loss:0.3423]\n",
      "Epoch [6/74, loss:0.6939]\n",
      "Epoch [6/75, loss:0.2593]\n",
      "Epoch [6/76, loss:2.3852]\n",
      "Epoch [6/77, loss:0.6557]\n",
      "Epoch [6/78, loss:0.1316]\n",
      "Epoch [6/79, loss:0.6242]\n",
      "Epoch [6/80, loss:1.3064]\n",
      "Epoch [6/81, loss:0.6577]\n",
      "Epoch [6/82, loss:0.6322]\n",
      "Epoch [6/83, loss:0.6515]\n",
      "Epoch [6/84, loss:1.4937]\n",
      "Epoch [6/85, loss:0.9212]\n",
      "Epoch [6/86, loss:0.2270]\n",
      "Epoch [6/87, loss:0.7396]\n",
      "Epoch [6/88, loss:0.6387]\n",
      "Epoch [6/89, loss:1.0103]\n",
      "Epoch [6/90, loss:0.6369]\n",
      "Epoch [6/91, loss:0.8082]\n",
      "Epoch [6/92, loss:2.2391]\n",
      "Epoch [6/93, loss:1.6273]\n",
      "Epoch [6/94, loss:0.6227]\n",
      "Epoch [6/95, loss:2.1992]\n",
      "Epoch [6/96, loss:0.2359]\n",
      "Epoch [6/97, loss:0.6646]\n",
      "Epoch [6/98, loss:0.9886]\n",
      "Epoch [6/99, loss:0.4424]\n",
      "Epoch [6/100, loss:0.4371]\n",
      "Epoch [6/101, loss:0.1929]\n",
      "Epoch [6/102, loss:1.7059]\n",
      "Epoch [6/103, loss:0.7537]\n",
      "Epoch [6/104, loss:0.7991]\n",
      "Epoch [6/105, loss:0.7418]\n",
      "Epoch [6/106, loss:0.1813]\n",
      "Epoch [6/107, loss:0.8861]\n",
      "Epoch [6/108, loss:0.4166]\n",
      "Epoch [6/109, loss:0.4436]\n",
      "Epoch [6/110, loss:0.3691]\n",
      "Epoch [6/111, loss:0.5103]\n",
      "Epoch [6/112, loss:0.4640]\n",
      "Epoch [6/113, loss:0.7110]\n",
      "Epoch [6/114, loss:0.4903]\n",
      "Epoch [6/115, loss:0.1646]\n",
      "Epoch [6/116, loss:0.7053]\n",
      "Epoch [6/117, loss:0.7930]\n",
      "Epoch [6/118, loss:1.0779]\n",
      "Epoch [6/119, loss:0.6905]\n",
      "Epoch [6/120, loss:0.9859]\n",
      "Epoch [6/121, loss:0.7630]\n",
      "Epoch [6/122, loss:0.8208]\n",
      "Epoch [6/123, loss:0.4234]\n",
      "Epoch [6/124, loss:0.6527]\n",
      "Epoch [6/125, loss:0.6882]\n",
      "Epoch [6/126, loss:0.6935]\n",
      "Epoch [6/127, loss:0.1448]\n",
      "Epoch [6/128, loss:0.9197]\n",
      "Epoch [6/129, loss:0.9636]\n",
      "Epoch [6/130, loss:0.5025]\n",
      "Epoch [6/131, loss:1.2676]\n",
      "Epoch [6/132, loss:0.9562]\n",
      "Epoch [6/133, loss:0.7115]\n",
      "Epoch [6/134, loss:0.2394]\n",
      "Epoch [6/135, loss:0.5121]\n",
      "Epoch [6/136, loss:0.3857]\n",
      "Epoch [6/137, loss:0.1689]\n",
      "Epoch [6/138, loss:1.2323]\n",
      "Epoch [6/139, loss:1.0327]\n",
      "Epoch [6/140, loss:4.1983]\n",
      "Epoch [6/141, loss:0.8909]\n",
      "Epoch [6/142, loss:0.3839]\n",
      "Epoch [6/143, loss:0.5638]\n",
      "Epoch [6/144, loss:0.7499]\n",
      "Epoch [6/145, loss:1.7252]\n",
      "Epoch [6/146, loss:0.4348]\n",
      "Epoch [6/147, loss:0.6098]\n",
      "Epoch [6/148, loss:0.6097]\n",
      "Epoch [6/149, loss:0.6472]\n",
      "Epoch [6/150, loss:0.0662]\n",
      "Epoch [6/151, loss:1.8235]\n",
      "Epoch [6/152, loss:0.6639]\n",
      "Epoch [6/153, loss:0.7687]\n",
      "Epoch [6/154, loss:0.8500]\n",
      "Epoch [6/155, loss:1.1016]\n",
      "Epoch [6/156, loss:0.6117]\n",
      "Epoch [6/157, loss:0.4088]\n",
      "Epoch [6/158, loss:0.7732]\n",
      "Epoch [6/159, loss:1.4303]\n",
      "Epoch [6/160, loss:0.7307]\n",
      "Epoch [6/161, loss:0.3628]\n",
      "Epoch [6/162, loss:0.9725]\n",
      "Epoch [6/163, loss:1.5244]\n",
      "Epoch [6/164, loss:0.3245]\n",
      "Epoch [6/165, loss:0.9795]\n",
      "Epoch [6/166, loss:1.1297]\n",
      "Epoch [6/167, loss:0.6531]\n",
      "Epoch [6/168, loss:1.4415]\n",
      "Epoch [6/169, loss:1.8324]\n",
      "Epoch [6/170, loss:1.1887]\n",
      "Epoch [6/171, loss:0.7883]\n",
      "Epoch [6/172, loss:0.5546]\n",
      "Epoch [6/173, loss:0.5077]\n",
      "Epoch [6/174, loss:1.0554]\n",
      "Epoch [6/175, loss:0.4430]\n",
      "Epoch [6/176, loss:0.3501]\n",
      "Epoch [6/177, loss:0.9252]\n",
      "Epoch [6/178, loss:1.0999]\n",
      "Epoch [6/179, loss:0.9441]\n",
      "Epoch [6/180, loss:1.7334]\n",
      "Epoch [6/181, loss:0.4663]\n",
      "Epoch [6/182, loss:0.8513]\n",
      "Epoch [6/183, loss:0.3841]\n",
      "Epoch [6/184, loss:2.2684]\n",
      "Epoch [6/185, loss:0.7089]\n",
      "Epoch [6/186, loss:0.6898]\n",
      "Epoch [6/187, loss:0.9794]\n",
      "Epoch [6/188, loss:0.7460]\n",
      "Epoch [6/189, loss:0.7501]\n",
      "Epoch [6/190, loss:0.5581]\n",
      "Epoch [6/191, loss:0.7147]\n",
      "Epoch [6/192, loss:1.7985]\n",
      "Epoch [6/193, loss:0.4599]\n",
      "Epoch [6/194, loss:0.8136]\n",
      "Epoch [6/195, loss:0.6274]\n",
      "Epoch [6/196, loss:2.9037]\n",
      "Epoch [6/197, loss:0.2880]\n",
      "Epoch [6/198, loss:0.3961]\n",
      "Epoch [6/199, loss:0.6092]\n",
      "Epoch [6/200, loss:0.1365]\n",
      "Epoch [7/1, loss:0.4018]\n",
      "Epoch [7/2, loss:0.6875]\n",
      "Epoch [7/3, loss:0.5850]\n",
      "Epoch [7/4, loss:0.3023]\n",
      "Epoch [7/5, loss:0.3485]\n",
      "Epoch [7/6, loss:0.6764]\n",
      "Epoch [7/7, loss:0.3163]\n",
      "Epoch [7/8, loss:0.2865]\n",
      "Epoch [7/9, loss:0.2931]\n",
      "Epoch [7/10, loss:1.2822]\n",
      "Epoch [7/11, loss:0.0636]\n",
      "Epoch [7/12, loss:3.5449]\n",
      "Epoch [7/13, loss:0.7770]\n",
      "Epoch [7/14, loss:0.7140]\n",
      "Epoch [7/15, loss:1.7086]\n",
      "Epoch [7/16, loss:0.0609]\n",
      "Epoch [7/17, loss:0.0613]\n",
      "Epoch [7/18, loss:1.2442]\n",
      "Epoch [7/19, loss:0.3337]\n",
      "Epoch [7/20, loss:0.2279]\n",
      "Epoch [7/21, loss:0.8098]\n",
      "Epoch [7/22, loss:0.4332]\n",
      "Epoch [7/23, loss:0.6433]\n",
      "Epoch [7/24, loss:0.6296]\n",
      "Epoch [7/25, loss:0.6455]\n",
      "Epoch [7/26, loss:0.1786]\n",
      "Epoch [7/27, loss:0.4823]\n",
      "Epoch [7/28, loss:0.2565]\n",
      "Epoch [7/29, loss:0.7074]\n",
      "Epoch [7/30, loss:0.9140]\n",
      "Epoch [7/31, loss:0.6829]\n",
      "Epoch [7/32, loss:0.9428]\n",
      "Epoch [7/33, loss:1.4736]\n",
      "Epoch [7/34, loss:0.6245]\n",
      "Epoch [7/35, loss:0.1427]\n",
      "Epoch [7/36, loss:0.0743]\n",
      "Epoch [7/37, loss:0.6351]\n",
      "Epoch [7/38, loss:0.4683]\n",
      "Epoch [7/39, loss:0.4106]\n",
      "Epoch [7/40, loss:0.8130]\n",
      "Epoch [7/41, loss:0.4525]\n",
      "Epoch [7/42, loss:0.6634]\n",
      "Epoch [7/43, loss:0.0941]\n",
      "Epoch [7/44, loss:0.7829]\n",
      "Epoch [7/45, loss:1.1066]\n",
      "Epoch [7/46, loss:0.1582]\n",
      "Epoch [7/47, loss:0.2476]\n",
      "Epoch [7/48, loss:0.1613]\n",
      "Epoch [7/49, loss:1.2479]\n",
      "Epoch [7/50, loss:1.1635]\n",
      "Epoch [7/51, loss:1.2804]\n",
      "Epoch [7/52, loss:0.8392]\n",
      "Epoch [7/53, loss:2.9605]\n",
      "Epoch [7/54, loss:1.0899]\n",
      "Epoch [7/55, loss:2.5339]\n",
      "Epoch [7/56, loss:0.5592]\n",
      "Epoch [7/57, loss:0.3866]\n",
      "Epoch [7/58, loss:0.2460]\n",
      "Epoch [7/59, loss:0.5827]\n",
      "Epoch [7/60, loss:0.7615]\n",
      "Epoch [7/61, loss:2.5701]\n",
      "Epoch [7/62, loss:0.8499]\n",
      "Epoch [7/63, loss:0.7680]\n",
      "Epoch [7/64, loss:0.4093]\n",
      "Epoch [7/65, loss:0.1027]\n",
      "Epoch [7/66, loss:0.5488]\n",
      "Epoch [7/67, loss:0.9940]\n",
      "Epoch [7/68, loss:0.6120]\n",
      "Epoch [7/69, loss:0.6466]\n",
      "Epoch [7/70, loss:0.6254]\n",
      "Epoch [7/71, loss:0.6863]\n",
      "Epoch [7/72, loss:0.1325]\n",
      "Epoch [7/73, loss:0.2820]\n",
      "Epoch [7/74, loss:0.5345]\n",
      "Epoch [7/75, loss:0.2226]\n",
      "Epoch [7/76, loss:2.4756]\n",
      "Epoch [7/77, loss:0.5634]\n",
      "Epoch [7/78, loss:0.1131]\n",
      "Epoch [7/79, loss:0.5180]\n",
      "Epoch [7/80, loss:1.4098]\n",
      "Epoch [7/81, loss:0.5814]\n",
      "Epoch [7/82, loss:0.4559]\n",
      "Epoch [7/83, loss:0.5910]\n",
      "Epoch [7/84, loss:1.5582]\n",
      "Epoch [7/85, loss:0.9242]\n",
      "Epoch [7/86, loss:0.1986]\n",
      "Epoch [7/87, loss:0.7055]\n",
      "Epoch [7/88, loss:0.4425]\n",
      "Epoch [7/89, loss:1.1176]\n",
      "Epoch [7/90, loss:0.6021]\n",
      "Epoch [7/91, loss:0.6513]\n",
      "Epoch [7/92, loss:2.3193]\n",
      "Epoch [7/93, loss:1.6728]\n",
      "Epoch [7/94, loss:0.5606]\n",
      "Epoch [7/95, loss:2.2150]\n",
      "Epoch [7/96, loss:0.2183]\n",
      "Epoch [7/97, loss:0.5465]\n",
      "Epoch [7/98, loss:0.8347]\n",
      "Epoch [7/99, loss:0.3980]\n",
      "Epoch [7/100, loss:0.3908]\n",
      "Epoch [7/101, loss:0.1814]\n",
      "Epoch [7/102, loss:1.4993]\n",
      "Epoch [7/103, loss:0.6268]\n",
      "Epoch [7/104, loss:0.7779]\n",
      "Epoch [7/105, loss:0.4704]\n",
      "Epoch [7/106, loss:0.1960]\n",
      "Epoch [7/107, loss:0.7331]\n",
      "Epoch [7/108, loss:0.3814]\n",
      "Epoch [7/109, loss:0.2735]\n",
      "Epoch [7/110, loss:0.3389]\n",
      "Epoch [7/111, loss:0.4387]\n",
      "Epoch [7/112, loss:0.4265]\n",
      "Epoch [7/113, loss:0.6538]\n",
      "Epoch [7/114, loss:0.3203]\n",
      "Epoch [7/115, loss:0.1298]\n",
      "Epoch [7/116, loss:0.6514]\n",
      "Epoch [7/117, loss:0.7048]\n",
      "Epoch [7/118, loss:1.0622]\n",
      "Epoch [7/119, loss:0.6321]\n",
      "Epoch [7/120, loss:0.9978]\n",
      "Epoch [7/121, loss:0.6048]\n",
      "Epoch [7/122, loss:0.7819]\n",
      "Epoch [7/123, loss:0.4015]\n",
      "Epoch [7/124, loss:0.5507]\n",
      "Epoch [7/125, loss:0.5762]\n",
      "Epoch [7/126, loss:0.7067]\n",
      "Epoch [7/127, loss:0.1168]\n",
      "Epoch [7/128, loss:0.9031]\n",
      "Epoch [7/129, loss:1.0155]\n",
      "Epoch [7/130, loss:0.5051]\n",
      "Epoch [7/131, loss:1.2756]\n",
      "Epoch [7/132, loss:0.6073]\n",
      "Epoch [7/133, loss:0.4865]\n",
      "Epoch [7/134, loss:0.2105]\n",
      "Epoch [7/135, loss:0.3852]\n",
      "Epoch [7/136, loss:0.3574]\n",
      "Epoch [7/137, loss:0.1414]\n",
      "Epoch [7/138, loss:0.8817]\n",
      "Epoch [7/139, loss:0.8908]\n",
      "Epoch [7/140, loss:4.3514]\n",
      "Epoch [7/141, loss:0.8440]\n",
      "Epoch [7/142, loss:0.3503]\n",
      "Epoch [7/143, loss:0.5349]\n",
      "Epoch [7/144, loss:0.6452]\n",
      "Epoch [7/145, loss:1.8256]\n",
      "Epoch [7/146, loss:0.4359]\n",
      "Epoch [7/147, loss:0.6011]\n",
      "Epoch [7/148, loss:0.5735]\n",
      "Epoch [7/149, loss:0.5760]\n",
      "Epoch [7/150, loss:0.0489]\n",
      "Epoch [7/151, loss:1.6765]\n",
      "Epoch [7/152, loss:0.6316]\n",
      "Epoch [7/153, loss:0.6866]\n",
      "Epoch [7/154, loss:0.8845]\n",
      "Epoch [7/155, loss:1.2282]\n",
      "Epoch [7/156, loss:0.6858]\n",
      "Epoch [7/157, loss:0.3737]\n",
      "Epoch [7/158, loss:0.7032]\n",
      "Epoch [7/159, loss:1.4817]\n",
      "Epoch [7/160, loss:0.6453]\n",
      "Epoch [7/161, loss:0.3323]\n",
      "Epoch [7/162, loss:0.9359]\n",
      "Epoch [7/163, loss:1.5679]\n",
      "Epoch [7/164, loss:0.3675]\n",
      "Epoch [7/165, loss:0.8526]\n",
      "Epoch [7/166, loss:1.0004]\n",
      "Epoch [7/167, loss:0.3774]\n",
      "Epoch [7/168, loss:1.3007]\n",
      "Epoch [7/169, loss:2.0909]\n",
      "Epoch [7/170, loss:1.0492]\n",
      "Epoch [7/171, loss:0.7569]\n",
      "Epoch [7/172, loss:0.5047]\n",
      "Epoch [7/173, loss:0.3882]\n",
      "Epoch [7/174, loss:1.0853]\n",
      "Epoch [7/175, loss:0.3873]\n",
      "Epoch [7/176, loss:0.3065]\n",
      "Epoch [7/177, loss:0.6576]\n",
      "Epoch [7/178, loss:1.0506]\n",
      "Epoch [7/179, loss:0.9078]\n",
      "Epoch [7/180, loss:1.7648]\n",
      "Epoch [7/181, loss:0.4403]\n",
      "Epoch [7/182, loss:0.7631]\n",
      "Epoch [7/183, loss:0.3679]\n",
      "Epoch [7/184, loss:2.3404]\n",
      "Epoch [7/185, loss:0.7263]\n",
      "Epoch [7/186, loss:0.5634]\n",
      "Epoch [7/187, loss:0.9687]\n",
      "Epoch [7/188, loss:0.6005]\n",
      "Epoch [7/189, loss:0.6601]\n",
      "Epoch [7/190, loss:0.5343]\n",
      "Epoch [7/191, loss:0.6102]\n",
      "Epoch [7/192, loss:1.9019]\n",
      "Epoch [7/193, loss:0.4227]\n",
      "Epoch [7/194, loss:0.7508]\n",
      "Epoch [7/195, loss:0.6524]\n",
      "Epoch [7/196, loss:2.8000]\n",
      "Epoch [7/197, loss:0.2715]\n",
      "Epoch [7/198, loss:0.2707]\n",
      "Epoch [7/199, loss:0.6212]\n",
      "Epoch [7/200, loss:0.1130]\n",
      "Epoch [8/1, loss:0.2661]\n",
      "Epoch [8/2, loss:0.5683]\n",
      "Epoch [8/3, loss:0.5752]\n",
      "Epoch [8/4, loss:0.2803]\n",
      "Epoch [8/5, loss:0.3157]\n",
      "Epoch [8/6, loss:0.5401]\n",
      "Epoch [8/7, loss:0.3369]\n",
      "Epoch [8/8, loss:0.2394]\n",
      "Epoch [8/9, loss:0.2509]\n",
      "Epoch [8/10, loss:1.4870]\n",
      "Epoch [8/11, loss:0.0492]\n",
      "Epoch [8/12, loss:3.6429]\n",
      "Epoch [8/13, loss:0.6679]\n",
      "Epoch [8/14, loss:0.5991]\n",
      "Epoch [8/15, loss:1.7116]\n",
      "Epoch [8/16, loss:0.0471]\n",
      "Epoch [8/17, loss:0.0481]\n",
      "Epoch [8/18, loss:0.9864]\n",
      "Epoch [8/19, loss:0.2717]\n",
      "Epoch [8/20, loss:0.1799]\n",
      "Epoch [8/21, loss:0.7485]\n",
      "Epoch [8/22, loss:0.4214]\n",
      "Epoch [8/23, loss:0.5287]\n",
      "Epoch [8/24, loss:0.5974]\n",
      "Epoch [8/25, loss:0.5397]\n",
      "Epoch [8/26, loss:0.1458]\n",
      "Epoch [8/27, loss:0.4061]\n",
      "Epoch [8/28, loss:0.2088]\n",
      "Epoch [8/29, loss:0.7582]\n",
      "Epoch [8/30, loss:1.1555]\n",
      "Epoch [8/31, loss:0.7217]\n",
      "Epoch [8/32, loss:1.0319]\n",
      "Epoch [8/33, loss:1.2483]\n",
      "Epoch [8/34, loss:0.5012]\n",
      "Epoch [8/35, loss:0.1223]\n",
      "Epoch [8/36, loss:0.0586]\n",
      "Epoch [8/37, loss:0.4949]\n",
      "Epoch [8/38, loss:0.4824]\n",
      "Epoch [8/39, loss:0.4270]\n",
      "Epoch [8/40, loss:0.6285]\n",
      "Epoch [8/41, loss:0.6092]\n",
      "Epoch [8/42, loss:0.5214]\n",
      "Epoch [8/43, loss:0.0910]\n",
      "Epoch [8/44, loss:0.6964]\n",
      "Epoch [8/45, loss:1.0260]\n",
      "Epoch [8/46, loss:0.1422]\n",
      "Epoch [8/47, loss:0.1859]\n",
      "Epoch [8/48, loss:0.1451]\n",
      "Epoch [8/49, loss:1.2908]\n",
      "Epoch [8/50, loss:1.2716]\n",
      "Epoch [8/51, loss:1.2206]\n",
      "Epoch [8/52, loss:0.8148]\n",
      "Epoch [8/53, loss:2.5188]\n",
      "Epoch [8/54, loss:1.0064]\n",
      "Epoch [8/55, loss:2.3828]\n",
      "Epoch [8/56, loss:0.4401]\n",
      "Epoch [8/57, loss:0.3823]\n",
      "Epoch [8/58, loss:0.2476]\n",
      "Epoch [8/59, loss:0.5032]\n",
      "Epoch [8/60, loss:0.7010]\n",
      "Epoch [8/61, loss:2.3969]\n",
      "Epoch [8/62, loss:0.9180]\n",
      "Epoch [8/63, loss:0.5929]\n",
      "Epoch [8/64, loss:0.2663]\n",
      "Epoch [8/65, loss:0.0800]\n",
      "Epoch [8/66, loss:0.4164]\n",
      "Epoch [8/67, loss:1.0399]\n",
      "Epoch [8/68, loss:0.4962]\n",
      "Epoch [8/69, loss:0.5475]\n",
      "Epoch [8/70, loss:0.5517]\n",
      "Epoch [8/71, loss:0.4323]\n",
      "Epoch [8/72, loss:0.0967]\n",
      "Epoch [8/73, loss:0.2104]\n",
      "Epoch [8/74, loss:0.4007]\n",
      "Epoch [8/75, loss:0.1767]\n",
      "Epoch [8/76, loss:2.5881]\n",
      "Epoch [8/77, loss:0.4790]\n",
      "Epoch [8/78, loss:0.0905]\n",
      "Epoch [8/79, loss:0.4255]\n",
      "Epoch [8/80, loss:1.5743]\n",
      "Epoch [8/81, loss:0.5182]\n",
      "Epoch [8/82, loss:0.3198]\n",
      "Epoch [8/83, loss:0.5331]\n",
      "Epoch [8/84, loss:1.5713]\n",
      "Epoch [8/85, loss:0.9305]\n",
      "Epoch [8/86, loss:0.1600]\n",
      "Epoch [8/87, loss:0.6857]\n",
      "Epoch [8/88, loss:0.3095]\n",
      "Epoch [8/89, loss:1.1507]\n",
      "Epoch [8/90, loss:0.5503]\n",
      "Epoch [8/91, loss:0.5203]\n",
      "Epoch [8/92, loss:2.4445]\n",
      "Epoch [8/93, loss:1.6661]\n",
      "Epoch [8/94, loss:0.5096]\n",
      "Epoch [8/95, loss:2.1820]\n",
      "Epoch [8/96, loss:0.1915]\n",
      "Epoch [8/97, loss:0.4406]\n",
      "Epoch [8/98, loss:0.6834]\n",
      "Epoch [8/99, loss:0.3429]\n",
      "Epoch [8/100, loss:0.3298]\n",
      "Epoch [8/101, loss:0.1618]\n",
      "Epoch [8/102, loss:1.2665]\n",
      "Epoch [8/103, loss:0.4998]\n",
      "Epoch [8/104, loss:0.7740]\n",
      "Epoch [8/105, loss:0.2960]\n",
      "Epoch [8/106, loss:0.2055]\n",
      "Epoch [8/107, loss:0.6175]\n",
      "Epoch [8/108, loss:0.3306]\n",
      "Epoch [8/109, loss:0.1561]\n",
      "Epoch [8/110, loss:0.3152]\n",
      "Epoch [8/111, loss:0.3468]\n",
      "Epoch [8/112, loss:0.3641]\n",
      "Epoch [8/113, loss:0.5965]\n",
      "Epoch [8/114, loss:0.2018]\n",
      "Epoch [8/115, loss:0.1010]\n",
      "Epoch [8/116, loss:0.6046]\n",
      "Epoch [8/117, loss:0.6314]\n",
      "Epoch [8/118, loss:0.9737]\n",
      "Epoch [8/119, loss:0.5791]\n",
      "Epoch [8/120, loss:1.0336]\n",
      "Epoch [8/121, loss:0.4566]\n",
      "Epoch [8/122, loss:0.7931]\n",
      "Epoch [8/123, loss:0.3884]\n",
      "Epoch [8/124, loss:0.4921]\n",
      "Epoch [8/125, loss:0.4625]\n",
      "Epoch [8/126, loss:0.7259]\n",
      "Epoch [8/127, loss:0.0943]\n",
      "Epoch [8/128, loss:0.9000]\n",
      "Epoch [8/129, loss:1.0762]\n",
      "Epoch [8/130, loss:0.5237]\n",
      "Epoch [8/131, loss:1.3369]\n",
      "Epoch [8/132, loss:0.3746]\n",
      "Epoch [8/133, loss:0.3511]\n",
      "Epoch [8/134, loss:0.1816]\n",
      "Epoch [8/135, loss:0.2951]\n",
      "Epoch [8/136, loss:0.3054]\n",
      "Epoch [8/137, loss:0.1200]\n",
      "Epoch [8/138, loss:0.5968]\n",
      "Epoch [8/139, loss:0.7683]\n",
      "Epoch [8/140, loss:4.3628]\n",
      "Epoch [8/141, loss:0.7741]\n",
      "Epoch [8/142, loss:0.3222]\n",
      "Epoch [8/143, loss:0.4696]\n",
      "Epoch [8/144, loss:0.5315]\n",
      "Epoch [8/145, loss:1.9101]\n",
      "Epoch [8/146, loss:0.3959]\n",
      "Epoch [8/147, loss:0.6087]\n",
      "Epoch [8/148, loss:0.4927]\n",
      "Epoch [8/149, loss:0.5291]\n",
      "Epoch [8/150, loss:0.0363]\n",
      "Epoch [8/151, loss:1.5145]\n",
      "Epoch [8/152, loss:0.5944]\n",
      "Epoch [8/153, loss:0.6046]\n",
      "Epoch [8/154, loss:0.9821]\n",
      "Epoch [8/155, loss:1.3636]\n",
      "Epoch [8/156, loss:0.7322]\n",
      "Epoch [8/157, loss:0.3178]\n",
      "Epoch [8/158, loss:0.6472]\n",
      "Epoch [8/159, loss:1.5012]\n",
      "Epoch [8/160, loss:0.5722]\n",
      "Epoch [8/161, loss:0.3036]\n",
      "Epoch [8/162, loss:0.8897]\n",
      "Epoch [8/163, loss:1.5767]\n",
      "Epoch [8/164, loss:0.4163]\n",
      "Epoch [8/165, loss:0.7212]\n",
      "Epoch [8/166, loss:0.8205]\n",
      "Epoch [8/167, loss:0.2376]\n",
      "Epoch [8/168, loss:1.1473]\n",
      "Epoch [8/169, loss:2.3059]\n",
      "Epoch [8/170, loss:0.9247]\n",
      "Epoch [8/171, loss:0.7359]\n",
      "Epoch [8/172, loss:0.4400]\n",
      "Epoch [8/173, loss:0.3076]\n",
      "Epoch [8/174, loss:1.1363]\n",
      "Epoch [8/175, loss:0.3208]\n",
      "Epoch [8/176, loss:0.2593]\n",
      "Epoch [8/177, loss:0.4592]\n",
      "Epoch [8/178, loss:0.9437]\n",
      "Epoch [8/179, loss:0.8741]\n",
      "Epoch [8/180, loss:1.6814]\n",
      "Epoch [8/181, loss:0.4189]\n",
      "Epoch [8/182, loss:0.6720]\n",
      "Epoch [8/183, loss:0.3777]\n",
      "Epoch [8/184, loss:2.3884]\n",
      "Epoch [8/185, loss:0.7988]\n",
      "Epoch [8/186, loss:0.4395]\n",
      "Epoch [8/187, loss:0.9661]\n",
      "Epoch [8/188, loss:0.4640]\n",
      "Epoch [8/189, loss:0.5696]\n",
      "Epoch [8/190, loss:0.5003]\n",
      "Epoch [8/191, loss:0.5042]\n",
      "Epoch [8/192, loss:1.9738]\n",
      "Epoch [8/193, loss:0.3818]\n",
      "Epoch [8/194, loss:0.6664]\n",
      "Epoch [8/195, loss:0.7018]\n",
      "Epoch [8/196, loss:2.6753]\n",
      "Epoch [8/197, loss:0.2597]\n",
      "Epoch [8/198, loss:0.1798]\n",
      "Epoch [8/199, loss:0.6501]\n",
      "Epoch [8/200, loss:0.0914]\n",
      "Epoch [9/1, loss:0.1748]\n",
      "Epoch [9/2, loss:0.4462]\n",
      "Epoch [9/3, loss:0.5683]\n",
      "Epoch [9/4, loss:0.2618]\n",
      "Epoch [9/5, loss:0.2868]\n",
      "Epoch [9/6, loss:0.4138]\n",
      "Epoch [9/7, loss:0.3677]\n",
      "Epoch [9/8, loss:0.2014]\n",
      "Epoch [9/9, loss:0.2140]\n",
      "Epoch [9/10, loss:1.7011]\n",
      "Epoch [9/11, loss:0.0379]\n",
      "Epoch [9/12, loss:3.6161]\n",
      "Epoch [9/13, loss:0.5487]\n",
      "Epoch [9/14, loss:0.4821]\n",
      "Epoch [9/15, loss:1.6674]\n",
      "Epoch [9/16, loss:0.0361]\n",
      "Epoch [9/17, loss:0.0375]\n",
      "Epoch [9/18, loss:0.6814]\n",
      "Epoch [9/19, loss:0.2187]\n",
      "Epoch [9/20, loss:0.1415]\n",
      "Epoch [9/21, loss:0.6961]\n",
      "Epoch [9/22, loss:0.3994]\n",
      "Epoch [9/23, loss:0.4203]\n",
      "Epoch [9/24, loss:0.5506]\n",
      "Epoch [9/25, loss:0.4716]\n",
      "Epoch [9/26, loss:0.1185]\n",
      "Epoch [9/27, loss:0.3326]\n",
      "Epoch [9/28, loss:0.1652]\n",
      "Epoch [9/29, loss:0.8291]\n",
      "Epoch [9/30, loss:1.3941]\n",
      "Epoch [9/31, loss:0.7566]\n",
      "Epoch [9/32, loss:1.1523]\n",
      "Epoch [9/33, loss:1.0105]\n",
      "Epoch [9/34, loss:0.3883]\n",
      "Epoch [9/35, loss:0.0995]\n",
      "Epoch [9/36, loss:0.0440]\n",
      "Epoch [9/37, loss:0.3716]\n",
      "Epoch [9/38, loss:0.4998]\n",
      "Epoch [9/39, loss:0.4512]\n",
      "Epoch [9/40, loss:0.4732]\n",
      "Epoch [9/41, loss:0.7997]\n",
      "Epoch [9/42, loss:0.3974]\n",
      "Epoch [9/43, loss:0.0880]\n",
      "Epoch [9/44, loss:0.6073]\n",
      "Epoch [9/45, loss:0.9628]\n",
      "Epoch [9/46, loss:0.1222]\n",
      "Epoch [9/47, loss:0.1363]\n",
      "Epoch [9/48, loss:0.1239]\n",
      "Epoch [9/49, loss:1.3240]\n",
      "Epoch [9/50, loss:1.4307]\n",
      "Epoch [9/51, loss:1.1764]\n",
      "Epoch [9/52, loss:0.7936]\n",
      "Epoch [9/53, loss:2.0973]\n",
      "Epoch [9/54, loss:0.9229]\n",
      "Epoch [9/55, loss:2.2059]\n",
      "Epoch [9/56, loss:0.3356]\n",
      "Epoch [9/57, loss:0.3614]\n",
      "Epoch [9/58, loss:0.2520]\n",
      "Epoch [9/59, loss:0.4430]\n",
      "Epoch [9/60, loss:0.6451]\n",
      "Epoch [9/61, loss:2.2017]\n",
      "Epoch [9/62, loss:0.9750]\n",
      "Epoch [9/63, loss:0.4351]\n",
      "Epoch [9/64, loss:0.1693]\n",
      "Epoch [9/65, loss:0.0614]\n",
      "Epoch [9/66, loss:0.3099]\n",
      "Epoch [9/67, loss:1.0770]\n",
      "Epoch [9/68, loss:0.4068]\n",
      "Epoch [9/69, loss:0.4624]\n",
      "Epoch [9/70, loss:0.4811]\n",
      "Epoch [9/71, loss:0.2761]\n",
      "Epoch [9/72, loss:0.0696]\n",
      "Epoch [9/73, loss:0.1502]\n",
      "Epoch [9/74, loss:0.3082]\n",
      "Epoch [9/75, loss:0.1365]\n",
      "Epoch [9/76, loss:2.6693]\n",
      "Epoch [9/77, loss:0.4028]\n",
      "Epoch [9/78, loss:0.0703]\n",
      "Epoch [9/79, loss:0.3447]\n",
      "Epoch [9/80, loss:1.7621]\n",
      "Epoch [9/81, loss:0.4636]\n",
      "Epoch [9/82, loss:0.2262]\n",
      "Epoch [9/83, loss:0.4689]\n",
      "Epoch [9/84, loss:1.5536]\n",
      "Epoch [9/85, loss:0.9443]\n",
      "Epoch [9/86, loss:0.1242]\n",
      "Epoch [9/87, loss:0.6730]\n",
      "Epoch [9/88, loss:0.2267]\n",
      "Epoch [9/89, loss:1.0879]\n",
      "Epoch [9/90, loss:0.4921]\n",
      "Epoch [9/91, loss:0.4087]\n",
      "Epoch [9/92, loss:2.5708]\n",
      "Epoch [9/93, loss:1.6186]\n",
      "Epoch [9/94, loss:0.4662]\n",
      "Epoch [9/95, loss:2.1062]\n",
      "Epoch [9/96, loss:0.1652]\n",
      "Epoch [9/97, loss:0.3520]\n",
      "Epoch [9/98, loss:0.5274]\n",
      "Epoch [9/99, loss:0.2883]\n",
      "Epoch [9/100, loss:0.2688]\n",
      "Epoch [9/101, loss:0.1416]\n",
      "Epoch [9/102, loss:1.0245]\n",
      "Epoch [9/103, loss:0.3885]\n",
      "Epoch [9/104, loss:0.7763]\n",
      "Epoch [9/105, loss:0.1892]\n",
      "Epoch [9/106, loss:0.2144]\n",
      "Epoch [9/107, loss:0.5243]\n",
      "Epoch [9/108, loss:0.2802]\n",
      "Epoch [9/109, loss:0.0857]\n",
      "Epoch [9/110, loss:0.2970]\n",
      "Epoch [9/111, loss:0.2621]\n",
      "Epoch [9/112, loss:0.2946]\n",
      "Epoch [9/113, loss:0.5423]\n",
      "Epoch [9/114, loss:0.1258]\n",
      "Epoch [9/115, loss:0.0810]\n",
      "Epoch [9/116, loss:0.5666]\n",
      "Epoch [9/117, loss:0.5442]\n",
      "Epoch [9/118, loss:0.8447]\n",
      "Epoch [9/119, loss:0.5336]\n",
      "Epoch [9/120, loss:1.0860]\n",
      "Epoch [9/121, loss:0.3378]\n",
      "Epoch [9/122, loss:0.8353]\n",
      "Epoch [9/123, loss:0.3794]\n",
      "Epoch [9/124, loss:0.4904]\n",
      "Epoch [9/125, loss:0.3611]\n",
      "Epoch [9/126, loss:0.7517]\n",
      "Epoch [9/127, loss:0.0771]\n",
      "Epoch [9/128, loss:0.9014]\n",
      "Epoch [9/129, loss:1.1463]\n",
      "Epoch [9/130, loss:0.5542]\n",
      "Epoch [9/131, loss:1.4156]\n",
      "Epoch [9/132, loss:0.2444]\n",
      "Epoch [9/133, loss:0.2794]\n",
      "Epoch [9/134, loss:0.1548]\n",
      "Epoch [9/135, loss:0.2294]\n",
      "Epoch [9/136, loss:0.2550]\n",
      "Epoch [9/137, loss:0.1023]\n",
      "Epoch [9/138, loss:0.4037]\n",
      "Epoch [9/139, loss:0.6370]\n",
      "Epoch [9/140, loss:4.2874]\n",
      "Epoch [9/141, loss:0.6984]\n",
      "Epoch [9/142, loss:0.2966]\n",
      "Epoch [9/143, loss:0.3961]\n",
      "Epoch [9/144, loss:0.4257]\n",
      "Epoch [9/145, loss:1.9589]\n",
      "Epoch [9/146, loss:0.3323]\n",
      "Epoch [9/147, loss:0.6312]\n",
      "Epoch [9/148, loss:0.3954]\n",
      "Epoch [9/149, loss:0.4771]\n",
      "Epoch [9/150, loss:0.0278]\n",
      "Epoch [9/151, loss:1.3268]\n",
      "Epoch [9/152, loss:0.5568]\n",
      "Epoch [9/153, loss:0.5347]\n",
      "Epoch [9/154, loss:1.1149]\n",
      "Epoch [9/155, loss:1.5340]\n",
      "Epoch [9/156, loss:0.7269]\n",
      "Epoch [9/157, loss:0.2580]\n",
      "Epoch [9/158, loss:0.6094]\n",
      "Epoch [9/159, loss:1.4775]\n",
      "Epoch [9/160, loss:0.5176]\n",
      "Epoch [9/161, loss:0.2756]\n",
      "Epoch [9/162, loss:0.8490]\n",
      "Epoch [9/163, loss:1.5742]\n",
      "Epoch [9/164, loss:0.4643]\n",
      "Epoch [9/165, loss:0.6041]\n",
      "Epoch [9/166, loss:0.6573]\n",
      "Epoch [9/167, loss:0.1718]\n",
      "Epoch [9/168, loss:1.0025]\n",
      "Epoch [9/169, loss:2.4317]\n",
      "Epoch [9/170, loss:0.8067]\n",
      "Epoch [9/171, loss:0.7014]\n",
      "Epoch [9/172, loss:0.3787]\n",
      "Epoch [9/173, loss:0.2565]\n",
      "Epoch [9/174, loss:1.1870]\n",
      "Epoch [9/175, loss:0.2595]\n",
      "Epoch [9/176, loss:0.2197]\n",
      "Epoch [9/177, loss:0.3383]\n",
      "Epoch [9/178, loss:0.8182]\n",
      "Epoch [9/179, loss:0.8326]\n",
      "Epoch [9/180, loss:1.5521]\n",
      "Epoch [9/181, loss:0.3929]\n",
      "Epoch [9/182, loss:0.5806]\n",
      "Epoch [9/183, loss:0.4001]\n",
      "Epoch [9/184, loss:2.3910]\n",
      "Epoch [9/185, loss:0.9056]\n",
      "Epoch [9/186, loss:0.3394]\n",
      "Epoch [9/187, loss:0.9783]\n",
      "Epoch [9/188, loss:0.3547]\n",
      "Epoch [9/189, loss:0.4962]\n",
      "Epoch [9/190, loss:0.4657]\n",
      "Epoch [9/191, loss:0.4088]\n",
      "Epoch [9/192, loss:2.0132]\n",
      "Epoch [9/193, loss:0.3451]\n",
      "Epoch [9/194, loss:0.5843]\n",
      "Epoch [9/195, loss:0.7603]\n",
      "Epoch [9/196, loss:2.5714]\n",
      "Epoch [9/197, loss:0.2481]\n",
      "Epoch [9/198, loss:0.1203]\n",
      "Epoch [9/199, loss:0.6799]\n",
      "Epoch [9/200, loss:0.0733]\n",
      "Epoch [10/1, loss:0.1208]\n",
      "Epoch [10/2, loss:0.3394]\n",
      "Epoch [10/3, loss:0.5595]\n",
      "Epoch [10/4, loss:0.2454]\n",
      "Epoch [10/5, loss:0.2628]\n",
      "Epoch [10/6, loss:0.3165]\n",
      "Epoch [10/7, loss:0.3991]\n",
      "Epoch [10/8, loss:0.1718]\n",
      "Epoch [10/9, loss:0.1823]\n",
      "Epoch [10/10, loss:1.8711]\n",
      "Epoch [10/11, loss:0.0295]\n",
      "Epoch [10/12, loss:3.5405]\n",
      "Epoch [10/13, loss:0.4407]\n",
      "Epoch [10/14, loss:0.3803]\n",
      "Epoch [10/15, loss:1.5967]\n",
      "Epoch [10/16, loss:0.0283]\n",
      "Epoch [10/17, loss:0.0304]\n",
      "Epoch [10/18, loss:0.4220]\n",
      "Epoch [10/19, loss:0.1772]\n",
      "Epoch [10/20, loss:0.1122]\n",
      "Epoch [10/21, loss:0.6555]\n",
      "Epoch [10/22, loss:0.3734]\n",
      "Epoch [10/23, loss:0.3298]\n",
      "Epoch [10/24, loss:0.4764]\n",
      "Epoch [10/25, loss:0.4226]\n",
      "Epoch [10/26, loss:0.0967]\n",
      "Epoch [10/27, loss:0.2706]\n",
      "Epoch [10/28, loss:0.1299]\n",
      "Epoch [10/29, loss:0.9149]\n",
      "Epoch [10/30, loss:1.4965]\n",
      "Epoch [10/31, loss:0.8027]\n",
      "Epoch [10/32, loss:1.2908]\n",
      "Epoch [10/33, loss:0.8202]\n",
      "Epoch [10/34, loss:0.2990]\n",
      "Epoch [10/35, loss:0.0794]\n",
      "Epoch [10/36, loss:0.0327]\n",
      "Epoch [10/37, loss:0.2789]\n",
      "Epoch [10/38, loss:0.5241]\n",
      "Epoch [10/39, loss:0.4783]\n",
      "Epoch [10/40, loss:0.3675]\n",
      "Epoch [10/41, loss:0.9346]\n",
      "Epoch [10/42, loss:0.3070]\n",
      "Epoch [10/43, loss:0.0842]\n",
      "Epoch [10/44, loss:0.5178]\n",
      "Epoch [10/45, loss:0.9234]\n",
      "Epoch [10/46, loss:0.1015]\n",
      "Epoch [10/47, loss:0.1012]\n",
      "Epoch [10/48, loss:0.1015]\n",
      "Epoch [10/49, loss:1.3201]\n",
      "Epoch [10/50, loss:1.6134]\n",
      "Epoch [10/51, loss:1.1675]\n",
      "Epoch [10/52, loss:0.7952]\n",
      "Epoch [10/53, loss:1.7317]\n",
      "Epoch [10/54, loss:0.8539]\n",
      "Epoch [10/55, loss:2.0146]\n",
      "Epoch [10/56, loss:0.2572]\n",
      "Epoch [10/57, loss:0.3256]\n",
      "Epoch [10/58, loss:0.2600]\n",
      "Epoch [10/59, loss:0.4030]\n",
      "Epoch [10/60, loss:0.6070]\n",
      "Epoch [10/61, loss:2.0017]\n",
      "Epoch [10/62, loss:1.0029]\n",
      "Epoch [10/63, loss:0.3198]\n",
      "Epoch [10/64, loss:0.1085]\n",
      "Epoch [10/65, loss:0.0478]\n",
      "Epoch [10/66, loss:0.2287]\n",
      "Epoch [10/67, loss:1.0950]\n",
      "Epoch [10/68, loss:0.3395]\n",
      "Epoch [10/69, loss:0.3994]\n",
      "Epoch [10/70, loss:0.4201]\n",
      "Epoch [10/71, loss:0.1901]\n",
      "Epoch [10/72, loss:0.0520]\n",
      "Epoch [10/73, loss:0.1094]\n",
      "Epoch [10/74, loss:0.2547]\n",
      "Epoch [10/75, loss:0.1074]\n",
      "Epoch [10/76, loss:2.6858]\n",
      "Epoch [10/77, loss:0.3405]\n",
      "Epoch [10/78, loss:0.0546]\n",
      "Epoch [10/79, loss:0.2788]\n",
      "Epoch [10/80, loss:1.9038]\n",
      "Epoch [10/81, loss:0.4156]\n",
      "Epoch [10/82, loss:0.1661]\n",
      "Epoch [10/83, loss:0.4018]\n",
      "Epoch [10/84, loss:1.5132]\n",
      "Epoch [10/85, loss:0.9539]\n",
      "Epoch [10/86, loss:0.0975]\n",
      "Epoch [10/87, loss:0.6657]\n",
      "Epoch [10/88, loss:0.1760]\n",
      "Epoch [10/89, loss:0.9507]\n",
      "Epoch [10/90, loss:0.4353]\n",
      "Epoch [10/91, loss:0.3134]\n",
      "Epoch [10/92, loss:2.6641]\n",
      "Epoch [10/93, loss:1.5438]\n",
      "Epoch [10/94, loss:0.4290]\n",
      "Epoch [10/95, loss:2.0248]\n",
      "Epoch [10/96, loss:0.1450]\n",
      "Epoch [10/97, loss:0.2843]\n",
      "Epoch [10/98, loss:0.3748]\n",
      "Epoch [10/99, loss:0.2404]\n",
      "Epoch [10/100, loss:0.2195]\n",
      "Epoch [10/101, loss:0.1251]\n",
      "Epoch [10/102, loss:0.7860]\n",
      "Epoch [10/103, loss:0.3061]\n",
      "Epoch [10/104, loss:0.7816]\n",
      "Epoch [10/105, loss:0.1260]\n",
      "Epoch [10/106, loss:0.2258]\n",
      "Epoch [10/107, loss:0.4492]\n",
      "Epoch [10/108, loss:0.2439]\n",
      "Epoch [10/109, loss:0.0472]\n",
      "Epoch [10/110, loss:0.2792]\n",
      "Epoch [10/111, loss:0.1968]\n",
      "Epoch [10/112, loss:0.2342]\n",
      "Epoch [10/113, loss:0.4973]\n",
      "Epoch [10/114, loss:0.0799]\n",
      "Epoch [10/115, loss:0.0693]\n",
      "Epoch [10/116, loss:0.5371]\n",
      "Epoch [10/117, loss:0.4427]\n",
      "Epoch [10/118, loss:0.7088]\n",
      "Epoch [10/119, loss:0.4963]\n",
      "Epoch [10/120, loss:1.1336]\n",
      "Epoch [10/121, loss:0.2549]\n",
      "Epoch [10/122, loss:0.8994]\n",
      "Epoch [10/123, loss:0.3664]\n",
      "Epoch [10/124, loss:0.5487]\n",
      "Epoch [10/125, loss:0.2795]\n",
      "Epoch [10/126, loss:0.7661]\n",
      "Epoch [10/127, loss:0.0637]\n",
      "Epoch [10/128, loss:0.9037]\n",
      "Epoch [10/129, loss:1.2242]\n",
      "Epoch [10/130, loss:0.5803]\n",
      "Epoch [10/131, loss:1.4886]\n",
      "Epoch [10/132, loss:0.1730]\n",
      "Epoch [10/133, loss:0.2525]\n",
      "Epoch [10/134, loss:0.1315]\n",
      "Epoch [10/135, loss:0.1817]\n",
      "Epoch [10/136, loss:0.2159]\n",
      "Epoch [10/137, loss:0.0865]\n",
      "Epoch [10/138, loss:0.2842]\n",
      "Epoch [10/139, loss:0.5000]\n",
      "Epoch [10/140, loss:4.2016]\n",
      "Epoch [10/141, loss:0.6422]\n",
      "Epoch [10/142, loss:0.2708]\n",
      "Epoch [10/143, loss:0.3293]\n",
      "Epoch [10/144, loss:0.3436]\n",
      "Epoch [10/145, loss:1.9654]\n",
      "Epoch [10/146, loss:0.2625]\n",
      "Epoch [10/147, loss:0.6538]\n",
      "Epoch [10/148, loss:0.3028]\n",
      "Epoch [10/149, loss:0.4103]\n",
      "Epoch [10/150, loss:0.0225]\n",
      "Epoch [10/151, loss:1.1393]\n",
      "Epoch [10/152, loss:0.5189]\n",
      "Epoch [10/153, loss:0.4795]\n",
      "Epoch [10/154, loss:1.2612]\n",
      "Epoch [10/155, loss:1.7119]\n",
      "Epoch [10/156, loss:0.6601]\n",
      "Epoch [10/157, loss:0.2047]\n",
      "Epoch [10/158, loss:0.5844]\n",
      "Epoch [10/159, loss:1.4175]\n",
      "Epoch [10/160, loss:0.4795]\n",
      "Epoch [10/161, loss:0.2488]\n",
      "Epoch [10/162, loss:0.8101]\n",
      "Epoch [10/163, loss:1.5698]\n",
      "Epoch [10/164, loss:0.4988]\n",
      "Epoch [10/165, loss:0.5112]\n",
      "Epoch [10/166, loss:0.5319]\n",
      "Epoch [10/167, loss:0.1414]\n",
      "Epoch [10/168, loss:0.8537]\n",
      "Epoch [10/169, loss:2.4663]\n",
      "Epoch [10/170, loss:0.6881]\n",
      "Epoch [10/171, loss:0.6354]\n",
      "Epoch [10/172, loss:0.3262]\n",
      "Epoch [10/173, loss:0.2240]\n",
      "Epoch [10/174, loss:1.2268]\n",
      "Epoch [10/175, loss:0.2070]\n",
      "Epoch [10/176, loss:0.1883]\n",
      "Epoch [10/177, loss:0.2629]\n",
      "Epoch [10/178, loss:0.6968]\n",
      "Epoch [10/179, loss:0.7829]\n",
      "Epoch [10/180, loss:1.3909]\n",
      "Epoch [10/181, loss:0.3655]\n",
      "Epoch [10/182, loss:0.4920]\n",
      "Epoch [10/183, loss:0.4281]\n",
      "Epoch [10/184, loss:2.3662]\n",
      "Epoch [10/185, loss:1.0294]\n",
      "Epoch [10/186, loss:0.2673]\n",
      "Epoch [10/187, loss:0.9907]\n",
      "Epoch [10/188, loss:0.2756]\n",
      "Epoch [10/189, loss:0.4454]\n",
      "Epoch [10/190, loss:0.4309]\n",
      "Epoch [10/191, loss:0.3265]\n",
      "Epoch [10/192, loss:2.0309]\n",
      "Epoch [10/193, loss:0.3138]\n",
      "Epoch [10/194, loss:0.5105]\n",
      "Epoch [10/195, loss:0.8241]\n",
      "Epoch [10/196, loss:2.5038]\n",
      "Epoch [10/197, loss:0.2389]\n",
      "Epoch [10/198, loss:0.0844]\n",
      "Epoch [10/199, loss:0.7120]\n",
      "Epoch [10/200, loss:0.0592]\n",
      "Süre 88.31167316436768\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "model = Net()\n",
    "\n",
    "optimizer = torch.optim.Adamax(model.parameters(), lr=0.001)\n",
    "error = torch.nn.CrossEntropyLoss()\n",
    "epoch = 10\n",
    "\n",
    "for i in range(epoch):\n",
    "    for j, (images, label) in enumerate(train_loader):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(images)\n",
    "        loss = error(out, label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(\"Epoch [{}/{}, loss:{:.4f}]\".format(i+1, j+1, loss.item()))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Süre\", end-start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelin Testi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dogruluk (loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # test modu \n",
    "\n",
    "    with torch.no_grad(): # gradient (türev hesaplama)\n",
    "        for x,y in loader:\n",
    "            tahmin = model(x) # images\n",
    "            _,pred = tahmin.max(1)\n",
    "            num_correct += (pred==y).sum()\n",
    "            num_samples += (pred.size(0))\n",
    "\n",
    "        print(f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct) / float(num_samples) * 100:.2f}\")\n",
    "\n",
    "        model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train doğruluk:\n",
      "Got 153 / 200 with accuracy 76.50\n",
      "test doğruluk:\n",
      "Got 61 / 79 with accuracy 77.22\n"
     ]
    }
   ],
   "source": [
    "print(\"train doğruluk:\")\n",
    "dogruluk(train_loader, model)\n",
    "\n",
    "print(\"test doğruluk:\")\n",
    "dogruluk(test_loader, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelin Eğitim ve Testi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  100 Loss: 1.5086 Accuracy: 35.4430 Error: 64.5570\n",
      "iteration:  200 Loss: 0.5581 Accuracy: 58.2278 Error: 41.7722\n",
      "iteration:  300 Loss: 0.6320 Accuracy: 59.4937 Error: 40.5063\n",
      "iteration:  400 Loss: 0.3969 Accuracy: 63.2911 Error: 36.7089\n",
      "iteration:  500 Loss: 0.8068 Accuracy: 65.8228 Error: 34.1772\n",
      "iteration:  600 Loss: 0.3740 Accuracy: 68.3544 Error: 31.6456\n",
      "iteration:  700 Loss: 0.4710 Accuracy: 74.6835 Error: 25.3165\n",
      "iteration:  800 Loss: 0.2469 Accuracy: 75.9494 Error: 24.0506\n",
      "iteration:  900 Loss: 0.9087 Accuracy: 74.6835 Error: 25.3165\n",
      "iteration: 1000 Loss: 0.2834 Accuracy: 75.9494 Error: 24.0506\n",
      "iteration: 1100 Loss: 0.0608 Accuracy: 81.0127 Error: 18.9873\n",
      "iteration: 1200 Loss: 0.2407 Accuracy: 74.6835 Error: 25.3165\n",
      "iteration: 1300 Loss: 0.0267 Accuracy: 83.5443 Error: 16.4557\n",
      "iteration: 1400 Loss: 0.0952 Accuracy: 79.7468 Error: 20.2532\n",
      "iteration: 1500 Loss: 0.0173 Accuracy: 81.0127 Error: 18.9873\n",
      "iteration: 1600 Loss: 0.0550 Accuracy: 81.0127 Error: 18.9873\n",
      "iteration: 1700 Loss: 0.0094 Accuracy: 81.0127 Error: 18.9873\n",
      "iteration: 1800 Loss: 0.1526 Accuracy: 78.4810 Error: 21.5190\n",
      "iteration: 1900 Loss: 0.0102 Accuracy: 82.2785 Error: 17.7215\n",
      "iteration: 2000 Loss: 0.0066 Accuracy: 82.2785 Error: 17.7215\n",
      "Süre: 148.91513204574585\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model = Net()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "error = torch.nn.CrossEntropyLoss()\n",
    "epoch = 10\n",
    "\n",
    "kayip = []\n",
    "count = 0\n",
    "iterasyon = []\n",
    "\n",
    "for i in range(epoch):\n",
    "    for j , (images, label) in enumerate (train_loader):\n",
    "\n",
    "        tahmin = model(images)\n",
    "        optimizer.zero_grad()\n",
    "        loss = error(tahmin, label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        count += 1\n",
    "\n",
    "        if count % 100 == 0:\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            err = 0\n",
    "\n",
    "            for images, labels in test_loader:\n",
    "                out = model(images)\n",
    "                pred = torch.max(out.data, 1)[1]\n",
    "                total += len(label)\n",
    "\n",
    "                correct+= (pred==labels).sum()\n",
    "                err += (pred != labels).sum()\n",
    "\n",
    "            dogruluk = 100 * correct / float(total)\n",
    "            hata = 100 * err / float(total)\n",
    "            kayip.append(loss.data)\n",
    "            iterasyon.append(count)\n",
    "\n",
    "        if count % 100 == 0:\n",
    "            print(\"iteration: {:4} Loss: {:3.4f} Accuracy: {:3.4f} Error: {:3.4f}\".format(count, loss.data, dogruluk, hata))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Süre:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  100 Loss: 1.4722 Accuracy: 27.8481 Error: 72.1519\n",
      "iteration:  200 Loss: 1.4101 Accuracy: 25.3165 Error: 74.6835\n",
      "iteration:  300 Loss: 1.2868 Accuracy: 36.7089 Error: 63.2911\n",
      "iteration:  400 Loss: 0.4800 Accuracy: 36.7089 Error: 63.2911\n",
      "iteration:  500 Loss: 0.3051 Accuracy: 46.8354 Error: 53.1646\n",
      "iteration:  600 Loss: 0.0977 Accuracy: 45.5696 Error: 54.4304\n",
      "iteration:  700 Loss: 0.2256 Accuracy: 50.6329 Error: 49.3671\n",
      "iteration:  800 Loss: 0.1284 Accuracy: 50.6329 Error: 49.3671\n",
      "iteration:  900 Loss: 0.3188 Accuracy: 53.1646 Error: 46.8354\n",
      "iteration: 1000 Loss: 0.1226 Accuracy: 53.1646 Error: 46.8354\n",
      "iteration: 1100 Loss: 0.3328 Accuracy: 51.8987 Error: 48.1013\n",
      "iteration: 1200 Loss: 0.1022 Accuracy: 54.4304 Error: 45.5696\n",
      "iteration: 1300 Loss: 0.3168 Accuracy: 51.8987 Error: 48.1013\n",
      "iteration: 1400 Loss: 0.0855 Accuracy: 54.4304 Error: 45.5696\n",
      "iteration: 1500 Loss: 0.2991 Accuracy: 51.8987 Error: 48.1013\n",
      "iteration: 1600 Loss: 0.0723 Accuracy: 58.2278 Error: 41.7722\n",
      "iteration: 1700 Loss: 0.2825 Accuracy: 55.6962 Error: 44.3038\n",
      "iteration: 1800 Loss: 0.0634 Accuracy: 59.4937 Error: 40.5063\n",
      "iteration: 1900 Loss: 0.2660 Accuracy: 58.2278 Error: 41.7722\n",
      "iteration: 2000 Loss: 0.0573 Accuracy: 59.4937 Error: 40.5063\n",
      "Süre: 148.10063695907593\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model = Net()\n",
    "\n",
    "optimizer = torch.optim.Adamax(model.parameters(), lr=0.001)\n",
    "error = torch.nn.CrossEntropyLoss()\n",
    "epoch = 10\n",
    "\n",
    "kayip = []\n",
    "count = 0\n",
    "iterasyon = []\n",
    "\n",
    "for i in range(epoch):\n",
    "    for j , (images, label) in enumerate (train_loader):\n",
    "\n",
    "        tahmin = model(images)\n",
    "        optimizer.zero_grad()\n",
    "        loss = error(tahmin, label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        count += 1\n",
    "\n",
    "        if count % 100 == 0:\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            err = 0\n",
    "\n",
    "            for images, labels in test_loader:\n",
    "                out = model(images)\n",
    "                pred = torch.max(out.data, 1)[1]\n",
    "                total += len(label)\n",
    "\n",
    "                correct+= (pred==labels).sum()\n",
    "                err += (pred != labels).sum()\n",
    "\n",
    "            dogruluk = 100 * correct / float(total)\n",
    "            hata = 100 * err / float(total)\n",
    "            kayip.append(loss.data)\n",
    "            iterasyon.append(count)\n",
    "\n",
    "        if count % 100 == 0:\n",
    "            print(\"iteration: {:4} Loss: {:3.4f} Accuracy: {:3.4f} Error: {:3.4f}\".format(count, loss.data, dogruluk, hata))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Süre:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "833b1e0daebd69276f47cc9e2e2c8387bf0a407b51837849a04c5beaa21d9be9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
